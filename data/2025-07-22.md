<div id=toc></div>

# Table of Contents

- [physics.ao-ph](#physics.ao-ph) [Total: 2]
- [cs.NE](#cs.NE) [Total: 5]
- [cs.CV](#cs.CV) [Total: 141]
- [cs.AI](#cs.AI) [Total: 58]


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [1] [A Simple Intermediate Coupled MJO-ENSO Model: Multiscale Interactions and ENSO Complexity](https://arxiv.org/abs/2507.14395)
*Yinling Zhang,Nan Chen,Charlotte Moser*

Main category: physics.ao-ph

TL;DR: 本文开发了一个简单的中尺度耦合MJO-ENSO模型，研究其双向反馈及对ENSO复杂性的调控作用。


<details>
  <summary>Details</summary>
Motivation: MJO和ENSO是热带气候变率的两种主要模式，但其耦合相互作用在ENSO复杂性（如空间多样性、时间演化和强度变化）中的研究较少。

Method: 模型整合了多尺度过程（MJO、ENSO和Walker环流），并引入随机参数化以改进多尺度相互作用和极端事件的表征。

Result: 模型成功捕捉了MJO和ENSO的关键特征，包括非高斯统计、季节周期和空间事件模式，并揭示了其相互作用机制。

Conclusion: 该模型为分析长期变化、理解ENSO极端事件及其远程影响提供了有用工具，并推动了季节性预测和气候韧性研究。

Abstract: The Madden-Julian Oscillation (MJO) and the El Ni\~no-Southern Oscillation
(ENSO) are two dominant modes of tropical climate variability, each with
profound global weather impacts. While their individual dynamics have been
widely studied, their coupled interactions, particularly in the context of ENSO
complexity, including spatial diversity (Central Pacific vs. Eastern Pacific
events), temporal evolution (single-year and multi-year events), and intensity
variations (moderate to extreme events), have received limited attention in
modeling studies. In this paper, a simple intermediate coupled MJO-ENSO model
is developed to address critical gaps in understanding their bidirectional
feedback and its role in modulating ENSO complexity. The model integrates
multiscale processes, bridging intraseasonal (MJO), interannual (ENSO), and
decadal (Walker circulation) variability. Key mechanisms include: (1)
interannual SST modulating MJO through latent heat and background states, (2)
MJO-induced wind forcing triggering diverse ENSO events, and (3) decadal
variability modulating the strength and occurrence frequency of Eastern Pacific
and Central Pacific events. Effective stochastic parameterizations are
incorporated to improve the characterization of multiscale MJO-ENSO
interactions and the emergence of intermittency and extremes. The model
captures several crucial observed MJO and ENSO features, including non-Gaussian
statistics, seasonal cycles, energy spectra, and spatial event patterns. It
also reproduces critical MJO-ENSO interactions: warm pool edge extension,
convective activity adjustments that modulate SST, and ENSO's dependence on
MJO-driven easterly and westerly wind anomalies. The model provides a useful
tool to analyze long-term variations. It also advances the understanding of
ENSO extreme events and their remote impacts, as well as seasonal forecasting
and climate resilience.

</details>


### [2] [Learning Climate Sensitivity from Future Observations, Fast and Slow](https://arxiv.org/abs/2507.15767)
*Adam Michael Bauer,Cristian Proistosescu,Kelvin K Droegemeier*

Main category: physics.ao-ph

TL;DR: 本文提出了一种新模型方法，用于探索平衡气候敏感性和瞬态气候响应的学习速率，并识别其物理驱动因素。研究发现，尽管可以约束未来的瞬态气候响应，但对平衡气候敏感性的约束更为困难，尤其是高值。


<details>
  <summary>Details</summary>
Motivation: 气候敏感性长期存在不确定性，本文旨在通过新方法探索其学习速率及物理驱动因素，以解决这一难题。

Method: 开发了一种新模型方法，考虑参数不确定性和协方差，同时考虑序列相关的内部气候变率。

Result: 研究发现，瞬态气候响应可以约束，但平衡气候敏感性的高值难以约束，低值更容易确定。

Conclusion: 本文揭示了约束平衡气候敏感性高值的困难，并指出深海响应的不确定性是主要原因。

Abstract: Climate sensitivity has remained stubbornly uncertain since the Charney
Report was published some 45 years ago. Two factors in future climate
projections could alter this dilemma: (i) an increased ratio of CO$_2$ forcing
relative to aerosol cooling, owing to both continued accumulation of CO$_2$ and
declining aerosol emissions, and (ii) a warming world, whereby CO$_2$-induced
warming becomes more pronounced relative to climate variability. Here, we
develop a novel modeling approach to explore the rates of learning about
equilibrium climate sensitivity and the transient climate response (TCR) and
identify the physical drivers underpinning these learning rates. Our approach
has the advantage over past work by accounting for the full spectrum of
parameter uncertainties and covariances, while also taking into account
serially correlated internal climate variability. Moreover, we provide a
physical explanation of how quickly we may hope to learn about climate
sensitivity. We find that, although we are able to constrain future TCR
regardless of the true underlying value, constraining ECS is more difficult,
with low values of ECS being more easily ascertained than high values. This
asymmetry can be explained by most of the warming this century being
attributable to the fast climate mode, which is more useful for constraining
TCR than it is for ECS. We further show that our inability to constrain the
deep ocean response is what limits our ability to learn high values of ECS.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [3] [APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation](https://arxiv.org/abs/2507.14270)
*Ravin Kumar*

Main category: cs.NE

TL;DR: APTx Neuron是一种新型统一神经计算单元，将非线性和线性变换集成到单一可训练表达式中，提高了计算效率和架构简洁性。


<details>
  <summary>Details</summary>
Motivation: 传统神经元设计需要独立的激活层，增加了计算复杂性和架构冗余。APTx Neuron旨在通过统一设计简化架构并提升效率。

Method: APTx Neuron基于APTx激活函数，形式为$y = \sum_{i=1}^{n} ((\alpha_i + \tanh(\beta_i x_i)) \cdot \gamma_i x_i) + \delta$，所有参数可训练。

Result: 在MNIST数据集上，APTx Neuron仅用20个epoch和约332K参数即达到96.69%的测试准确率。

Conclusion: APTx Neuron在表达能力和计算效率上优于传统神经元，为统一神经元设计提供了新范式。

Abstract: We propose the APTx Neuron, a novel, unified neural computation unit that
integrates non-linear activation and linear transformation into a single
trainable expression. The APTx Neuron is derived from the APTx activation
function, thereby eliminating the need for separate activation layers and
making the architecture both computationally efficient and elegant. The
proposed neuron follows the functional form $y = \sum_{i=1}^{n} ((\alpha_i +
\tanh(\beta_i x_i)) \cdot \gamma_i x_i) + \delta$, where all parameters
$\alpha_i$, $\beta_i$, $\gamma_i$, and $\delta$ are trainable. We validate our
APTx Neuron-based architecture on the MNIST dataset, achieving up to 96.69\%
test accuracy in just 20 epochs using approximately 332K trainable parameters.
The results highlight the superior expressiveness and computational efficiency
of the APTx Neuron compared to traditional neurons, pointing toward a new
paradigm in unified neuron design and the architectures built upon it.

</details>


### [4] [Training oscillator Ising machines to assign the dynamic stability of their equilibrium points](https://arxiv.org/abs/2507.14386)
*Yi Cheng,Zongli Lin*

Main category: cs.NE

TL;DR: 提出了一种神经网络模型，通过调整平衡点的稳定性实现类似Hopfield的联想记忆，基于OIM模型，开发了HRECM方法训练耦合权重。


<details>
  <summary>Details</summary>
Motivation: 传统Hopfield模型需同时考虑平衡点的存在和动态稳定性，而OIM模型因其结构稳定性简化了权重设计，仅需关注动态稳定性。

Method: 建立了OIM平衡点稳定性与Hamiltonian能量的联系，提出HRECM方法训练耦合权重。

Result: 数值实验验证了HRECM方法的有效性。

Conclusion: HRECM方法简化了OIM模型的权重设计，提高了联想记忆的实现效率。

Abstract: We propose a neural network model, which, with appropriate assignment of the
stability of its equilibrium points (EPs), achieves Hopfield-like associative
memory. The oscillator Ising machine (OIM) is an ideal candidates for such a
model, as all its $0/\pi$ binary EPs are structurally stable with their dynamic
stability tunable by the coupling weights. Traditional Hopfield-based models
store the desired patterns by designing the coupling weights between neurons.
The design of coupling weights should simultaneously take into account both the
existence and the dynamic stability of the EPs for the storage of the desired
patterns. For OIMs, since all $0/\pi$ binary EPs are structurally stable, the
design of the coupling weights needs only to focus on assigning appropriate
stability for the $0/\pi$ binary EPs according to the desired patterns. In this
paper, we establish a connection between the stability and the Hamiltonian
energy of EPs for OIMs, and, based on this connection, provide a
Hamiltonian-Regularized Eigenvalue Contrastive Method (HRECM) to train the
coupling weights of OIMs for assigning appropriate stability to their EPs.
Finally, numerical experiments are performed to validate the effectiveness of
the proposed method.

</details>


### [5] [Analyzing Internal Activity and Robustness of SNNs Across Neuron Parameter Space](https://arxiv.org/abs/2507.14757)
*Szymon Mazurek,Jakub Caputa,Maciej Wielgosz*

Main category: cs.NE

TL;DR: 本文识别并描述了SNN神经元模型参数（膜时间常数和电压阈值）的操作空间，在此区域内网络表现最佳，平衡分类准确性和能量效率。


<details>
  <summary>Details</summary>
Motivation: SNNs具有高效能和生物合理性，但其性能依赖于神经元模型参数的调优，因此需要研究如何优化这些参数以实现最佳性能。

Method: 通过系统探索数据集和架构，可视化并量化神经元超参数的操作空间，评估对抗噪声的鲁棒性。

Result: 在操作空间内，SNN表现最佳；超出此空间会导致能量浪费或网络沉默。对抗噪声下，非最优区域的SNN表现出更高的脉冲相关性和内部同步性。

Conclusion: 研究强调了超参数调优的重要性，为部署高效稳健的SNN提供了实用指南，特别是在神经形态计算场景中。

Abstract: Spiking Neural Networks (SNNs) offer energy-efficient and biologically
plausible alternatives to traditional artificial neural networks, but their
performance depends critically on the tuning of neuron model parameters. In
this work, we identify and characterize an operational space - a constrained
region in the neuron hyperparameter domain (specifically membrane time constant
tau and voltage threshold vth) - within which the network exhibits meaningful
activity and functional behavior. Operating inside this manifold yields optimal
trade-offs between classification accuracy and spiking activity, while stepping
outside leads to degeneration: either excessive energy use or complete network
silence.
  Through systematic exploration across datasets and architectures, we
visualize and quantify this manifold and identify efficient operating points.
We further assess robustness to adversarial noise, showing that SNNs exhibit
increased spike correlation and internal synchrony when operating outside their
optimal region. These findings highlight the importance of principled
hyperparameter tuning to ensure both task performance and energy efficiency.
Our results offer practical guidelines for deploying robust and efficient SNNs,
particularly in neuromorphic computing scenarios.

</details>


### [6] [DHEvo: Data-Algorithm Based Heuristic Evolution for Generalizable MILP Solving](https://arxiv.org/abs/2507.15615)
*Zhihao Zhang,Siyuan Li,Chenxi Li,Feifan Liu,Mengjing Chen,Kai Li,Tao Zhong,Bo An,Peng Liu*

Main category: cs.NE

TL;DR: 论文提出了一种数据-算法协同进化框架（DHEvo），通过迭代选择代表性实例和进化启发式方法，解决了现有基于LLM的方法在混合整数规划（MILP）中泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的MILP启发式方法在问题类内泛化能力有限，无法捕捉实例特征。

Method: 提出DHEvo框架，通过LLM多智能体系统生成数据-代码对，并基于适应度分数迭代优化。

Result: 实验表明，DHEvo在多个MILP基准测试中显著优于人工设计的启发式和现有LLM方法。

Conclusion: DHEvo通过数据-算法协同进化，显著提升了MILP启发式的泛化能力和求解性能。

Abstract: Primal heuristics play a critical role in improving the efficiency of mixed
integer programming (MILP) solvers. As large language models (LLMs) have
demonstrated superior code generation abilities, recent MILP works are devoted
to leveraging the evolutionary computation approaches with LLMs to generate
effective primal heuristics. Although the generated heuristics have achieved
better solving performance than the hand-crafted ones with little adaptability,
the advantage of current LLM-based methods is limited to few MILP instances in
one problem class, as they fail to capture the instance characteristics in the
problem class (the MILP instances generated from the same mathematical model
are defined as a problem class). Since MILP instances often differ
significantly in structure and feature distribution, the neglect of their
characteristics in the evolution process results in poor generalization within
the same problem class. To overcome this challenge, we propose a data-algorithm
co-evolution framework (DHEvo) that iteratively selects representative
instances and evolves corresponding heuristics. With the initial instance
distribution, we develop an LLM-based multi-agent system to generate data-code
pairs simultaneously. These data-code pairs are iteratively refined based on
their fitness scores, leading to the identification of the most effective
heuristic over the entire problem class. Extensive experiments across diverse
MILP benchmarks demonstrate that our approach significantly outperforms both
human-designed heuristics and existing LLM-based methods.

</details>


### [7] [TONUS: Neuromorphic human pose estimation for artistic sound co-creation](https://arxiv.org/abs/2507.15734)
*Jules Lecomte,Konrad Zinner,Michael Neumeier,Axel von Arnim*

Main category: cs.NE

TL;DR: 论文提出了一种基于神经形态身体传感的艺术声音装置，旨在通过非侵入式交互让访客与机器共同创造声音景观。


<details>
  <summary>Details</summary>
Motivation: 人机交互在艺术和工业中日益重要，但现有交互过于技术化且缺乏艺术潜力，未能充分发挥新技术的作用。

Method: 设计了一种神经形态多头人体姿态估计神经传感器，利用尖峰神经网络提取特征，并通过专用神经形态芯片处理。

Result: 访客通过精细的身体动作控制声音景观和视觉输出，体验与机器的神经对话。

Conclusion: 该装置实现了无缝的人机交互，支持访客的想象力和诗意表达。

Abstract: Human machine interaction is a huge source of inspiration in today's media
art and digital design, as machines and humans merge together more and more.
Its place in art reflects its growing applications in industry, such as
robotics. However, those interactions often remains too technical and
machine-driven for people to really engage into. On the artistic side, new
technologies are often not explored in their full potential and lag a bit
behind, so that state-of-the-art research does not make its way up to museums
and exhibitions. Machines should support people's imagination and poetry in a
seamless interface to their body or soul. We propose an artistic sound
installation featuring neuromorphic body sensing to support a direct yet non
intrusive interaction with the visitor with the purpose of creating sound
scapes together with the machine. We design a neuromorphic multihead human pose
estimation neural sensor that shapes sound scapes and visual output with fine
body movement control. In particular, the feature extractor is a spiking neural
network tailored for a dedicated neuromorphic chip. The visitor, immersed in a
sound atmosphere and a neurally processed representation of themselves that
they control, experience the dialogue with a machine that thinks neurally,
similarly to them.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [8] [Comparative Analysis of Algorithms for the Fitting of Tessellations to 3D Image Data](https://arxiv.org/abs/2507.14268)
*Andreas Alpers,Orkun Furat,Christian Jung,Matthias Neumann,Claudia Redenbach,Aigerim Saken,Volker Schmidt*

Main category: cs.CV

TL;DR: 比较分析用于拟合3D图像数据的镶嵌模型算法策略，评估优化方法并指导选择。


<details>
  <summary>Details</summary>
Motivation: 在材料科学中，拟合3D图像数据（如多晶体和泡沫）的镶嵌模型是一个不断发展的领域，需要评估不同算法的效果。

Method: 使用线性/非线性规划、随机优化（交叉熵法）和梯度下降等方法生成Voronoi、Laguerre和GBPD模型，并通过体积、表面积和拓扑差异评估拟合质量。

Result: 揭示了模型复杂性、优化方法复杂性和近似质量之间的权衡，为根据数据特征和应用需求选择方法提供指导。

Conclusion: 研究结果为选择适合的镶嵌模型算法提供了实用建议，平衡了复杂性和拟合质量。

Abstract: This paper presents a comparative analysis of algorithmic strategies for
fitting tessellation models to 3D image data of materials such as polycrystals
and foams. In this steadily advancing field, we review and assess
optimization-based methods -- including linear and nonlinear programming,
stochastic optimization via the cross-entropy method, and gradient descent --
for generating Voronoi, Laguerre, and generalized balanced power diagrams
(GBPDs) that approximate voxelbased grain structures. The quality of fit is
evaluated on real-world datasets using discrepancy measures that quantify
differences in grain volume, surface area, and topology. Our results highlight
trade-offs between model complexity, the complexity of the optimization
routines involved, and the quality of approximation, providing guidance for
selecting appropriate methods based on data characteristics and application
needs.

</details>


### [9] [Semantic Segmentation based Scene Understanding in Autonomous Vehicles](https://arxiv.org/abs/2507.14303)
*Ehsan Rassekh*

Main category: cs.CV

TL;DR: 本文探讨了深度学习在语义分割中的应用，提出了几种高效模型，并研究了不同主干网络对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 人工智能和深度学习在复杂任务中表现出色，尤其是在自动驾驶等领域。本文旨在通过语义分割提升场景理解能力。

Method: 使用BDD100k数据集，提出多种高效模型，并尝试不同主干网络作为编码器。

Result: 结果表明，选择合适的主干网络对语义分割性能有显著影响，模型在准确性、平均IoU和损失函数方面均有提升。

Conclusion: 通过优化主干网络，语义分割性能得到改善，有助于更好地理解场景和环境。

Abstract: In recent years, the concept of artificial intelligence (AI) has become a
prominent keyword because it is promising in solving complex tasks. The need
for human expertise in specific areas may no longer be needed because machines
have achieved successful results using artificial intelligence and can make the
right decisions in critical situations. This process is possible with the help
of deep learning (DL), one of the most popular artificial intelligence
technologies. One of the areas in which the use of DL is used is in the
development of self-driving cars, which is very effective and important. In
this work, we propose several efficient models to investigate scene
understanding through semantic segmentation. We use the BDD100k dataset to
investigate these models. Another contribution of this work is the usage of
several Backbones as encoders for models. The obtained results show that
choosing the appropriate backbone has a great effect on the performance of the
model for semantic segmentation. Better performance in semantic segmentation
allows us to understand better the scene and the environment around the agent.
In the end, we analyze and evaluate the proposed models in terms of accuracy,
mean IoU, and loss function, and the results show that these metrics are
improved.

</details>


### [10] [CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation](https://arxiv.org/abs/2507.14312)
*Marc Lafon,Gustavo Adolfo Vargas Hakim,Clément Rambour,Christian Desrosier,Nicolas Thome*

Main category: cs.CV

TL;DR: CLIPTTA是一种基于梯度的测试时适应方法，通过软对比损失与CLIP预训练目标对齐，解决了传统熵最小化方法在视觉语言模型中的局限性，并在开放集设置中表现出色。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（如CLIP）在零样本任务中表现优异，但在分布偏移下泛化能力不足。传统的测试时适应方法（如熵最小化）与CLIP的对比训练目标不匹配，导致性能受限和伪标签漂移等问题。

Method: 提出CLIPTTA，采用与CLIP预训练目标一致的软对比损失进行梯度更新，并通过理论分析证明其能避免类崩溃。进一步扩展至开放集设置，使用Outlier Contrastive Exposure（OCE）损失提升OOD检测能力。

Result: 在75个数据集上的实验表明，CLIPTTA在多样分布偏移下表现稳定，优于基于熵的目标方法，并在多个数据集上超越现有最先进的TTA方法。

Conclusion: CLIPTTA通过对齐预训练目标，显著提升了视觉语言模型在测试时适应中的性能，尤其在开放集和分布偏移场景下表现出色。

Abstract: Vision-language models (VLMs) like CLIP exhibit strong zero-shot capabilities
but often fail to generalize under distribution shifts. Test-time adaptation
(TTA) allows models to update at inference time without labeled data, typically
via entropy minimization. However, this objective is fundamentally misaligned
with the contrastive image-text training of VLMs, limiting adaptation
performance and introducing failure modes such as pseudo-label drift and class
collapse. We propose CLIPTTA, a new gradient-based TTA method for
vision-language models that leverages a soft contrastive loss aligned with
CLIP's pre-training objective. We provide a theoretical analysis of CLIPTTA's
gradients, showing how its batch-aware design mitigates the risk of collapse.
We further extend CLIPTTA to the open-set setting, where both in-distribution
(ID) and out-of-distribution (OOD) samples are encountered, using an Outlier
Contrastive Exposure (OCE) loss to improve OOD detection. Evaluated on 75
datasets spanning diverse distribution shifts, CLIPTTA consistently outperforms
entropy-based objectives and is highly competitive with state-of-the-art TTA
methods, outperforming them on a large number of datasets and exhibiting more
stable performance across diverse shifts.

</details>


### [11] [A Hidden Stumbling Block in Generalized Category Discovery: Distracted Attention](https://arxiv.org/abs/2507.14315)
*Qiyu Xu,Zhanxuan Hu,Yu Duan,Ercheng Pei,Yonghang Tai*

Main category: cs.CV

TL;DR: 论文提出了一种称为注意力聚焦（AF）的机制，通过剪除非信息性标记来解决广义类别发现（GCD）中的注意力分散问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有GCD方法在处理未标记数据时，模型注意力容易被任务无关的背景区域分散，导致特征提取不理想。

Method: AF由两个组件组成：标记重要性度量（TIME）和多尺度标记自适应剪枝（TAP），通过量化标记重要性并剪除非信息性标记来优化注意力。

Result: 将AF集成到SimGCD方法中，性能提升了15.4%，且计算开销极小。

Conclusion: AF是一种轻量级、即插即用的模块，能有效提升GCD方法的性能。

Abstract: Generalized Category Discovery (GCD) aims to classify unlabeled data from
both known and unknown categories by leveraging knowledge from labeled known
categories. While existing methods have made notable progress, they often
overlook a hidden stumbling block in GCD: distracted attention. Specifically,
when processing unlabeled data, models tend to focus not only on key objects in
the image but also on task-irrelevant background regions, leading to suboptimal
feature extraction. To remove this stumbling block, we propose Attention
Focusing (AF), an adaptive mechanism designed to sharpen the model's focus by
pruning non-informative tokens. AF consists of two simple yet effective
components: Token Importance Measurement (TIME) and Token Adaptive Pruning
(TAP), working in a cascade. TIME quantifies token importance across multiple
scales, while TAP prunes non-informative tokens by utilizing the multi-scale
importance scores provided by TIME. AF is a lightweight, plug-and-play module
that integrates seamlessly into existing GCD methods with minimal computational
overhead. When incorporated into one prominent GCD method, SimGCD, AF achieves
up to 15.4% performance improvement over the baseline with minimal
computational overhead. The implementation code is provided in
https://github.com/Afleve/AFGCD.

</details>


### [12] [Hallucination Score: Towards Mitigating Hallucinations in Generative Image Super-Resolution](https://arxiv.org/abs/2507.14367)
*Weiming Ren,Raghav Goyal,Zhiming Hu,Tristan Ty Aumentado-Armstrong,Iqbal Mohomed,Alex Levinshtein*

Main category: cs.CV

TL;DR: 生成超分辨率（GSR）在感知图像质量上表现优异，但存在与低分辨率图像（LRI）或真实图像（GTI）不匹配的“幻觉”问题。本文提出一种基于多模态大语言模型（MLLM）的“幻觉评分”（HS）方法，并通过深度特征距离优化GSR模型以减少幻觉。


<details>
  <summary>Details</summary>
Motivation: GSR在感知质量上表现优异，但生成的细节可能与LRI或GTI不匹配，即“幻觉”问题，限制了其实际应用。现有指标无法有效衡量此类问题。

Method: 利用MLLM构建提示，评估幻觉视觉元素并生成HS。同时，发现某些深度特征距离与HS强相关，提出将其作为可微奖励函数优化GSR模型。

Result: HS与人类评估高度一致，并为超分辨率模型提供了补充性见解。深度特征距离与HS的强相关性为模型优化提供了新方向。

Conclusion: 本文提出的HS方法有效衡量并缓解了GSR中的幻觉问题，通过深度特征距离优化模型，为实际应用提供了新思路。

Abstract: Generative super-resolution (GSR) currently sets the state-of-the-art in
terms of perceptual image quality, overcoming the "regression-to-the-mean" blur
of prior non-generative models. However, from a human perspective, such models
do not fully conform to the optimal balance between quality and fidelity.
Instead, a different class of artifacts, in which generated details fail to
perceptually match the low resolution image (LRI) or ground-truth image (GTI),
is a critical but under studied issue in GSR, limiting its practical
deployments. In this work, we focus on measuring, analyzing, and mitigating
these artifacts (i.e., "hallucinations"). We observe that hallucinations are
not well-characterized with existing image metrics or quality models, as they
are orthogonal to both exact fidelity and no-reference quality. Instead, we
take advantage of a multimodal large language model (MLLM) by constructing a
prompt that assesses hallucinatory visual elements and generates a
"Hallucination Score" (HS). We find that our HS is closely aligned with human
evaluations, and also provides complementary insights to prior image metrics
used for super-resolution (SR) models. In addition, we find certain deep
feature distances have strong correlations with HS. We therefore propose to
align the GSR models by using such features as differentiable reward functions
to mitigate hallucinations.

</details>


### [13] [DUSTrack: Semi-automated point tracking in ultrasound videos](https://arxiv.org/abs/2507.14368)
*Praneeth Namburi,Roger Pallarès-López,Jessica Rosendorf,Duarte Folgado,Brian W. Anthony*

Main category: cs.CV

TL;DR: DUSTrack是一个结合深度学习和光流的半自动化工具包，用于在B型超声视频中跟踪任意点，解决了噪声和运动模糊等问题，表现出高准确性和通用性。


<details>
  <summary>Details</summary>
Motivation: B型超声中的组织运动跟踪因噪声、低对比度和平面外运动而困难，需要一种通用且准确的解决方案。

Method: 结合深度学习和光流技术，提供图形界面生成训练数据，并采用新型光流滤波技术减少噪声。

Result: DUSTrack在准确性上优于零样本点跟踪器，与专用方法相当，适用于多种解剖结构和运动模式。

Conclusion: DUSTrack是一个开源工具，为临床和生物力学研究提供了强大的组织运动量化框架。

Abstract: Ultrasound technology enables safe, non-invasive imaging of dynamic tissue
behavior, making it a valuable tool in medicine, biomechanics, and sports
science. However, accurately tracking tissue motion in B-mode ultrasound
remains challenging due to speckle noise, low edge contrast, and out-of-plane
movement. These challenges complicate the task of tracking anatomical landmarks
over time, which is essential for quantifying tissue dynamics in many clinical
and research applications. This manuscript introduces DUSTrack (Deep learning
and optical flow-based toolkit for UltraSound Tracking), a semi-automated
framework for tracking arbitrary points in B-mode ultrasound videos. We combine
deep learning with optical flow to deliver high-quality and robust tracking
across diverse anatomical structures and motion patterns. The toolkit includes
a graphical user interface that streamlines the generation of high-quality
training data and supports iterative model refinement. It also implements a
novel optical-flow-based filtering technique that reduces high-frequency
frame-to-frame noise while preserving rapid tissue motion. DUSTrack
demonstrates superior accuracy compared to contemporary zero-shot point
trackers and performs on par with specialized methods, establishing its
potential as a general and foundational tool for clinical and biomechanical
research. We demonstrate DUSTrack's versatility through three use cases:
cardiac wall motion tracking in echocardiograms, muscle deformation analysis
during reaching tasks, and fascicle tracking during ankle plantarflexion. As an
open-source solution, DUSTrack offers a powerful, flexible framework for point
tracking to quantify tissue motion from ultrasound videos. DUSTrack is
available at https://github.com/praneethnamburi/DUSTrack.

</details>


### [14] [CRAFT: A Neuro-Symbolic Framework for Visual Functional Affordance Grounding](https://arxiv.org/abs/2507.14426)
*Zhou Chen,Joe Lin,Sathyanarayanan N. Aakur*

Main category: cs.CV

TL;DR: CRAFT是一个神经符号框架，用于可解释的affordance grounding，通过整合常识先验和视觉证据，提升场景理解的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决场景理解中affordance grounding的透明性和鲁棒性问题。

Method: 结合ConceptNet和语言模型的常识先验与CLIP的视觉证据，通过基于能量的推理循环迭代优化预测。

Result: 在多对象、无标签设置下，CRAFT提高了准确性和可解释性。

Conclusion: CRAFT为鲁棒且可信的场景理解提供了新方向。

Abstract: We introduce CRAFT, a neuro-symbolic framework for interpretable affordance
grounding, which identifies the objects in a scene that enable a given action
(e.g., "cut"). CRAFT integrates structured commonsense priors from ConceptNet
and language models with visual evidence from CLIP, using an energy-based
reasoning loop to refine predictions iteratively. This process yields
transparent, goal-driven decisions to ground symbolic and perceptual
structures. Experiments in multi-object, label-free settings demonstrate that
CRAFT enhances accuracy while improving interpretability, providing a step
toward robust and trustworthy scene understanding.

</details>


### [15] [Adaptive 3D Gaussian Splatting Video Streaming](https://arxiv.org/abs/2507.14432)
*Han Gong,Qiyue Li,Zhi Liu,Hao Zhou,Peng Yuan Zhou,Zhu Li,Jie Li*

Main category: cs.CV

TL;DR: 提出了一种基于高斯变形场的3DGS视频流框架，通过混合显著性分块和差异化质量建模，实现了高效压缩和带宽适应。


<details>
  <summary>Details</summary>
Motivation: 3DGS视频数据量大且传输复杂，传统方法难以满足需求。

Method: 设计基于高斯变形场的3DGS视频构建方法，结合混合显著性分块和差异化质量建模。

Result: 实验验证了该方法在视频质量、压缩效率和传输速率上的优越性。

Conclusion: 该框架有效解决了3DGS视频流传输的挑战，性能优于现有方法。

Abstract: The advent of 3D Gaussian splatting (3DGS) has significantly enhanced the
quality of volumetric video representation. Meanwhile, in contrast to
conventional volumetric video, 3DGS video poses significant challenges for
streaming due to its substantially larger data volume and the heightened
complexity involved in compression and transmission. To address these issues,
we introduce an innovative framework for 3DGS volumetric video streaming.
Specifically, we design a 3DGS video construction method based on the Gaussian
deformation field. By employing hybrid saliency tiling and differentiated
quality modeling of 3DGS video, we achieve efficient data compression and
adaptation to bandwidth fluctuations while ensuring high transmission quality.
Then we build a complete 3DGS video streaming system and validate the
transmission performance. Through experimental evaluation, our method
demonstrated superiority over existing approaches in various aspects, including
video quality, compression effectiveness, and transmission rate.

</details>


### [16] [IRGPT: Understanding Real-world Infrared Image with Bi-cross-modal Curriculum on Large-scale Benchmark](https://arxiv.org/abs/2507.14449)
*Zhe Cao,Jin Zhang,Ruiheng Zhang*

Main category: cs.CV

TL;DR: IRGPT是首个针对真实世界红外图像的多模态大语言模型，基于大规模红外-文本数据集（IR-TD），通过双向跨模态课程迁移学习策略，在9个任务上实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖合成红外图像的局限性，以及真实红外图像与文本对齐数据稀缺的问题。

Method: 构建IR-TD数据集（26万真实红外图像-文本对），提出双向跨模态课程迁移学习策略，从可见光到红外域逐步迁移知识。

Result: 在9个任务（如识别、定位）上达到最先进性能，优于更大规模的模型。

Conclusion: IRGPT通过真实数据集和创新学习策略，显著提升了红外图像的多模态理解能力。

Abstract: Real-world infrared imagery presents unique challenges for vision-language
models due to the scarcity of aligned text data and domain-specific
characteristics. Although existing methods have advanced the field, their
reliance on synthetic infrared images generated through style transfer from
visible images, which limits their ability to capture the unique
characteristics of the infrared modality. To address this, we propose IRGPT,
the first multi-modal large language model for real-world infrared images,
built upon a large-scale InfraRed-Text Dataset (IR-TD) comprising over 260K
authentic image-text pairs. The proposed IR-TD dataset contains real infrared
images paired with meticulously handcrafted texts, where the initial drafts
originated from two complementary processes: (1) LLM-generated descriptions of
visible images, and (2) rule-based descriptions of annotations. Furthermore, we
introduce a bi-cross-modal curriculum transfer learning strategy that
systematically transfers knowledge from visible to infrared domains by
considering the difficulty scores of both infrared-visible and infrared-text.
Evaluated on a benchmark of 9 tasks (e.g., recognition, grounding), IRGPT
achieves state-of-the-art performance even compared with larger-scale models.

</details>


### [17] [GPI-Net: Gestalt-Guided Parallel Interaction Network via Orthogonal Geometric Consistency for Robust Point Cloud Registration](https://arxiv.org/abs/2507.14452)
*Weikang Gu,Mingyue Han,Li Xue,Heng Dong,Changcai Yang,Riqing Chen,Lifang Wei*

Main category: cs.CV

TL;DR: 提出了一种基于Gestalt原则的并行交互网络（GPI-Net），用于点云配准中高质量对应关系的识别。


<details>
  <summary>Details</summary>
Motivation: 解决局部和全局特征融合中的特征冗余和复杂空间关系问题。

Method: 利用Gestalt原则设计正交几何一致性策略，结合Gestalt特征注意力块（GFA）和双路径多粒度并行交互聚合块（DMG）。

Result: 在多个挑战性任务中表现优于现有方法。

Conclusion: GPI-Net通过Gestalt原则优化了局部与全局信息的互补性，提升了点云配准的准确性。

Abstract: The accurate identification of high-quality correspondences is a prerequisite
task in feature-based point cloud registration. However, it is extremely
challenging to handle the fusion of local and global features due to feature
redundancy and complex spatial relationships. Given that Gestalt principles
provide key advantages in analyzing local and global relationships, we propose
a novel Gestalt-guided Parallel Interaction Network via orthogonal geometric
consistency (GPI-Net) in this paper. It utilizes Gestalt principles to
facilitate complementary communication between local and global information.
Specifically, we introduce an orthogonal integration strategy to optimally
reduce redundant information and generate a more compact global structure for
high-quality correspondences. To capture geometric features in correspondences,
we leverage a Gestalt Feature Attention (GFA) block through a hybrid
utilization of self-attention and cross-attention mechanisms. Furthermore, to
facilitate the integration of local detail information into the global
structure, we design an innovative Dual-path Multi-Granularity parallel
interaction aggregation (DMG) block to promote information exchange across
different granularities. Extensive experiments on various challenging tasks
demonstrate the superior performance of our proposed GPI-Net in comparison to
existing methods. The code will be released at https://github.com/gwk/GPI-Net.

</details>


### [18] [Adaptive 3D Gaussian Splatting Video Streaming: Visual Saliency-Aware Tiling and Meta-Learning-Based Bitrate Adaptation](https://arxiv.org/abs/2507.14454)
*Han Gong,Qiyue Li,Jie Li,Zhi Liu*

Main category: cs.CV

TL;DR: 本文提出了一种基于显著性分析的自适应3DGS分块技术、新的3DGS视频质量评估框架以及基于元学习的自适应码率算法，显著提升了3DGS视频流的表现。


<details>
  <summary>Details</summary>
Motivation: 3DGS视频流在提供沉浸式3D体验方面表现出色，但仍面临分块、质量评估和码率适应等挑战，需要进一步研究。

Method: 提出自适应3DGS分块技术（结合空间和时间特征）、3DGS视频质量评估框架（联合评估3DGS表示和2D渲染图像质量）和基于元学习的自适应码率算法。

Result: 实验表明，所提方法显著优于现有技术。

Conclusion: 本文提出的解决方案有效解决了3DGS视频流中的关键问题，提升了性能和用户体验。

Abstract: 3D Gaussian splatting video (3DGS) streaming has recently emerged as a
research hotspot in both academia and industry, owing to its impressive ability
to deliver immersive 3D video experiences. However, research in this area is
still in its early stages, and several fundamental challenges, such as tiling,
quality assessment, and bitrate adaptation, require further investigation. In
this paper, we tackle these challenges by proposing a comprehensive set of
solutions. Specifically, we propose an adaptive 3DGS tiling technique guided by
saliency analysis, which integrates both spatial and temporal features. Each
tile is encoded into versions possessing dedicated deformation fields and
multiple quality levels for adaptive selection. We also introduce a novel
quality assessment framework for 3DGS video that jointly evaluates
spatial-domain degradation in 3DGS representations during streaming and the
quality of the resulting 2D rendered images. Additionally, we develop a
meta-learning-based adaptive bitrate algorithm specifically tailored for 3DGS
video streaming, achieving optimal performance across varying network
conditions. Extensive experiments demonstrate that our proposed approaches
significantly outperform state-of-the-art methods.

</details>


### [19] [GEMINUS: Dual-aware Global and Scene-Adaptive Mixture-of-Experts for End-to-End Autonomous Driving](https://arxiv.org/abs/2507.14456)
*Chi Wan,Yixin Cui,Jiatong Du,Shuo Yang,Yulong Bai,Yanjun Huang*

Main category: cs.CV

TL;DR: GEMINUS是一种基于混合专家（Mixture-of-Experts）的端到端自动驾驶框架，通过全局专家、场景自适应专家组和双感知路由器实现多样场景下的自适应和鲁棒性能。


<details>
  <summary>Details</summary>
Motivation: 现有单模式规划方法难以处理复杂多样的交通场景，需要一种能够学习多样化驾驶技能的方法。

Method: 提出GEMINUS框架，包含全局专家、场景自适应专家组和双感知路由器，动态激活专家模块。

Result: 在Bench2Drive基准测试中表现优异，驾驶分数和成功率均达到最优，单目视觉输入下仍有显著提升。

Conclusion: GEMINUS通过混合专家方法显著提升了自动驾驶的适应性和鲁棒性，优于现有方法。

Abstract: End-to-end autonomous driving requires adaptive and robust handling of
complex and diverse traffic environments. However, prevalent single-mode
planning methods attempt to learn an overall policy while struggling to acquire
diversified driving skills to handle diverse scenarios. Therefore, this paper
proposes GEMINUS, a Mixture-of-Experts end-to-end autonomous driving framework
featuring a Global Expert, a Scene-Adaptive Experts Group, and equipped with a
Dual-aware Router. Specifically, the Global Expert is trained on the overall
dataset, possessing robust performance. The Scene-Adaptive Experts are trained
on corresponding scene subsets, achieving adaptive performance. The Dual-aware
Router simultaneously considers scenario-level features and routing uncertainty
to dynamically activate expert modules. Through the effective coupling of the
Global Expert and the Scene-Adaptive Experts Group via the Dual-aware Router,
GEMINUS achieves adaptive and robust performance in diverse scenarios. GEMINUS
outperforms existing methods in the Bench2Drive closed-loop benchmark and
achieves state-of-the-art performance in Driving Score and Success Rate, even
with only monocular vision input. Furthermore, ablation studies demonstrate
significant improvements over the original single-expert baseline: 7.67% in
Driving Score, 22.06% in Success Rate, and 19.41% in MultiAbility-Mean. The
code will be available at https://github.com/newbrains1/GEMINUS.

</details>


### [20] [VisGuard: Securing Visualization Dissemination through Tamper-Resistant Data Retrieval](https://arxiv.org/abs/2507.14459)
*Huayuan Ye,Juntong Chen,Shenzhuo Zhang,Yipeng Zhang,Changbo Wang,Chenhui Li*

Main category: cs.CV

TL;DR: VisGuard是一种抗篡改的可视化图像数据检索框架，通过嵌入元数据链接解决现有方法在图像裁剪和编辑时的脆弱性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在可视化图像传播中容易因裁剪和编辑丢失元数据，缺乏实用性。

Method: VisGuard采用重复数据平铺、可逆信息广播和基于锚点的裁剪定位技术，增强嵌入数据的鲁棒性。

Result: 实验表明VisGuard在数据检索准确性、嵌入容量和抗篡改安全性方面表现优异。

Conclusion: VisGuard能有效保护和促进可视化传播及信息传递。

Abstract: The dissemination of visualizations is primarily in the form of raster
images, which often results in the loss of critical information such as source
code, interactive features, and metadata. While previous methods have proposed
embedding metadata into images to facilitate Visualization Image Data Retrieval
(VIDR), most existing methods lack practicability since they are fragile to
common image tampering during online distribution such as cropping and editing.
To address this issue, we propose VisGuard, a tamper-resistant VIDR framework
that reliably embeds metadata link into visualization images. The embedded data
link remains recoverable even after substantial tampering upon images. We
propose several techniques to enhance robustness, including repetitive data
tiling, invertible information broadcasting, and an anchor-based scheme for
crop localization. VisGuard enables various applications, including interactive
chart reconstruction, tampering detection, and copyright protection. We conduct
comprehensive experiments on VisGuard's superior performance in data retrieval
accuracy, embedding capacity, and security against tampering and steganalysis,
demonstrating VisGuard's competence in facilitating and safeguarding
visualization dissemination and information conveyance.

</details>


### [21] [OptiCorNet: Optimizing Sequence-Based Context Correlation for Visual Place Recognition](https://arxiv.org/abs/2507.14477)
*Zhenyu Li,Tianyi Shang,Pengjie Xu,Ruirui Zhang,Fanchen Kong*

Main category: cs.CV

TL;DR: OptiCorNet是一个新颖的序列建模框架，通过结合空间特征提取和时间差分，解决了动态和感知混淆环境中的视觉地点识别问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法主要关注单帧嵌入，忽略了图像序列中的时间连贯性，导致在动态和感知混淆环境中的地点识别效果不佳。

Method: OptiCorNet采用轻量级1D卷积编码器和可学习的差分时间算子（DSD），结合LSTM精炼和四元组损失函数，直接学习序列级嵌入。

Result: 在多个公开基准测试中，OptiCorNet在季节和视角变化挑战下优于现有方法。

Conclusion: OptiCorNet通过端到端学习序列级嵌入，显著提升了动态和感知混淆环境中的视觉地点识别性能。

Abstract: Visual Place Recognition (VPR) in dynamic and perceptually aliased
environments remains a fundamental challenge for long-term localization.
Existing deep learning-based solutions predominantly focus on single-frame
embeddings, neglecting the temporal coherence present in image sequences. This
paper presents OptiCorNet, a novel sequence modeling framework that unifies
spatial feature extraction and temporal differencing into a differentiable,
end-to-end trainable module. Central to our approach is a lightweight 1D
convolutional encoder combined with a learnable differential temporal operator,
termed Differentiable Sequence Delta (DSD), which jointly captures short-term
spatial context and long-range temporal transitions. The DSD module models
directional differences across sequences via a fixed-weight differencing
kernel, followed by an LSTM-based refinement and optional residual projection,
yielding compact, discriminative descriptors robust to viewpoint and appearance
shifts. To further enhance inter-class separability, we incorporate a
quadruplet loss that optimizes both positive alignment and multi-negative
divergence within each batch. Unlike prior VPR methods that treat temporal
aggregation as post-processing, OptiCorNet learns sequence-level embeddings
directly, enabling more effective end-to-end place recognition. Comprehensive
evaluations on multiple public benchmarks demonstrate that our approach
outperforms state-of-the-art baselines under challenging seasonal and viewpoint
variations.

</details>


### [22] [DFQ-ViT: Data-Free Quantization for Vision Transformers without Fine-tuning](https://arxiv.org/abs/2507.14481)
*Yujia Tong,Jingling Yuan,Tian Zhang,Jianquan Liu,Chuang Hu*

Main category: cs.CV

TL;DR: DFQ-ViT提出了一种无需数据的ViT量化方法，通过合成样本和激活校正矩阵提升量化模型性能，性能接近真实数据量化模型。


<details>
  <summary>Details</summary>
Motivation: 现有DFQ方法无法充分平衡合成样本的全局和局部特征，且量化模型与全精度模型的中间层激活分布差异大，导致性能下降。

Method: 按难度递增顺序合成样本，并引入激活校正矩阵对齐量化与全精度模型的中间层激活。

Result: DFQ-ViT性能显著优于现有DFQ方法，3位量化DeiT-T性能提升4.29%，无需微调。

Conclusion: DFQ-ViT降低了计算开销和部署门槛，符合绿色学习原则，适用于资源受限环境。

Abstract: Data-Free Quantization (DFQ) enables the quantization of Vision Transformers
(ViTs) without requiring access to data, allowing for the deployment of ViTs on
devices with limited resources. In DFQ, the quantization model must be
calibrated using synthetic samples, making the quality of these synthetic
samples crucial. Existing methods fail to fully capture and balance the global
and local features within the samples, resulting in limited synthetic data
quality. Moreover, we have found that during inference, there is a significant
difference in the distributions of intermediate layer activations between the
quantized and full-precision models. These issues lead to a severe performance
degradation of the quantized model. To address these problems, we propose a
pipeline for Data-Free Quantization for Vision Transformers (DFQ-ViT).
Specifically, we synthesize samples in order of increasing difficulty,
effectively enhancing the quality of synthetic data. During the calibration and
inference stage, we introduce the activation correction matrix for the
quantized model to align the intermediate layer activations with those of the
full-precision model. Extensive experiments demonstrate that DFQ-ViT achieves
remarkable superiority over existing DFQ methods and its performance is on par
with models quantized through real data. For example, the performance of DeiT-T
with 3-bit weights quantization is 4.29% higher than the state-of-the-art. Our
method eliminates the need for fine-tuning, which not only reduces
computational overhead but also lowers the deployment barriers for edge
devices. This characteristic aligns with the principles of Green Learning by
improving energy efficiency and facilitating real-world applications in
resource-constrained environments.

</details>


### [23] [Benefit from Reference: Retrieval-Augmented Cross-modal Point Cloud Completion](https://arxiv.org/abs/2507.14485)
*Hongye Hou,Liu Zhan,Yang Yang*

Main category: cs.CV

TL;DR: 提出了一种基于检索增强的点云补全框架，通过跨模态检索学习结构先验信息，生成细粒度点云。


<details>
  <summary>Details</summary>
Motivation: 解决不完整点云补全任务中缺乏典型结构特征的挑战，现有方法局限于特定输入类别。

Method: 设计了结构共享特征编码器（SSFE）和渐进检索增强生成器（PRAG），结合跨模态检索和层次特征融合。

Result: 在多个数据集和真实场景中验证了方法的有效性，尤其在稀疏数据和未见类别上表现优异。

Conclusion: 该方法通过学习参考样本的结构先验信息，显著提升了点云补全的生成能力和泛化能力。

Abstract: Completing the whole 3D structure based on an incomplete point cloud is a
challenging task, particularly when the residual point cloud lacks typical
structural characteristics. Recent methods based on cross-modal learning
attempt to introduce instance images to aid the structure feature learning.
However, they still focus on each particular input class, limiting their
generation abilities. In this work, we propose a novel retrieval-augmented
point cloud completion framework. The core idea is to incorporate cross-modal
retrieval into completion task to learn structural prior information from
similar reference samples. Specifically, we design a Structural Shared Feature
Encoder (SSFE) to jointly extract cross-modal features and reconstruct
reference features as priors. Benefiting from a dual-channel control gate in
the encoder, relevant structural features in the reference sample are enhanced
and irrelevant information interference is suppressed. In addition, we propose
a Progressive Retrieval-Augmented Generator (PRAG) that employs a hierarchical
feature fusion mechanism to integrate reference prior information with input
features from global to local. Through extensive evaluations on multiple
datasets and real-world scenes, our method shows its effectiveness in
generating fine-grained point clouds, as well as its generalization capability
in handling sparse data and unseen categories.

</details>


### [24] [Efficient Whole Slide Pathology VQA via Token Compression](https://arxiv.org/abs/2507.14497)
*Weimin Lyu,Qingqiao Hu,Kehan Qi,Zhan Shi,Wentao Huang,Saumya Gupta,Chao Chen*

Main category: cs.CV

TL;DR: TCP-LLaVA是一种新型多模态大语言模型，通过令牌压缩技术解决病理学全切片图像（WSI）的视觉问答（VQA）问题，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 病理学全切片图像（WSI）的高分辨率和长上下文长度对多模态大语言模型（MLLM）提出了巨大挑战，现有方法在生成能力和资源消耗方面存在不足。

Method: 提出TCP-LLaVA，通过可训练的压缩令牌和模态压缩模块聚合视觉与文本信息，仅将压缩后的令牌输入语言模型生成答案。

Result: 在十种TCGA肿瘤亚型的实验中，TCP-LLaVA在VQA准确率上优于现有MLLM基线，同时大幅减少训练资源消耗。

Conclusion: TCP-LLaVA通过令牌压缩技术有效解决了WSI的VQA问题，为高分辨率图像的多模态分析提供了高效解决方案。

Abstract: Whole-slide images (WSIs) in pathology can reach up to 10,000 x 10,000
pixels, posing significant challenges for multimodal large language model
(MLLM) due to long context length and high computational demands. Previous
methods typically focus on patch-level analysis or slide-level classification
using CLIP-based models with multi-instance learning, but they lack the
generative capabilities needed for visual question answering (VQA). More recent
MLLM-based approaches address VQA by feeding thousands of patch tokens directly
into the language model, which leads to excessive resource consumption. To
address these limitations, we propose Token Compression Pathology LLaVA
(TCP-LLaVA), the first MLLM architecture to perform WSI VQA via token
compression. TCP-LLaVA introduces a set of trainable compression tokens that
aggregate visual and textual information through a modality compression module,
inspired by the [CLS] token mechanism in BERT. Only the compressed tokens are
forwarded to the LLM for answer generation, significantly reducing input length
and computational cost. Experiments on ten TCGA tumor subtypes show that
TCP-LLaVA outperforms existing MLLM baselines in VQA accuracy while reducing
training resource consumption by a substantial margin.

</details>


### [25] [Motion Segmentation and Egomotion Estimation from Event-Based Normal Flow](https://arxiv.org/abs/2507.14500)
*Zhiyuan Hua,Dehao Yuan,Cornelia Fermüller*

Main category: cs.CV

TL;DR: 提出了一种基于事件法向流的运动分割与自运动估计框架，适用于神经形态视觉传感器，无需完整光流计算即可实现高精度。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖光流或深度估计，而神经形态传感器的事件数据稀疏且时间分辨率高，需要新方法。

Method: 利用几何约束结合法向流、场景结构和惯性测量，通过优化流程进行事件过分割、残差分析分离运动物体，并基于运动相似性和时间一致性进行层次聚类。

Result: 在EVIMO2v2数据集上验证了方法的准确性，尤其在物体边界表现优异。

Conclusion: 该方法在实时机器人及导航应用中具有显著潜力。

Abstract: This paper introduces a robust framework for motion segmentation and
egomotion estimation using event-based normal flow, tailored specifically for
neuromorphic vision sensors. In contrast to traditional methods that rely
heavily on optical flow or explicit depth estimation, our approach exploits the
sparse, high-temporal-resolution event data and incorporates geometric
constraints between normal flow, scene structure, and inertial measurements.
The proposed optimization-based pipeline iteratively performs event
over-segmentation, isolates independently moving objects via residual analysis,
and refines segmentations using hierarchical clustering informed by motion
similarity and temporal consistency. Experimental results on the EVIMO2v2
dataset validate that our method achieves accurate segmentation and
translational motion estimation without requiring full optical flow
computation. This approach demonstrates significant advantages at object
boundaries and offers considerable potential for scalable, real-time robotic
and navigation applications.

</details>


### [26] [Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey](https://arxiv.org/abs/2507.14501)
*Jiahui Zhang,Yuelei Li,Anpei Chen,Muyu Xu,Kunhao Liu,Jianyuan Wang,Xiao-Xiao Long,Hanxue Liang,Zexiang Xu,Hao Su,Christian Theobalt,Christian Rupprecht,Andrea Vedaldi,Hanspeter Pfister,Shijian Lu,Fangneng Zhan*

Main category: cs.CV

TL;DR: 综述了基于前馈方法的3D重建和视图合成技术，分类讨论了不同表示架构，并探讨了其应用、数据集和未来方向。


<details>
  <summary>Details</summary>
Motivation: 传统方法计算复杂且难以实时应用，深度学习驱动的前馈方法提供了快速且通用的解决方案。

Method: 分类讨论了点云、3D高斯泼溅、神经辐射场等表示架构，并分析了关键任务如无姿态重建和动态3D重建。

Result: 前馈方法显著提升了3D重建和视图合成的效率和通用性，广泛应用于数字人、SLAM等领域。

Conclusion: 前馈方法潜力巨大，但仍需解决开放挑战以推动3D视觉技术的进一步发展。

Abstract: 3D reconstruction and view synthesis are foundational problems in computer
vision, graphics, and immersive technologies such as augmented reality (AR),
virtual reality (VR), and digital twins. Traditional methods rely on
computationally intensive iterative optimization in a complex chain, limiting
their applicability in real-world scenarios. Recent advances in feed-forward
approaches, driven by deep learning, have revolutionized this field by enabling
fast and generalizable 3D reconstruction and view synthesis. This survey offers
a comprehensive review of feed-forward techniques for 3D reconstruction and
view synthesis, with a taxonomy according to the underlying representation
architectures including point cloud, 3D Gaussian Splatting (3DGS), Neural
Radiance Fields (NeRF), etc. We examine key tasks such as pose-free
reconstruction, dynamic 3D reconstruction, and 3D-aware image and video
synthesis, highlighting their applications in digital humans, SLAM, robotics,
and beyond. In addition, we review commonly used datasets with detailed
statistics, along with evaluation protocols for various downstream tasks. We
conclude by discussing open research challenges and promising directions for
future work, emphasizing the potential of feed-forward approaches to advance
the state of the art in 3D vision.

</details>


### [27] [DCHM: Depth-Consistent Human Modeling for Multiview Detection](https://arxiv.org/abs/2507.14505)
*Jiahao Ma,Tianyu Wang,Miaomiao Liu,David Ahmedt-Aristizabal,Chuong Nguyen*

Main category: cs.CV

TL;DR: 提出了一种名为DCHM的框架，通过深度一致性建模和多视角融合，显著减少了噪声并提高了行人检测的精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多视角行人检测中噪声大、精度低，且依赖昂贵的3D标注，难以泛化到多样化场景。

Method: 采用深度一致性人类建模（DCHM）框架，结合超像素级高斯泼溅技术，实现多视角深度一致性和精确点云生成。

Result: 实验表明，DCHM显著减少了噪声，优于现有方法，并在稀疏视角、大规模和拥挤场景中首次实现了行人重建和多视角分割。

Conclusion: DCHM无需依赖人工标注，在多视角行人检测中表现出色，为复杂场景提供了有效解决方案。

Abstract: Multiview pedestrian detection typically involves two stages: human modeling
and pedestrian localization. Human modeling represents pedestrians in 3D space
by fusing multiview information, making its quality crucial for detection
accuracy. However, existing methods often introduce noise and have low
precision. While some approaches reduce noise by fitting on costly multiview 3D
annotations, they often struggle to generalize across diverse scenes. To
eliminate reliance on human-labeled annotations and accurately model humans, we
propose Depth-Consistent Human Modeling (DCHM), a framework designed for
consistent depth estimation and multiview fusion in global coordinates.
Specifically, our proposed pipeline with superpixel-wise Gaussian Splatting
achieves multiview depth consistency in sparse-view, large-scaled, and crowded
scenarios, producing precise point clouds for pedestrian localization.
Extensive validations demonstrate that our method significantly reduces noise
during human modeling, outperforming previous state-of-the-art baselines.
Additionally, to our knowledge, DCHM is the first to reconstruct pedestrians
and perform multiview segmentation in such a challenging setting. Code is
available on the \href{https://jiahao-ma.github.io/DCHM/}{project page}.

</details>


### [28] [ArtiMuse: Fine-Grained Image Aesthetics Assessment with Joint Scoring and Expert-Level Understanding](https://arxiv.org/abs/2507.14533)
*Shuo Cao,Nan Ma,Jiayang Li,Xiaohui Li,Lihao Shao,Kaiwen Zhu,Yu Zhou,Yuandong Pu,Jiarui Wu,Jiaquan Wang,Bo Qu,Wenhai Wang,Yu Qiao,Dajuin Yao,Yihao Liu*

Main category: cs.CV

TL;DR: 提出了一种基于多模态大语言模型的图像美学评估方法ArtiMuse，解决了传统方法的模态偏差问题，并发布了首个专家标注的数据集ArtiMuse-10K。


<details>
  <summary>Details</summary>
Motivation: 随着教育应用、艺术创作和AI生成内容的发展，对图像美学评估的需求增加，但现有方法存在模态偏差和缺乏细粒度属性分析的问题。

Method: 提出了ArtiMuse模型，具备联合评分和专家级理解能力，并构建了ArtiMuse-10K数据集，包含10,000张图像，标注了8维属性和整体评分。

Result: ArtiMuse模型在美学评估中表现出更强的感知和泛化能力，解决了传统方法的局限性。

Conclusion: ArtiMuse模型和数据集将公开，以推动图像美学评估领域的发展。

Abstract: The rapid advancement of educational applications, artistic creation, and
AI-generated content (AIGC) technologies has substantially increased practical
requirements for comprehensive Image Aesthetics Assessment (IAA), particularly
demanding methods capable of delivering both quantitative scoring and
professional understanding. Multimodal Large Language Model (MLLM)-based IAA
methods demonstrate stronger perceptual and generalization capabilities
compared to traditional approaches, yet they suffer from modality bias
(score-only or text-only) and lack fine-grained attribute decomposition,
thereby failing to support further aesthetic assessment. In this paper, we
present:(1) ArtiMuse, an innovative MLLM-based IAA model with Joint Scoring and
Expert-Level Understanding capabilities; (2) ArtiMuse-10K, the first
expert-curated image aesthetic dataset comprising 10,000 images spanning 5 main
categories and 15 subcategories, each annotated by professional experts with
8-dimensional attributes analysis and a holistic score. Both the model and
dataset will be made public to advance the field.

</details>


### [29] [Real Time Captioning of Sign Language Gestures in Video Meetings](https://arxiv.org/abs/2507.14543)
*Sharanya Mukherjee,Md Hishaam Akhtar,Kannadasan R*

Main category: cs.CV

TL;DR: 提出一种浏览器扩展，通过计算机视觉将手语实时翻译为字幕，帮助听障人士在视频会议中更顺畅地交流。


<details>
  <summary>Details</summary>
Motivation: 听障人士与普通人之间的沟通存在障碍，尤其在疫情期间视频会议成为主流时，手语翻译的需求更加迫切。

Method: 使用大规模数据集（2000多个单词级ASL视频，由100多名手语者完成），开发浏览器扩展实现手语到字幕的自动翻译。

Result: 通过计算机视觉技术，实现了手语的实时翻译，为视频会议提供了无障碍交流工具。

Conclusion: 该浏览器扩展有望显著改善听障人士在视频会议中的沟通体验。

Abstract: It has always been a rather tough task to communicate with someone possessing
a hearing impairment. One of the most tested ways to establish such a
communication is through the use of sign based languages. However, not many
people are aware of the smaller intricacies involved with sign language. Sign
language recognition using computer vision aims at eliminating the
communication barrier between deaf-mute and ordinary people so that they can
properly communicate with others. Recently the pandemic has left the whole
world shaken up and has transformed the way we communicate. Video meetings have
become essential for everyone, even people with a hearing disability. In recent
studies, it has been found that people with hearing disabilities prefer to sign
over typing during these video calls. In this paper, we are proposing a browser
extension that will automatically translate sign language to subtitles for
everyone else in the video call. The Large-scale dataset which contains more
than 2000 Word-Level ASL videos, which were performed by over 100 signers will
be used.

</details>


### [30] [Multimodal AI for Gastrointestinal Diagnostics: Tackling VQA in MEDVQA-GI 2025](https://arxiv.org/abs/2507.14544)
*Sujata Gaihre,Amir Thapa Magar,Prasuna Pokharel,Laxmi Tiwari*

Main category: cs.CV

TL;DR: 本文介绍了基于Florence模型的医学视觉问答方法，在ImageCLEFmed MEDVQA 2025挑战赛中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决胃肠道内窥镜视觉问答任务，提升医学VQA的准确性和泛化能力。

Method: 采用Florence多模态基础模型，结合领域特定的数据增强技术。

Result: 在KASVIR数据集上微调Florence模型，取得了官方挑战指标的优异表现。

Conclusion: 展示了大型多模态模型在医学VQA中的潜力，为未来研究提供了基线。

Abstract: This paper describes our approach to Subtask 1 of the ImageCLEFmed MEDVQA
2025 Challenge, which targets visual question answering (VQA) for
gastrointestinal endoscopy. We adopt the Florence model-a large-scale
multimodal foundation model-as the backbone of our VQA pipeline, pairing a
powerful vision encoder with a text encoder to interpret endoscopic images and
produce clinically relevant answers. To improve generalization, we apply
domain-specific augmentations that preserve medical features while increasing
training diversity. Experiments on the KASVIR dataset show that fine-tuning
Florence yields accurate responses on the official challenge metrics. Our
results highlight the potential of large multimodal models in medical VQA and
provide a strong baseline for future work on explainability, robustness, and
clinical integration. The code is publicly available at:
https://github.com/TiwariLaxuu/VQA-Florence.git

</details>


### [31] [Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering Human Perceptual Variability on Facial Expressions](https://arxiv.org/abs/2507.14549)
*Haotian Deng,Chi Zhang,Chen Wei,Quanying Liu*

Main category: cs.CV

TL;DR: 研究探讨了人工神经网络（ANN）与人类情感感知之间的关系，发现ANN分类模糊的刺激同样引发人类感知差异，并通过行为数据优化ANN模型，使其与人类感知模式对齐。


<details>
  <summary>Details</summary>
Motivation: 解决情感认知科学中外部情感刺激与人类内部体验关系建模的挑战，特别是探索ANN在捕捉个体感知差异方面的潜力。

Method: 提出一种新颖的感知边界采样方法，生成位于ANN决策边界的面部表情刺激，构建varEmotion数据集，并通过大规模人类行为实验验证。

Result: 发现ANN分类模糊的刺激同样引发人类感知不确定性，通过行为数据微调ANN模型，使其与人类群体及个体感知模式对齐。

Conclusion: 建立了ANN决策边界与人类感知变异性之间的系统性联系，为情感解释的个性化建模提供了新见解。

Abstract: A fundamental challenge in affective cognitive science is to develop models
that accurately capture the relationship between external emotional stimuli and
human internal experiences. While ANNs have demonstrated remarkable accuracy in
facial expression recognition, their ability to model inter-individual
differences in human perception remains underexplored. This study investigates
the phenomenon of high perceptual variability-where individuals exhibit
significant differences in emotion categorization even when viewing the same
stimulus. Inspired by the similarity between ANNs and human perception, we
hypothesize that facial expression samples that are ambiguous for ANN
classifiers also elicit divergent perceptual judgments among human observers.
To examine this hypothesis, we introduce a novel perceptual boundary sampling
method to generate facial expression stimuli that lie along ANN decision
boundaries. These ambiguous samples form the basis of the varEmotion dataset,
constructed through large-scale human behavioral experiments. Our analysis
reveals that these ANN-confusing stimuli also provoke heightened perceptual
uncertainty in human participants, highlighting shared computational principles
in emotion perception. Finally, by fine-tuning ANN representations using
behavioral data, we achieve alignment between ANN predictions and both
group-level and individual-level human perceptual patterns. Our findings
establish a systematic link between ANN decision boundaries and human
perceptual variability, offering new insights into personalized modeling of
emotional interpretation.

</details>


### [32] [Clutter Detection and Removal by Multi-Objective Analysis for Photographic Guidance](https://arxiv.org/abs/2507.14553)
*Xiaoran Wu*

Main category: cs.CV

TL;DR: 该论文提出了一种相机引导系统，帮助摄影爱好者识别和去除照片中的杂乱内容，通过美学评估和图像修复算法提升照片质量。


<details>
  <summary>Details</summary>
Motivation: 照片中的杂乱内容会分散注意力，影响情感或故事的传达。业余摄影师由于经验不足或疏忽，常会拍摄杂乱场景，因此需要一种系统来指导他们识别和去除杂乱。

Method: 系统通过美学评估算法区分杂乱对象，并基于生成对抗网络的迭代图像修复算法去除杂乱对象。同时提供交互式工具和建议。

Result: 用户研究表明，该系统能帮助用户更高效地识别杂乱内容，并在更短时间内拍摄出更高质量的照片。

Conclusion: 该系统通过灵活界面和准确算法，有效解决了照片杂乱问题，提升了摄影作品的质量。

Abstract: Clutter in photos is a distraction preventing photographers from conveying
the intended emotions or stories to the audience. Photography amateurs
frequently include clutter in their photos due to unconscious negligence or the
lack of experience in creating a decluttered, aesthetically appealing scene for
shooting. We are thus motivated to develop a camera guidance system that
provides solutions and guidance for clutter identification and removal. We
estimate and visualize the contribution of objects to the overall aesthetics
and content of a photo, based on which users can interactively identify
clutter. Suggestions on getting rid of clutter, as well as a tool that removes
cluttered objects computationally, are provided to guide users to deal with
different kinds of clutter and improve their photographic work. Two technical
novelties underpin interactions in our system: a clutter distinguishment
algorithm with aesthetics evaluations for objects and an iterative image
inpainting algorithm based on generative adversarial nets that reconstructs
missing regions of removed objects for high-resolution images. User studies
demonstrate that our system provides flexible interfaces and accurate
algorithms that allow users to better identify distractions and take higher
quality images within less time.

</details>


### [33] [Descrip3D: Enhancing Large Language Model-based 3D Scene Understanding with Object-Level Text Descriptions](https://arxiv.org/abs/2507.14555)
*Jintang Xue,Ganning Zhao,Jie-En Yao,Hong-En Chen,Yue Hu,Meida Chen,Suya You,C. -C. Jay Kuo*

Main category: cs.CV

TL;DR: Descrip3D通过自然语言编码物体间关系，提升3D场景理解，优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景-语言模型在物体关系理解上表现不足，视觉嵌入无法充分表达物体角色和交互。

Method: Descrip3D通过文本描述增强物体表示，结合嵌入融合和提示级注入实现多任务统一推理。

Result: 在五个基准数据集上表现优于基线模型。

Conclusion: 语言引导的关系表示对复杂室内场景理解有效。

Abstract: Understanding 3D scenes goes beyond simply recognizing objects; it requires
reasoning about the spatial and semantic relationships between them. Current 3D
scene-language models often struggle with this relational understanding,
particularly when visual embeddings alone do not adequately convey the roles
and interactions of objects. In this paper, we introduce Descrip3D, a novel and
powerful framework that explicitly encodes the relationships between objects
using natural language. Unlike previous methods that rely only on 2D and 3D
embeddings, Descrip3D enhances each object with a textual description that
captures both its intrinsic attributes and contextual relationships. These
relational cues are incorporated into the model through a dual-level
integration: embedding fusion and prompt-level injection. This allows for
unified reasoning across various tasks such as grounding, captioning, and
question answering, all without the need for task-specific heads or additional
supervision. When evaluated on five benchmark datasets, including ScanRefer,
Multi3DRefer, ScanQA, SQA3D, and Scan2Cap, Descrip3D consistently outperforms
strong baseline models, demonstrating the effectiveness of language-guided
relational representation for understanding complex indoor scenes.

</details>


### [34] [LEAD: Exploring Logit Space Evolution for Model Selection](https://arxiv.org/abs/2507.14559)
*Zixuan Hu,Xiaotong Li,Shixiang Tang,Jun Liu,Yichun Hu,Ling-Yu Duan*

Main category: cs.CV

TL;DR: 论文提出了一种名为LEAD的方法，通过基于网络输出的logits建模优化过程，解决了预训练模型选择中的非线性动态预测问题。


<details>
  <summary>Details</summary>
Motivation: 预训练模型的激增使得选择适合下游任务的模型变得困难，现有方法未能准确捕捉微调动态的非线性特性。

Method: LEAD通过理论框架建模优化过程，使用ODE描述非线性演化，并提出类感知分解方法以适应不同类的动态。

Result: 在24个预训练模型和10个下游数据集上的实验表明，LEAD在性能和适应性上表现优异，尤其在低数据场景中。

Conclusion: LEAD通过单步优化解决了微调动态的非线性问题，为预训练模型选择提供了高效解决方案。

Abstract: The remarkable success of pretrain-then-finetune paradigm has led to a
proliferation of available pre-trained models for vision tasks. This surge
presents a significant challenge in efficiently choosing the most suitable
pre-trained models for downstream tasks. The critical aspect of this challenge
lies in effectively predicting the model transferability by considering the
underlying fine-tuning dynamics. Existing methods often model fine-tuning
dynamics in feature space with linear transformations, which do not precisely
align with the fine-tuning objective and fail to grasp the essential
nonlinearity from optimization. To this end, we present LEAD, a
finetuning-aligned approach based on the network output of logits. LEAD
proposes a theoretical framework to model the optimization process and derives
an ordinary differential equation (ODE) to depict the nonlinear evolution
toward the final logit state. Additionally, we design a class-aware
decomposition method to consider the varying evolution dynamics across classes
and further ensure practical applicability. Integrating the closely aligned
optimization objective and nonlinear modeling capabilities derived from the
differential equation, our method offers a concise solution to effectively
bridge the optimization gap in a single step, bypassing the lengthy fine-tuning
process. The comprehensive experiments on 24 supervised and self-supervised
pre-trained models across 10 downstream datasets demonstrate impressive
performances and showcase its broad adaptability even in low-data scenarios.

</details>


### [35] [Benchmarking GANs, Diffusion Models, and Flow Matching for T1w-to-T2w MRI Translation](https://arxiv.org/abs/2507.14575)
*Andrea Moschetto,Lemuel Puglisi,Alec Sargood,Pierluigi Dell'Acqua,Francesco Guarnera,Sebastiano Battiato,Daniele Ravì*

Main category: cs.CV

TL;DR: 本文比较了GAN、扩散模型和流匹配技术在T1w到T2w MRI图像转换中的性能，发现GAN-based Pix2Pix模型在结构保真度、图像质量和计算效率上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 减少MRI扫描时间和成本，通过计算合成缺失的模态。

Method: 使用GAN、扩散模型和流匹配技术进行T1w到T2w的2D MRI图像转换，并在三个公开数据集上评估。

Result: GAN-based Pix2Pix模型优于扩散和流匹配方法，流匹配模型在小数据集上容易过拟合。

Conclusion: GAN更适合实际MRI工作流，流匹配模型需要更多数据以提升性能。

Abstract: Magnetic Resonance Imaging (MRI) enables the acquisition of multiple image
contrasts, such as T1-weighted (T1w) and T2-weighted (T2w) scans, each offering
distinct diagnostic insights. However, acquiring all desired modalities
increases scan time and cost, motivating research into computational methods
for cross-modal synthesis. To address this, recent approaches aim to synthesize
missing MRI contrasts from those already acquired, reducing acquisition time
while preserving diagnostic quality. Image-to-image (I2I) translation provides
a promising framework for this task. In this paper, we present a comprehensive
benchmark of generative models$\unicode{x2013}$specifically, Generative
Adversarial Networks (GANs), diffusion models, and flow matching (FM)
techniques$\unicode{x2013}$for T1w-to-T2w 2D MRI I2I translation. All
frameworks are implemented with comparable settings and evaluated on three
publicly available MRI datasets of healthy adults. Our quantitative and
qualitative analyses show that the GAN-based Pix2Pix model outperforms
diffusion and FM-based methods in terms of structural fidelity, image quality,
and computational efficiency. Consistent with existing literature, these
results suggest that flow-based models are prone to overfitting on small
datasets and simpler tasks, and may require more data to match or surpass GAN
performance. These findings offer practical guidance for deploying I2I
translation techniques in real-world MRI workflows and highlight promising
directions for future research in cross-modal medical image synthesis. Code and
models are publicly available at
https://github.com/AndreaMoschetto/medical-I2I-benchmark.

</details>


### [36] [Performance comparison of medical image classification systems using TensorFlow Keras, PyTorch, and JAX](https://arxiv.org/abs/2507.14587)
*Merjem Bećirović,Amina Kurtović,Nordin Smajlović,Medina Kapo,Amila Akagić*

Main category: cs.CV

TL;DR: 比较了TensorFlow、PyTorch和JAX在血液细胞图像分类中的性能，发现JAX和PyTorch表现优异。


<details>
  <summary>Details</summary>
Motivation: 缺乏对特定深度学习框架在血液图像分析中的详细性能分析。

Method: 比较了TensorFlow、PyTorch和JAX在BloodMNIST数据集上的分类性能和推理时间。

Result: JAX和PyTorch的分类准确性与当前基准相当，性能受图像分辨率和框架优化影响。

Conclusion: JAX和PyTorch在医学图像分类中表现出高效性。

Abstract: Medical imaging plays a vital role in early disease diagnosis and monitoring.
Specifically, blood microscopy offers valuable insights into blood cell
morphology and the detection of hematological disorders. In recent years, deep
learning-based automated classification systems have demonstrated high
potential in enhancing the accuracy and efficiency of blood image analysis.
However, a detailed performance analysis of specific deep learning frameworks
appears to be lacking. This paper compares the performance of three popular
deep learning frameworks, TensorFlow with Keras, PyTorch, and JAX, in
classifying blood cell images from the publicly available BloodMNIST dataset.
The study primarily focuses on inference time differences, but also
classification performance for different image sizes. The results reveal
variations in performance across frameworks, influenced by factors such as
image resolution and framework-specific optimizations. Classification accuracy
for JAX and PyTorch was comparable to current benchmarks, showcasing the
efficiency of these frameworks for medical image classification.

</details>


### [37] [DiSCO-3D : Discovering and segmenting Sub-Concepts from Open-vocabulary queries in NeRF](https://arxiv.org/abs/2507.14596)
*Doriand Petit,Steve Bourgeois,Vincent Gay-Bellile,Florian Chabot,Loïc Barthe*

Main category: cs.CV

TL;DR: DiSCO-3D是一种结合无监督分割和开放词汇指导的3D开放词汇子概念发现方法，在开放词汇和无监督分割的边缘案例中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅适应特定任务目标或场景内容，无法同时适应场景和用户查询。DiSCO-3D旨在解决这一问题。

Method: 基于神经场表示，结合无监督分割和弱开放词汇指导。

Result: 在开放词汇子概念发现中表现有效，在开放词汇和无监督分割的边缘案例中达到最先进水平。

Conclusion: DiSCO-3D为3D语义分割提供了更灵活的解决方案，适应场景和用户需求。

Abstract: 3D semantic segmentation provides high-level scene understanding for
applications in robotics, autonomous systems, \textit{etc}. Traditional methods
adapt exclusively to either task-specific goals (open-vocabulary segmentation)
or scene content (unsupervised semantic segmentation). We propose DiSCO-3D, the
first method addressing the broader problem of 3D Open-Vocabulary Sub-concepts
Discovery, which aims to provide a 3D semantic segmentation that adapts to both
the scene and user queries. We build DiSCO-3D on Neural Fields representations,
combining unsupervised segmentation with weak open-vocabulary guidance. Our
evaluations demonstrate that DiSCO-3D achieves effective performance in
Open-Vocabulary Sub-concepts Discovery and exhibits state-of-the-art results in
the edge cases of both open-vocabulary and unsupervised segmentation.

</details>


### [38] [Exp-Graph: How Connections Learn Facial Attributes in Graph-based Expression Recognition](https://arxiv.org/abs/2507.14608)
*Nandani Sharma,Dinesh Singh*

Main category: cs.CV

TL;DR: 提出Exp-Graph框架，通过图建模结合面部结构信息提升表情识别精度，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 面部表情识别在人机交互等领域至关重要，但面部结构随表情变化，需结合结构信息提升识别效果。

Method: 使用面部关键点作为图顶点，基于邻近性和局部外观相似性确定边，结合视觉Transformer和图卷积网络捕捉结构依赖。

Result: 在Oulu-CASIA、eNTERFACE05和AFEW数据集上分别达到98.09%、79.01%和56.39%的识别准确率。

Conclusion: Exp-Graph在实验室和真实场景中均表现出色，具有实用价值。

Abstract: Facial expression recognition is crucial for human-computer interaction
applications such as face animation, video surveillance, affective computing,
medical analysis, etc. Since the structure of facial attributes varies with
facial expressions, incorporating structural information into facial attributes
is essential for facial expression recognition. In this paper, we propose
Exp-Graph, a novel framework designed to represent the structural relationships
among facial attributes using graph-based modeling for facial expression
recognition. For facial attributes graph representation, facial landmarks are
used as the graph's vertices. At the same time, the edges are determined based
on the proximity of the facial landmark and the similarity of the local
appearance of the facial attributes encoded using the vision transformer.
Additionally, graph convolutional networks are utilized to capture and
integrate these structural dependencies into the encoding of facial attributes,
thereby enhancing the accuracy of expression recognition. Thus, Exp-Graph
learns from the facial attribute graphs highly expressive semantic
representations. On the other hand, the vision transformer and graph
convolutional blocks help the framework exploit the local and global
dependencies among the facial attributes that are essential for the recognition
of facial expressions. We conducted comprehensive evaluations of the proposed
Exp-Graph model on three benchmark datasets: Oulu-CASIA, eNTERFACE05, and AFEW.
The model achieved recognition accuracies of 98.09\%, 79.01\%, and 56.39\%,
respectively. These results indicate that Exp-Graph maintains strong
generalization capabilities across both controlled laboratory settings and
real-world, unconstrained environments, underscoring its effectiveness for
practical facial expression recognition applications.

</details>


### [39] [Depthwise-Dilated Convolutional Adapters for Medical Object Tracking and Segmentation Using the Segment Anything Model 2](https://arxiv.org/abs/2507.14613)
*Guoping Xu,Christopher Kabat,You Zhang*

Main category: cs.CV

TL;DR: DD-SAM2是一个高效适配框架，通过Depthwise-Dilated Adapter增强SAM2在医学视频分割中的多尺度特征提取，减少参数开销。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法多为模态特定设计，适应性差，且SAM2及其变种在医学视频场景中需要大规模数据集重新训练，计算成本高。

Method: 提出DD-SAM2框架，结合Depthwise-Dilated Adapter，以最小参数开销增强多尺度特征提取，适用于有限训练数据的医学视频。

Result: 在TrackRad2025和EchoNet-Dynamic数据集上表现优异，Dice分数分别达到0.93和0.97。

Conclusion: DD-SAM2首次系统探索了基于适配器的SAM2微调方法，为医学视频分割与跟踪提供了高效解决方案。

Abstract: Recent advances in medical image segmentation have been driven by deep
learning; however, most existing methods remain limited by modality-specific
designs and exhibit poor adaptability to dynamic medical imaging scenarios. The
Segment Anything Model 2 (SAM2) and its related variants, which introduce a
streaming memory mechanism for real-time video segmentation, present new
opportunities for prompt-based, generalizable solutions. Nevertheless, adapting
these models to medical video scenarios typically requires large-scale datasets
for retraining or transfer learning, leading to high computational costs and
the risk of catastrophic forgetting. To address these challenges, we propose
DD-SAM2, an efficient adaptation framework for SAM2 that incorporates a
Depthwise-Dilated Adapter (DD-Adapter) to enhance multi-scale feature
extraction with minimal parameter overhead. This design enables effective
fine-tuning of SAM2 on medical videos with limited training data. Unlike
existing adapter-based methods focused solely on static images, DD-SAM2 fully
exploits SAM2's streaming memory for medical video object tracking and
segmentation. Comprehensive evaluations on TrackRad2025 (tumor segmentation)
and EchoNet-Dynamic (left ventricle tracking) datasets demonstrate superior
performance, achieving Dice scores of 0.93 and 0.97, respectively. To the best
of our knowledge, this work provides an initial attempt at systematically
exploring adapter-based SAM2 fine-tuning for medical video segmentation and
tracking. Code, datasets, and models will be publicly available at
https://github.com/apple1986/DD-SAM2.

</details>


### [40] [BusterX++: Towards Unified Cross-Modal AI-Generated Content Detection and Explanation with MLLM](https://arxiv.org/abs/2507.14632)
*Haiquan Wen,Tianxiao Li,Zhenglin Huang,Yiwei He,Guangliang Cheng*

Main category: cs.CV

TL;DR: 论文提出了一种名为BusterX++的新框架，用于跨模态检测和解释合成媒体，解决了现有单模态检测方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的快速发展导致合成媒体内容增多，增加了虚假信息的风险。现有检测方法因单模态设计而效果有限。

Method: BusterX++采用强化学习后训练策略，结合多阶段训练、思维奖励和混合推理，提升性能。

Result: 实验表明BusterX++在跨模态检测中表现优异，并提出了GenBuster++基准用于全面评估。

Conclusion: BusterX++为合成媒体检测提供了高效且可解释的解决方案，具有广泛适用性。

Abstract: Recent advances in generative AI have dramatically improved image and video
synthesis capabilities, significantly increasing the risk of misinformation
through sophisticated fake content. In response, detection methods have evolved
from traditional approaches to multimodal large language models (MLLMs),
offering enhanced transparency and interpretability in identifying synthetic
media. However, current detection systems remain fundamentally limited by their
single-modality design. These approaches analyze images or videos separately,
making them ineffective against synthetic content that combines multiple media
formats. To address these challenges, we introduce \textbf{BusterX++}, a novel
framework designed specifically for cross-modal detection and explanation of
synthetic media. Our approach incorporates an advanced reinforcement learning
(RL) post-training strategy that eliminates cold-start. Through Multi-stage
Training, Thinking Reward, and Hybrid Reasoning, BusterX++ achieves stable and
substantial performance improvements. To enable comprehensive evaluation, we
also present \textbf{GenBuster++}, a cross-modal benchmark leveraging
state-of-the-art image and video generation techniques. This benchmark
comprises 4,000 images and video clips, meticulously curated by human experts
using a novel filtering methodology to ensure high quality, diversity, and
real-world applicability. Extensive experiments demonstrate the effectiveness
and generalizability of our approach.

</details>


### [41] [Multispectral State-Space Feature Fusion: Bridging Shared and Cross-Parametric Interactions for Object Detection](https://arxiv.org/abs/2507.14643)
*Jifeng Shen,Haibo Zhan,Shaohua Dong,Xin Zuo,Wankou Yang,Haibin Ling*

Main category: cs.CV

TL;DR: MS2Fusion提出了一种基于状态空间模型的双路径参数交互机制，有效解决了多光谱特征融合中的局部互补特征偏好和计算复杂度问题，显著提升了目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现代多光谱特征融合在目标检测中存在两个关键问题：过度偏好局部互补特征而忽略跨模态共享语义，以及感受野大小与计算复杂度之间的权衡。

Method: MS2Fusion采用双路径参数交互机制，一条路径通过跨模态隐藏状态解码挖掘互补信息，另一条路径通过参数共享探索跨模态对齐的相似语义特征。

Result: 在FLIR、M3FD和LLVIP等主流基准测试中，MS2Fusion显著优于其他最先进的多光谱目标检测方法，并在RGB-T语义分割和RGBT显著目标检测任务中表现出通用性。

Conclusion: MS2Fusion通过统一框架实现了功能互补和共享语义空间，不仅提升了目标检测性能，还展示了其在其他多光谱感知任务中的潜力。

Abstract: Modern multispectral feature fusion for object detection faces two critical
limitations: (1) Excessive preference for local complementary features over
cross-modal shared semantics adversely affects generalization performance; and
(2) The trade-off between the receptive field size and computational complexity
present critical bottlenecks for scalable feature modeling. Addressing these
issues, a novel Multispectral State-Space Feature Fusion framework, dubbed
MS2Fusion, is proposed based on the state space model (SSM), achieving
efficient and effective fusion through a dual-path parametric interaction
mechanism. More specifically, the first cross-parameter interaction branch
inherits the advantage of cross-attention in mining complementary information
with cross-modal hidden state decoding in SSM. The second shared-parameter
branch explores cross-modal alignment with joint embedding to obtain
cross-modal similar semantic features and structures through parameter sharing
in SSM. Finally, these two paths are jointly optimized with SSM for fusing
multispectral features in a unified framework, allowing our MS2Fusion to enjoy
both functional complementarity and shared semantic space. In our extensive
experiments on mainstream benchmarks including FLIR, M3FD and LLVIP, our
MS2Fusion significantly outperforms other state-of-the-art multispectral object
detection methods, evidencing its superiority. Moreover, MS2Fusion is general
and applicable to other multispectral perception tasks. We show that, even
without specific design, MS2Fusion achieves state-of-the-art results on RGB-T
semantic segmentation and RGBT salient object detection, showing its
generality. The source code will be available at
https://github.com/61s61min/MS2Fusion.git.

</details>


### [42] [AI-Powered Precision in Sport Taekwondo: Enhancing Fairness, Speed, and Trust in Competition (FST.ai)](https://arxiv.org/abs/2507.14657)
*Keivan Shariatmadar,Ahmad Osman*

Main category: cs.CV

TL;DR: FST.ai是一个基于AI的框架，旨在通过计算机视觉和深度学习技术提升体育裁判的实时决策能力，特别是在跆拳道中的头部踢击检测与评分。


<details>
  <summary>Details</summary>
Motivation: 传统裁判系统存在延迟、主观性和不一致性，影响公平性和运动员信任。FST.ai旨在解决这些问题。

Method: 利用计算机视觉、深度学习和边缘推理技术，实现实时动作识别与分类。

Result: 系统将决策时间从分钟级缩短至秒级，提高了裁判的一致性和透明度。

Conclusion: FST.ai框架不仅适用于跆拳道，还可扩展到其他需要动作检测的体育项目，展示了其广泛应用的潜力。

Abstract: The integration of Artificial Intelligence (AI) into sports officiating
represents a paradigm shift in how decisions are made in competitive
environments. Traditional manual systems, even when supported by Instant Video
Replay (IVR), often suffer from latency, subjectivity, and inconsistent
enforcement, undermining fairness and athlete trust. This paper introduces
FST.ai, a novel AI-powered framework designed to enhance officiating in Sport
Taekwondo, particularly focusing on the complex task of real-time head kick
detection and scoring. Leveraging computer vision, deep learning, and edge
inference, the system automates the identification and classification of key
actions, significantly reducing decision time from minutes to seconds while
improving consistency and transparency. Importantly, the methodology is not
limited to Taekwondo. The underlying framework -- based on pose estimation,
motion classification, and impact analysis -- can be adapted to a wide range of
sports requiring action detection, such as judo, karate, fencing, or even team
sports like football and basketball, where foul recognition or performance
tracking is critical. By addressing one of Taekwondo's most challenging
scenarios -- head kick scoring -- we demonstrate the robustness, scalability,
and sport-agnostic potential of FST.ai to transform officiating standards
across multiple disciplines.

</details>


### [43] [Artificial Intelligence in the Food Industry: Food Waste Estimation based on Computer Vision, a Brief Case Study in a University Dining Hall](https://arxiv.org/abs/2507.14662)
*Shayan Rokhva,Babak Teimourpour*

Main category: cs.CV

TL;DR: 该研究提出了一种基于计算机视觉的框架，通过语义分割RGB图像来量化餐盘级食物浪费，适用于五种伊朗菜肴。模型表现良好，部分达到90%以上的像素比例一致性。


<details>
  <summary>Details</summary>
Motivation: 量化机构餐饮环境中的食物浪费，支持数据驱动的可持续发展策略。

Method: 使用四种全监督模型（U-Net、U-Net++及其轻量版），通过动态逆频率损失和AdamW优化器训练，并评估了多种指标。

Result: 模型性能良好，部分食物类型的像素比例一致性接近或超过90%。轻量模型实现实时推理。

Conclusion: 该框架为大规模餐饮环境中的实时浪费监测提供了可扩展的无接触解决方案，并为减少食物浪费提供了可行方向。

Abstract: Quantifying post-consumer food waste in institutional dining settings is
essential for supporting data-driven sustainability strategies. This study
presents a cost-effective computer vision framework that estimates plate-level
food waste by utilizing semantic segmentation of RGB images taken before and
after meal consumption across five Iranian dishes. Four fully supervised models
(U-Net, U-Net++, and their lightweight variants) were trained using a capped
dynamic inverse-frequency loss and AdamW optimizer, then evaluated through a
comprehensive set of metrics, including Pixel Accuracy, Dice, IoU, and a
custom-defined Distributional Pixel Agreement (DPA) metric tailored to the
task. All models achieved satisfying performance, and for each food type, at
least one model approached or surpassed 90% DPA, demonstrating strong alignment
in pixel-wise proportion estimates. Lighter models with reduced parameter
counts offered faster inference, achieving real-time throughput on an NVIDIA T4
GPU. Further analysis showed superior segmentation performance for dry and more
rigid components (e.g., rice and fries), while more complex, fragmented, or
viscous dishes, such as stews, showed reduced performance, specifically
post-consumption. Despite limitations such as reliance on 2D imaging,
constrained food variety, and manual data collection, the proposed framework is
pioneering and represents a scalable, contactless solution for continuous
monitoring of food consumption. This research lays foundational groundwork for
automated, real-time waste tracking systems in large-scale food service
environments and offers actionable insights and outlines feasible future
directions for dining hall management and policymakers aiming to reduce
institutional food waste.

</details>


### [44] [Gene-DML: Dual-Pathway Multi-Level Discrimination for Gene Expression Prediction from Histopathology Images](https://arxiv.org/abs/2507.14670)
*Yaxuan Song,Jianan Fan,Hang Chang,Weidong Cai*

Main category: cs.CV

TL;DR: Gene-DML是一个通过双路径多级判别增强组织病理学图像与基因表达谱之间跨模态对齐的统一框架，显著提升了基因表达预测的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用组织病理学图像与基因表达谱之间的跨模态表示对齐，限制了预测性能。

Method: Gene-DML采用双路径多级判别方法：多尺度实例级判别路径和跨级实例-组判别路径，分别对齐形态与转录关系并增强跨模态结构一致性。

Result: 在公开的空间转录组数据集上，Gene-DML实现了最先进的基因表达预测性能。

Conclusion: Gene-DML通过学习稳健的跨模态表示，为精准医学和计算病理学提供了可扩展且非侵入的分子分析工具。

Abstract: Accurately predicting gene expression from histopathology images offers a
scalable and non-invasive approach to molecular profiling, with significant
implications for precision medicine and computational pathology. However,
existing methods often underutilize the cross-modal representation alignment
between histopathology images and gene expression profiles across multiple
representational levels, thereby limiting their prediction performance. To
address this, we propose Gene-DML, a unified framework that structures latent
space through Dual-pathway Multi-Level discrimination to enhance correspondence
between morphological and transcriptional modalities. The multi-scale
instance-level discrimination pathway aligns hierarchical histopathology
representations extracted at local, neighbor, and global levels with gene
expression profiles, capturing scale-aware morphological-transcriptional
relationships. In parallel, the cross-level instance-group discrimination
pathway enforces structural consistency between individual (image/gene)
instances and modality-crossed (gene/image, respectively) groups, strengthening
the alignment across modalities. By jointly modelling fine-grained and
structural-level discrimination, Gene-DML is able to learn robust cross-modal
representations, enhancing both predictive accuracy and generalization across
diverse biological contexts. Extensive experiments on public spatial
transcriptomics datasets demonstrate that Gene-DML achieves state-of-the-art
performance in gene expression prediction. The code and checkpoints will be
released soon.

</details>


### [45] [Docopilot: Improving Multimodal Models for Document-Level Understanding](https://arxiv.org/abs/2507.14675)
*Yuchen Duan,Zhe Chen,Yusong Hu,Weiyun Wang,Shenglong Ye,Botian Shi,Lewei Lu,Qibin Hou,Tong Lu,Hongsheng Li,Jifeng Dai,Wenhai Wang*

Main category: cs.CV

TL;DR: 论文提出了Doc-750K数据集和Docopilot模型，解决了多模态大语言模型在复杂文档理解中的不足，无需依赖检索增强生成方法。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在复杂多页文档理解上表现不佳，缺乏高质量文档级数据集，且RAG方法存在上下文碎片化、多阶段错误累积和额外时间成本问题。

Method: 构建Doc-750K数据集，包含多样文档结构和跨页依赖关系，并开发原生多模态模型Docopilot，直接处理文档级依赖。

Result: Docopilot在文档理解任务和多轮交互中表现出更高的连贯性、准确性和效率，为文档级多模态理解设定了新基准。

Conclusion: Doc-750K和Docopilot为复杂文档理解提供了有效解决方案，无需依赖RAG方法，显著提升了性能。

Abstract: Despite significant progress in multimodal large language models (MLLMs),
their performance on complex, multi-page document comprehension remains
inadequate, largely due to the lack of high-quality, document-level datasets.
While current retrieval-augmented generation (RAG) methods offer partial
solutions, they suffer from issues, such as fragmented retrieval contexts,
multi-stage error accumulation, and extra time costs of retrieval. In this
work, we present a high-quality document-level dataset, Doc-750K, designed to
support in-depth understanding of multimodal documents. This dataset includes
diverse document structures, extensive cross-page dependencies, and real
question-answer pairs derived from the original documents. Building on the
dataset, we develop a native multimodal model, Docopilot, which can accurately
handle document-level dependencies without relying on RAG. Experiments
demonstrate that Docopilot achieves superior coherence, accuracy, and
efficiency in document understanding tasks and multi-turn interactions, setting
a new baseline for document-level multimodal understanding. Data, code, and
models are released at https://github.com/OpenGVLab/Docopilot

</details>


### [46] [WSI-Agents: A Collaborative Multi-Agent System for Multi-Modal Whole Slide Image Analysis](https://arxiv.org/abs/2507.14680)
*Xinheng Lyu,Yuci Liang,Wenting Chen,Meidan Ding,Jiaqi Yang,Guolin Huang,Daokun Zhang,Xiangjian He,Linlin Shen*

Main category: cs.CV

TL;DR: WSI-Agents是一种新型协作多代理系统，用于多模态WSI分析，通过任务分配、验证和总结模块提升准确性和多功能性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在WSI分析中性能不足的问题，探索协作多代理系统在病理学领域的潜力。

Method: 提出WSI-Agents系统，包含任务分配模块、验证机制和总结模块，结合专家代理和知识库。

Result: 实验表明WSI-Agents在多模态WSI基准测试中优于现有方法。

Conclusion: WSI-Agents在病理学领域展示了协作多代理系统的潜力，平衡了多功能性和准确性。

Abstract: Whole slide images (WSIs) are vital in digital pathology, enabling gigapixel
tissue analysis across various pathological tasks. While recent advancements in
multi-modal large language models (MLLMs) allow multi-task WSI analysis through
natural language, they often underperform compared to task-specific models.
Collaborative multi-agent systems have emerged as a promising solution to
balance versatility and accuracy in healthcare, yet their potential remains
underexplored in pathology-specific domains. To address these issues, we
propose WSI-Agents, a novel collaborative multi-agent system for multi-modal
WSI analysis. WSI-Agents integrates specialized functional agents with robust
task allocation and verification mechanisms to enhance both task-specific
accuracy and multi-task versatility through three components: (1) a task
allocation module assigning tasks to expert agents using a model zoo of patch
and WSI level MLLMs, (2) a verification mechanism ensuring accuracy through
internal consistency checks and external validation using pathology knowledge
bases and domain-specific models, and (3) a summary module synthesizing the
final summary with visual interpretation maps. Extensive experiments on
multi-modal WSI benchmarks show WSI-Agents's superiority to current WSI MLLMs
and medical agent frameworks across diverse tasks.

</details>


### [47] [From Semantics, Scene to Instance-awareness: Distilling Foundation Model for Open-vocabulary Situation Recognition](https://arxiv.org/abs/2507.14686)
*Chen Cai,Tianyi Liu,Jianjun Gao,Wenyang Liu,Kejun Wu,Ruoyu Wang,Yi Wang,Soo Chin Liew*

Main category: cs.CV

TL;DR: 论文提出了一种名为MIPD的新框架，通过从多模态大语言模型（MLLM）中蒸馏知识，提升小模型在开放词汇接地情境识别（Ov-GSR）任务中的泛化和零样本能力。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLM在复杂接地情境识别（GSR）任务中表现不佳且资源消耗大，而传统GSR模型泛化能力不足。论文旨在通过知识迁移解决这些问题。

Method: 提出MIPD框架，包括基于LLM的理性生成器（JRG）、场景感知和实例感知提示，以及负引导多模态提示对齐（NMPA）模块，将多模态知识蒸馏到学生模型中。

Result: 在Ov-SWiG和HICO-DET数据集上，MIPD在已知、罕见和未知情境中表现优异，并提升了未知检测能力。

Conclusion: MIPD通过知识蒸馏有效提升了小模型的泛化和零样本能力，为复杂情境识别任务提供了新思路。

Abstract: Recent Multimodal Large Language Models (MLLMs) exhibit strong zero-shot
abilities but struggle with complex Grounded Situation Recognition (GSR) and
are resource-intensive for edge device deployment. Meanwhile, conventional GSR
models often lack generalization ability, falling short in recognizing unseen
and rare situations. In this paper, we exploit transferring knowledge from a
teacher MLLM to a small GSR model to enhance its generalization and zero-shot
abilities, thereby introducing the task of Open-vocabulary Grounded Situation
Recognition (Ov-GSR). To achieve this, we propose Multimodal Interactive Prompt
Distillation (MIPD), a novel framework that distills enriched multimodal
knowledge from the foundation model, enabling the student Ov-GSR model to
recognize unseen situations and be better aware of rare situations.
Specifically, the MIPD framework first leverages the LLM-based Judgmental
Rationales Generator (JRG) to construct positive and negative glimpse and gaze
rationales enriched with contextual semantic information. The proposed
scene-aware and instance-perception prompts are then introduced to align
rationales with visual information from the MLLM teacher via the
Negative-Guided Multimodal Prompting Alignment (NMPA) module, effectively
capturing holistic and perceptual multimodal knowledge. Finally, the aligned
multimodal knowledge is distilled into the student Ov-GSR model, providing a
stronger foundation for generalization that enhances situation understanding,
bridges the gap between seen and unseen scenarios, and mitigates prediction
bias in rare cases. We evaluate MIPD on the refined Ov-SWiG dataset, achieving
superior performance on seen, rare, and unseen situations, and further
demonstrate improved unseen detection on the HICO-DET dataset.

</details>


### [48] [GTPBD: A Fine-Grained Global Terraced Parcel and Boundary Dataset](https://arxiv.org/abs/2507.14697)
*Zhiwei Zhang,Zi Ye,Yibin Wen,Shuai Yuan,Haohuan Fu,Jianxi Huang,Juepeng Zheng*

Main category: cs.CV

TL;DR: 论文介绍了首个全球梯田地块精细数据集GTPBD，覆盖复杂梯田地形的200,000多个地块，支持多种任务，填补了梯田遥感研究的空白。


<details>
  <summary>Details</summary>
Motivation: 现有农业地块提取研究多集中于中分辨率或平坦农田，缺乏对复杂梯田地形的精细表达，无法满足精准农业需求。

Method: 构建了GTPBD数据集，包含47,537张高分辨率图像及三级标注（边界、掩码、地块标签），覆盖全球多个地理和气候区域。

Result: GTPBD在多种任务（语义分割、边缘检测等）中进行了基准测试，展示了其挑战性和适用性。

Conclusion: GTPBD填补了梯田遥感研究的空白，为精细农业地形分析和跨场景知识迁移提供了基础设施。

Abstract: Agricultural parcels serve as basic units for conducting agricultural
practices and applications, which is vital for land ownership registration,
food security assessment, soil erosion monitoring, etc. However, existing
agriculture parcel extraction studies only focus on mid-resolution mapping or
regular plain farmlands while lacking representation of complex terraced
terrains due to the demands of precision agriculture.In this paper, we
introduce a more fine-grained terraced parcel dataset named GTPBD (Global
Terraced Parcel and Boundary Dataset), which is the first fine-grained dataset
covering major worldwide terraced regions with more than 200,000 complex
terraced parcels with manual annotation. GTPBD comprises 47,537 high-resolution
images with three-level labels, including pixel-level boundary labels, mask
labels, and parcel labels. It covers seven major geographic zones in China and
transcontinental climatic regions around the world.Compared to the existing
datasets, the GTPBD dataset brings considerable challenges due to the: (1)
terrain diversity; (2) complex and irregular parcel objects; and (3) multiple
domain styles. Our proposed GTPBD dataset is suitable for four different tasks,
including semantic segmentation, edge detection, terraced parcel extraction,
and unsupervised domain adaptation (UDA) tasks.Accordingly, we benchmark the
GTPBD dataset on eight semantic segmentation methods, four edge extraction
methods, three parcel extraction methods, and five UDA methods, along with a
multi-dimensional evaluation framework integrating pixel-level and object-level
metrics. GTPBD fills a critical gap in terraced remote sensing research,
providing a basic infrastructure for fine-grained agricultural terrain analysis
and cross-scenario knowledge transfer.

</details>


### [49] [MultiRetNet: A Multimodal Vision Model and Deferral System for Staging Diabetic Retinopathy](https://arxiv.org/abs/2507.14738)
*Jeannie She,Katie Spivakovsky*

Main category: cs.CV

TL;DR: MultiRetNet结合视网膜成像、社会经济因素和共病资料，通过多模态融合方法提升糖尿病视网膜病变（DR）分期准确性，并整合临床延迟系统，提高早期检测率。


<details>
  <summary>Details</summary>
Motivation: 低收入社区人群因筛查机会有限，DR进展风险更高，共病条件加速病情发展，需改进早期检测方法。

Method: 提出MultiRetNet管道，结合多模态数据（视网膜图像、社会经济因素、共病资料），采用全连接层融合方法，并通过对比学习训练延迟系统识别需临床复查的样本。

Result: 系统在低质量图像上保持诊断准确性，整合关键健康数据，提高早期检测率，尤其对服务不足人群有效。

Conclusion: MultiRetNet可降低医疗成本，提高早期检测率，减少医疗资源分配不均，促进健康公平。

Abstract: Diabetic retinopathy (DR) is a leading cause of preventable blindness,
affecting over 100 million people worldwide. In the United States, individuals
from lower-income communities face a higher risk of progressing to advanced
stages before diagnosis, largely due to limited access to screening. Comorbid
conditions further accelerate disease progression. We propose MultiRetNet, a
novel pipeline combining retinal imaging, socioeconomic factors, and
comorbidity profiles to improve DR staging accuracy, integrated with a clinical
deferral system for a clinical human-in-the-loop implementation. We experiment
with three multimodal fusion methods and identify fusion through a fully
connected layer as the most versatile methodology. We synthesize adversarial,
low-quality images and use contrastive learning to train the deferral system,
guiding the model to identify out-of-distribution samples that warrant
clinician review. By maintaining diagnostic accuracy on suboptimal images and
integrating critical health data, our system can improve early detection,
particularly in underserved populations where advanced DR is often first
identified. This approach may reduce healthcare costs, increase early detection
rates, and address disparities in access to care, promoting healthcare equity.

</details>


### [50] [InterAct-Video: Reasoning-Rich Video QA for Urban Traffic](https://arxiv.org/abs/2507.14743)
*Joseph Raj Vishal,Rutuja Patil,Manas Srinivas Gowda,Katha Naik,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: 论文提出了InterAct VideoQA数据集，用于提升视频问答模型在复杂交通场景中的表现，包含8小时真实交通视频和25,000个QA对。


<details>
  <summary>Details</summary>
Motivation: 现有视频问答模型难以处理真实交通场景中的多事件并发问题，需领域专用数据集提升性能。

Method: 构建InterAct VideoQA数据集，包含多样交通视频和QA对，评估并微调现有模型。

Result: 数据集揭示了模型在细粒度时空依赖推理上的挑战，微调后性能显著提升。

Conclusion: InterAct VideoQA为智能交通系统中的视频问答研究提供了重要基准。

Abstract: Traffic monitoring is crucial for urban mobility, road safety, and
intelligent transportation systems (ITS). Deep learning has advanced
video-based traffic monitoring through video question answering (VideoQA)
models, enabling structured insight extraction from traffic videos. However,
existing VideoQA models struggle with the complexity of real-world traffic
scenes, where multiple concurrent events unfold across spatiotemporal
dimensions. To address these challenges, this paper introduces \textbf{InterAct
VideoQA}, a curated dataset designed to benchmark and enhance VideoQA models
for traffic monitoring tasks. The InterAct VideoQA dataset comprises 8 hours of
real-world traffic footage collected from diverse intersections, segmented into
10-second video clips, with over 25,000 question-answer (QA) pairs covering
spatiotemporal dynamics, vehicle interactions, incident detection, and other
critical traffic attributes. State-of-the-art VideoQA models are evaluated on
InterAct VideoQA, exposing challenges in reasoning over fine-grained
spatiotemporal dependencies within complex traffic scenarios. Additionally,
fine-tuning these models on InterAct VideoQA yields notable performance
improvements, demonstrating the necessity of domain-specific datasets for
VideoQA. InterAct VideoQA is publicly available as a benchmark dataset to
facilitate future research in real-world deployable VideoQA models for
intelligent transportation systems. GitHub Repo:
https://github.com/joe-rabbit/InterAct_VideoQA

</details>


### [51] [LeAdQA: LLM-Driven Context-Aware Temporal Grounding for Video Question Answering](https://arxiv.org/abs/2507.14784)
*Xinxin Dong,Baoyun Peng,Haokai Ma,Yufei Wang,Zixuan Dong,Fei Hu,Xiaodong Wang*

Main category: cs.CV

TL;DR: LeAdQA通过结合因果感知查询优化与细粒度视觉定位，解决了视频问答中稀疏关键帧识别和复杂推理的挑战，实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前视频问答方法存在任务无关采样和启发式检索的局限性，无法有效捕捉因果-时间结构，导致复杂推理能力不足。

Method: LeAdQA利用LLM优化问题-选项对，消除因果模糊性，并通过时间定位模型精准检索关键片段，结合自适应融合机制和MLLM生成答案。

Result: 在NExT-QA、IntentQA和NExT-GQA数据集上，LeAdQA表现出色，实现了复杂推理任务的SOTA性能，同时保持计算效率。

Conclusion: LeAdQA通过因果感知和视觉定位的协同作用，显著提升了视频问答的推理能力，为复杂任务提供了高效解决方案。

Abstract: Video Question Answering (VideoQA) requires identifying sparse critical
moments in long videos and reasoning about their causal relationships to answer
semantically complex questions. While recent advances in multimodal learning
have improved alignment and fusion, current approaches remain limited by two
prevalent but fundamentally flawed strategies: (1) task-agnostic sampling
indiscriminately processes all frames, overwhelming key events with irrelevant
content; and (2) heuristic retrieval captures superficial patterns but misses
causal-temporal structures needed for complex reasoning. To address these
challenges, we introduce LeAdQA, an innovative approach that bridges these gaps
through synergizing causal-aware query refinement with fine-grained visual
grounding. Our method first leverages LLMs to reformulate question-option
pairs, resolving causal ambiguities and sharpening temporal focus. These
refined queries subsequently direct a temporal grounding model to precisely
retrieve the most salient segments, complemented by an adaptive fusion
mechanism dynamically integrating the evidence to maximize relevance. The
integrated visual-textual cues are then processed by an MLLM to generate
accurate, contextually-grounded answers. Experiments on NExT-QA, IntentQA, and
NExT-GQA demonstrate that our method's precise visual grounding substantially
enhances the understanding of video-question relationships, achieving
state-of-the-art (SOTA) performance on complex reasoning tasks while
maintaining computational efficiency.

</details>


### [52] [FOCUS: Fused Observation of Channels for Unveiling Spectra](https://arxiv.org/abs/2507.14787)
*Xi Xiao,Aristeidis Tsaris,Anika Tabassum,John Lagergren,Larry M. York,Tianyang Wang,Xiao Wang*

Main category: cs.CV

TL;DR: FOCUS框架首次实现了对冻结Vision Transformers（ViTs）在HSI数据中的高效空间-光谱可解释性，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: HSI数据的高维特性使得ViTs的可解释性面临挑战，现有方法难以捕捉有意义的光谱线索且计算成本高。

Method: FOCUS引入类特定光谱提示和可学习的[SINK]令牌，通过单次前向传播生成稳定的3D显著性图和光谱重要性曲线。

Result: FOCUS将波段级IoU提高15%，减少注意力崩溃40%以上，且与专家标注高度一致。

Conclusion: FOCUS以不到1%的参数开销，为实际HSI应用提供了高效可靠的ViT可解释性解决方案。

Abstract: Hyperspectral imaging (HSI) captures hundreds of narrow, contiguous
wavelength bands, making it a powerful tool in biology, agriculture, and
environmental monitoring. However, interpreting Vision Transformers (ViTs) in
this setting remains largely unexplored due to two key challenges: (1) existing
saliency methods struggle to capture meaningful spectral cues, often collapsing
attention onto the class token, and (2) full-spectrum ViTs are computationally
prohibitive for interpretability, given the high-dimensional nature of HSI
data. We present FOCUS, the first framework that enables reliable and efficient
spatial-spectral interpretability for frozen ViTs. FOCUS introduces two core
components: class-specific spectral prompts that guide attention toward
semantically meaningful wavelength groups, and a learnable [SINK] token trained
with an attraction loss to absorb noisy or redundant attention. Together, these
designs make it possible to generate stable and interpretable 3D saliency maps
and spectral importance curves in a single forward pass, without any gradient
backpropagation or backbone modification. FOCUS improves band-level IoU by 15
percent, reduces attention collapse by over 40 percent, and produces saliency
results that align closely with expert annotations. With less than 1 percent
parameter overhead, our method makes high-resolution ViT interpretability
practical for real-world hyperspectral applications, bridging a long-standing
gap between black-box modeling and trustworthy HSI decision-making.

</details>


### [53] [A Novel Downsampling Strategy Based on Information Complementarity for Medical Image Segmentation](https://arxiv.org/abs/2507.14790)
*Wenbo Yue,Chang Li,Guoping Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于信息互补的下采样方法HPD，用于解决传统下采样方法在语义分割任务中丢失关键空间信息的问题。


<details>
  <summary>Details</summary>
Motivation: 传统下采样方法（如最大池化和跨行卷积）在特征聚合、感受野扩展和计算量减少方面表现良好，但在语义分割任务中可能导致关键空间信息丢失，影响像素级预测精度。

Method: 提出Hybrid Pooling Downsampling (HPD)方法，用MinMaxPooling替代传统方法，通过提取局部区域的最大值信息，有效保留图像的明暗对比和细节特征。

Result: 在ACDC和Synapse数据集上的实验表明，HPD在分割性能上优于传统方法，平均DSC系数提高了0.5%。

Conclusion: HPD模块为语义分割任务提供了一种高效的解决方案。

Abstract: In convolutional neural networks (CNNs), downsampling operations are crucial
to model performance. Although traditional downsampling methods (such as
maximum pooling and cross-row convolution) perform well in feature aggregation,
receptive field expansion, and computational reduction, they may lead to the
loss of key spatial information in semantic segmentation tasks, thereby
affecting the pixel-by-pixel prediction accuracy.To this end, this study
proposes a downsampling method based on information complementarity - Hybrid
Pooling Downsampling (HPD). The core is to replace the traditional method with
MinMaxPooling, and effectively retain the light and dark contrast and detail
features of the image by extracting the maximum value information of the local
area.Experiment on various CNN architectures on the ACDC and Synapse datasets
show that HPD outperforms traditional methods in segmentation performance, and
increases the DSC coefficient by 0.5% on average. The results show that the HPD
module provides an efficient solution for semantic segmentation tasks.

</details>


### [54] [Distilling Parallel Gradients for Fast ODE Solvers of Diffusion Models](https://arxiv.org/abs/2507.14797)
*Beier Zhu,Ruoyu Wang,Tong Zhao,Hanwang Zhang,Chi Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为EPD的新型ODE求解器，通过并行梯度评估减少截断误差，实现高质量、低延迟的采样。


<details>
  <summary>Details</summary>
Motivation: 扩散模型因顺序去噪导致采样延迟高，现有加速方法在低延迟预算下图像质量下降。

Method: EPD利用多个并行梯度评估优化ODE步骤，通过可学习参数蒸馏减少训练开销，并可作为插件改进现有ODE采样器。

Result: 在5 NFE延迟下，EPD在多个数据集（如CIFAR-10、FFHQ等）上FID显著优于现有学习型求解器。

Conclusion: EPD在保持低延迟的同时显著提升了图像生成质量，具有广泛适用性。

Abstract: Diffusion models (DMs) have achieved state-of-the-art generative performance
but suffer from high sampling latency due to their sequential denoising nature.
Existing solver-based acceleration methods often face image quality degradation
under a low-latency budget. In this paper, we propose the Ensemble Parallel
Direction solver (dubbed as \ours), a novel ODE solver that mitigates
truncation errors by incorporating multiple parallel gradient evaluations in
each ODE step. Importantly, since the additional gradient computations are
independent, they can be fully parallelized, preserving low-latency sampling.
  Our method optimizes a small set of learnable parameters in a distillation
fashion, ensuring minimal training overhead.
  In addition, our method can serve as a plugin to improve existing ODE
samplers. Extensive experiments on various image synthesis benchmarks
demonstrate the effectiveness of our \ours~in achieving high-quality and
low-latency sampling. For example, at the same latency level of 5 NFE, EPD
achieves an FID of 4.47 on CIFAR-10, 7.97 on FFHQ, 8.17 on ImageNet, and 8.26
on LSUN Bedroom, surpassing existing learning-based solvers by a significant
margin. Codes are available in https://github.com/BeierZhu/EPD.

</details>


### [55] [An Evaluation of DUSt3R/MASt3R/VGGT 3D Reconstruction on Photogrammetric Aerial Blocks](https://arxiv.org/abs/2507.14798)
*Xinyi Wu,Steven Landgraf,Markus Ulrich,Rongjun Qin*

Main category: cs.CV

TL;DR: 论文评估了DUSt3R、MASt3R和VGGT等3D重建基础模型在航拍图像上的表现，发现它们能从稀疏图像集（少于10张）准确重建密集点云，但高分辨率和大图像集仍存在局限性。


<details>
  <summary>Details</summary>
Motivation: 研究这些模型在航拍图像上的潜力，填补其在摄影测量领域应用的空白。

Method: 在UseGeo数据集的航拍图像块上评估预训练的DUSt3R、MASt3R和VGGT模型，进行姿态估计和密集3D重建。

Result: 模型能从极稀疏图像集（分辨率最高518像素）重建密集点云，完整性比COLMAP提升50%，VGGT计算效率更高。但高分辨率和大图像集下姿态估计可靠性下降。

Conclusion: 基于Transformer的方法无法完全替代传统SfM和MVS，但在低分辨率、稀疏场景下可作为补充。

Abstract: State-of-the-art 3D computer vision algorithms continue to advance in
handling sparse, unordered image sets. Recently developed foundational models
for 3D reconstruction, such as Dense and Unconstrained Stereo 3D Reconstruction
(DUSt3R), Matching and Stereo 3D Reconstruction (MASt3R), and Visual Geometry
Grounded Transformer (VGGT), have attracted attention due to their ability to
handle very sparse image overlaps. Evaluating DUSt3R/MASt3R/VGGT on typical
aerial images matters, as these models may handle extremely low image overlaps,
stereo occlusions, and textureless regions. For redundant collections, they can
accelerate 3D reconstruction by using extremely sparsified image sets. Despite
tests on various computer vision benchmarks, their potential on photogrammetric
aerial blocks remains unexplored. This paper conducts a comprehensive
evaluation of the pre-trained DUSt3R/MASt3R/VGGT models on the aerial blocks of
the UseGeo dataset for pose estimation and dense 3D reconstruction. Results
show these methods can accurately reconstruct dense point clouds from very
sparse image sets (fewer than 10 images, up to 518 pixels resolution), with
completeness gains up to +50% over COLMAP. VGGT also demonstrates higher
computational efficiency, scalability, and more reliable camera pose
estimation. However, all exhibit limitations with high-resolution images and
large sets, as pose reliability declines with more images and geometric
complexity. These findings suggest transformer-based methods cannot fully
replace traditional SfM and MVS, but offer promise as complementary approaches,
especially in challenging, low-resolution, and sparse scenarios.

</details>


### [56] [Exploring Scalable Unified Modeling for General Low-Level Vision](https://arxiv.org/abs/2507.14801)
*Xiangyu Chen,Kaiwen Zhu,Yuandong Pu,Shuo Cao,Xiaohui Li,Wenlong Zhang,Yihao Liu,Yu Qiao,Jiantao Zhou,Chao Dong*

Main category: cs.CV

TL;DR: 提出了一种基于视觉提示的统一低层视觉任务处理框架VPIP，通过多任务联合训练提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决低层视觉任务多样性导致的统一建模挑战。

Method: 设计了包含图像处理主干、提示编码器和交互模块的VPIP框架，并开发了统一模型GenLV。

Result: 在多任务基准测试中表现优异，任务数量增加提升泛化能力。

Conclusion: VPIP框架具有高效性、可扩展性和潜力，为通用低层视觉建模提供了统一基础。

Abstract: Low-level vision involves a wide spectrum of tasks, including image
restoration, enhancement, stylization, and feature extraction, which differ
significantly in both task formulation and output domains. To address the
challenge of unified modeling across such diverse tasks, we propose a Visual
task Prompt-based Image Processing (VPIP) framework that leverages input-target
image pairs as visual prompts to guide the model in performing a variety of
low-level vision tasks. The framework comprises an end-to-end image processing
backbone, a prompt encoder, and a prompt interaction module, enabling flexible
integration with various architectures and effective utilization of
task-specific visual representations. Based on this design, we develop a
unified low-level vision model, GenLV, and evaluate its performance across
multiple representative tasks. To explore the scalability of this approach, we
extend the framework along two dimensions: model capacity and task diversity.
We construct a large-scale benchmark consisting of over 100 low-level vision
tasks and train multiple versions of the model with varying scales.
Experimental results show that the proposed method achieves considerable
performance across a wide range of tasks. Notably, increasing the number of
training tasks enhances generalization, particularly for tasks with limited
data, indicating the model's ability to learn transferable representations
through joint training. Further evaluations in zero-shot generalization,
few-shot transfer, and task-specific fine-tuning scenarios demonstrate the
model's strong adaptability, confirming the effectiveness, scalability, and
potential of the proposed framework as a unified foundation for general
low-level vision modeling.

</details>


### [57] [Seeing Through Deepfakes: A Human-Inspired Framework for Multi-Face Detection](https://arxiv.org/abs/2507.14807)
*Juan Hu,Shaojing Fan,Terence Sim*

Main category: cs.CV

TL;DR: 提出了一种基于人类认知的多脸深度伪造视频检测框架HICOM，通过分析人类依赖的四种关键线索，显著提升了检测准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单脸检测表现良好，但在多脸场景中因缺乏上下文线索而表现不佳，需借鉴人类认知提升检测能力。

Method: 通过人类研究识别四种关键线索（场景-运动一致性、脸间外观兼容性、人际注视对齐、脸-身体一致性），并设计HICOM框架结合这些线索进行检测。

Result: HICOM在基准数据集上平均准确率提升3.3%，在真实扰动下提升2.8%，在未见数据集上优于现有方法5.8%。

Conclusion: HICOM通过结合人类认知线索显著提升了多脸深度伪造检测的准确性和可解释性，为防御深度伪造提供了新思路。

Abstract: Multi-face deepfake videos are becoming increasingly prevalent, often
appearing in natural social settings that challenge existing detection methods.
Most current approaches excel at single-face detection but struggle in
multi-face scenarios, due to a lack of awareness of crucial contextual cues. In
this work, we develop a novel approach that leverages human cognition to
analyze and defend against multi-face deepfake videos. Through a series of
human studies, we systematically examine how people detect deepfake faces in
social settings. Our quantitative analysis reveals four key cues humans rely
on: scene-motion coherence, inter-face appearance compatibility, interpersonal
gaze alignment, and face-body consistency. Guided by these insights, we
introduce \textsf{HICOM}, a novel framework designed to detect every fake face
in multi-face scenarios. Extensive experiments on benchmark datasets show that
\textsf{HICOM} improves average accuracy by 3.3\% in in-dataset detection and
2.8\% under real-world perturbations. Moreover, it outperforms existing methods
by 5.8\% on unseen datasets, demonstrating the generalization of human-inspired
cues. \textsf{HICOM} further enhances interpretability by incorporating an LLM
to provide human-readable explanations, making detection results more
transparent and convincing. Our work sheds light on involving human factors to
enhance defense against deepfakes.

</details>


### [58] [Light Future: Multimodal Action Frame Prediction via InstructPix2Pix](https://arxiv.org/abs/2507.14809)
*Zesen Zhong,Duomin Zhang,Yijia Li*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级的机器人动作预测方法，利用InstructPix2Pix模型进行多模态未来帧预测，显著降低了计算成本和推理延迟。


<details>
  <summary>Details</summary>
Motivation: 预测未来运动轨迹在机器人、自主系统等领域至关重要，但传统视频预测模型计算成本高且推理慢，需要更高效的解决方案。

Method: 通过改进InstructPix2Pix模型，结合视觉和文本输入，实现单帧图像和文本指令下的未来100帧预测。

Result: 在RoboTWin数据集上，该方法在SSIM和PSNR指标上优于现有基线模型，且计算更高效。

Conclusion: 该方法为机器人动作预测提供了一种轻量、高效的解决方案，特别适用于需要快速推理和多模态控制的应用场景。

Abstract: Predicting future motion trajectories is a critical capability across domains
such as robotics, autonomous systems, and human activity forecasting, enabling
safer and more intelligent decision-making. This paper proposes a novel,
efficient, and lightweight approach for robot action prediction, offering
significantly reduced computational cost and inference latency compared to
conventional video prediction models. Importantly, it pioneers the adaptation
of the InstructPix2Pix model for forecasting future visual frames in robotic
tasks, extending its utility beyond static image editing. We implement a deep
learning-based visual prediction framework that forecasts what a robot will
observe 100 frames (10 seconds) into the future, given a current image and a
textual instruction. We repurpose and fine-tune the InstructPix2Pix model to
accept both visual and textual inputs, enabling multimodal future frame
prediction. Experiments on the RoboTWin dataset (generated based on real-world
scenarios) demonstrate that our method achieves superior SSIM and PSNR compared
to state-of-the-art baselines in robot action prediction tasks. Unlike
conventional video prediction models that require multiple input frames, heavy
computation, and slow inference latency, our approach only needs a single image
and a text prompt as input. This lightweight design enables faster inference,
reduced GPU demands, and flexible multimodal control, particularly valuable for
applications like robotics and sports motion trajectory analytics, where motion
trajectory precision is prioritized over visual fidelity.

</details>


### [59] [SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models](https://arxiv.org/abs/2507.14811)
*Jiaji Zhang,Ruichao Sun,Hailiang Zhao,Jiaju Wu,Peng Chen,Hao Li,Xinkui Zhao,Kingsum Chow,Gang Xiong,Lin Ye,Shuiguang Deng*

Main category: cs.CV

TL;DR: SegQuant是一个统一的量化框架，通过自适应结合互补技术提升跨模型通用性，解决了扩散模型量化中的通用性和部署兼容性问题。


<details>
  <summary>Details</summary>
Motivation: 扩散模型计算密集，现有后训练量化方法通用性不足，难以适应工业部署需求。

Method: 提出SegQuant框架，包含SegLinear（分段感知的图量化策略）和DualScale（双尺度量化方案），以保持生成输出的视觉保真度。

Result: SegQuant在多种模型上表现优异，且与主流部署工具兼容。

Conclusion: SegQuant为扩散模型的高效部署提供了通用且高效的量化解决方案。

Abstract: Diffusion models have demonstrated exceptional generative capabilities but
are computationally intensive, posing significant challenges for deployment in
resource-constrained or latency-sensitive environments. Quantization offers an
effective means to reduce model size and computational cost, with post-training
quantization (PTQ) being particularly appealing due to its compatibility with
pre-trained models without requiring retraining or training data. However,
existing PTQ methods for diffusion models often rely on architecture-specific
heuristics that limit their generalizability and hinder integration with
industrial deployment pipelines. To address these limitations, we propose
SegQuant, a unified quantization framework that adaptively combines
complementary techniques to enhance cross-model versatility. SegQuant consists
of a segment-aware, graph-based quantization strategy (SegLinear) that captures
structural semantics and spatial heterogeneity, along with a dual-scale
quantization scheme (DualScale) that preserves polarity-asymmetric activations,
which is crucial for maintaining visual fidelity in generated outputs. SegQuant
is broadly applicable beyond Transformer-based diffusion models, achieving
strong performance while ensuring seamless compatibility with mainstream
deployment tools.

</details>


### [60] [FinChart-Bench: Benchmarking Financial Chart Comprehension in Vision-Language Models](https://arxiv.org/abs/2507.14823)
*Dong Shu,Haoyang Yuan,Yuchen Wang,Yanguang Liu,Huopu Zhang,Haiyan Zhao,Mengnan Du*

Main category: cs.CV

TL;DR: FinChart-Bench是首个专注于真实世界金融图表的基准测试，包含1,200张图表和7,016个问题，评估了25种大型视觉语言模型（LVLM），揭示了当前模型在金融图表理解中的关键局限性。


<details>
  <summary>Details</summary>
Motivation: 金融图表因其复杂的时间结构和领域特定术语而未被充分研究，需要专门的基准测试来评估LVLM的性能。

Method: 构建FinChart-Bench数据集，包含1,200张金融图表和7,016个问题（TF、MC、QA），并对25种LVLM进行全面评估。

Result: 发现开源与闭源模型性能差距缩小、升级模型性能下降、指令遵循困难、空间推理能力不足，以及LVLM不可靠作为自动评估工具。

Conclusion: 当前LVLM在金融图表理解中存在显著局限性，FinChart-Bench为未来研究提供了重要基准。

Abstract: Large vision-language models (LVLMs) have made significant progress in chart
understanding. However, financial charts, characterized by complex temporal
structures and domain-specific terminology, remain notably underexplored. We
introduce FinChart-Bench, the first benchmark specifically focused on
real-world financial charts. FinChart-Bench comprises 1,200 financial chart
images collected from 2015 to 2024, each annotated with True/False (TF),
Multiple Choice (MC), and Question Answering (QA) questions, totaling 7,016
questions. We conduct a comprehensive evaluation of 25 state-of-the-art LVLMs
on FinChart-Bench. Our evaluation reveals critical insights: (1) the
performance gap between open-source and closed-source models is narrowing, (2)
performance degradation occurs in upgraded models within families, (3) many
models struggle with instruction following, (4) both advanced models show
significant limitations in spatial reasoning abilities, and (5) current LVLMs
are not reliable enough to serve as automated evaluators. These findings
highlight important limitations in current LVLM capabilities for financial
chart understanding. The FinChart-Bench dataset is available at
https://huggingface.co/datasets/Tizzzzy/FinChart-Bench.

</details>


### [61] [PHATNet: A Physics-guided Haze Transfer Network for Domain-adaptive Real-world Image Dehazing](https://arxiv.org/abs/2507.14826)
*Fu-Jen Tsai,Yan-Tsung Peng,Yen-Yu Lin,Chia-Wen Lin*

Main category: cs.CV

TL;DR: 提出了一种基于物理引导的雾霾转移网络（PHATNet），通过将目标域的雾霾模式转移到源域的无雾图像上，生成域特定的微调数据集，以提升去雾模型的域适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有去雾模型在未见过的真实雾霾图像上性能下降明显，主要由于训练数据有限。

Method: 提出PHATNet，通过雾霾转移生成域特定微调集，并引入雾霾转移一致性损失和内容泄漏损失以增强解耦能力。

Result: 实验表明，PHATNet显著提升了现有去雾模型在真实世界图像去雾数据集上的性能。

Conclusion: PHATNet通过域适应方法有效提升了去雾模型在未见数据上的表现。

Abstract: Image dehazing aims to remove unwanted hazy artifacts in images. Although
previous research has collected paired real-world hazy and haze-free images to
improve dehazing models' performance in real-world scenarios, these models
often experience significant performance drops when handling unseen real-world
hazy images due to limited training data. This issue motivates us to develop a
flexible domain adaptation method to enhance dehazing performance during
testing. Observing that predicting haze patterns is generally easier than
recovering clean content, we propose the Physics-guided Haze Transfer Network
(PHATNet) which transfers haze patterns from unseen target domains to
source-domain haze-free images, creating domain-specific fine-tuning sets to
update dehazing models for effective domain adaptation. Additionally, we
introduce a Haze-Transfer-Consistency loss and a Content-Leakage Loss to
enhance PHATNet's disentanglement ability. Experimental results demonstrate
that PHATNet significantly boosts state-of-the-art dehazing models on benchmark
real-world image dehazing datasets.

</details>


### [62] [Paired Image Generation with Diffusion-Guided Diffusion Models](https://arxiv.org/abs/2507.14833)
*Haoxuan Zhang,Wenju Cui,Yuzhu Cao,Tao Tan,Jie Liu,Yunsong Peng,Jian Zheng*

Main category: cs.CV

TL;DR: 提出了一种用于数字乳腺断层合成（DBT）图像中肿块分割的配对图像生成方法，解决了现有扩散模型在生成质量和标注数据不足方面的问题。


<details>
  <summary>Details</summary>
Motivation: 高密度乳腺组织导致肿块隐蔽，人工标注困难且耗时，现有扩散模型生成质量低且无法生成标注，限制了监督训练的效果。

Method: 训练一个额外的扩散引导器，实现条件扩散模型的配对图像生成，无需外部条件。

Result: 实验表明，该方法提高了生成质量，缓解了标注数据短缺问题，并提升了下游任务的性能。

Conclusion: 提出的方法在无外部条件下改善了生成质量，为肿块分割任务提供了更多标注数据，提升了模型性能。

Abstract: The segmentation of mass lesions in digital breast tomosynthesis (DBT) images
is very significant for the early screening of breast cancer. However, the
high-density breast tissue often leads to high concealment of the mass lesions,
which makes manual annotation difficult and time-consuming. As a result, there
is a lack of annotated data for model training. Diffusion models are commonly
used for data augmentation, but the existing methods face two challenges.
First, due to the high concealment of lesions, it is difficult for the model to
learn the features of the lesion area. This leads to the low generation quality
of the lesion areas, thus limiting the quality of the generated images. Second,
existing methods can only generate images and cannot generate corresponding
annotations, which restricts the usability of the generated images in
supervised training. In this work, we propose a paired image generation method.
The method does not require external conditions and can achieve the generation
of paired images by training an extra diffusion guider for the conditional
diffusion model. During the experimental phase, we generated paired DBT slices
and mass lesion masks. Then, we incorporated them into the supervised training
process of the mass lesion segmentation task. The experimental results show
that our method can improve the generation quality without external conditions.
Moreover, it contributes to alleviating the shortage of annotated data, thus
enhancing the performance of downstream tasks.

</details>


### [63] [Training Self-Supervised Depth Completion Using Sparse Measurements and a Single Image](https://arxiv.org/abs/2507.14845)
*Rizhao Fan,Zhigen Li,Heping Li,Ning An*

Main category: cs.CV

TL;DR: 提出了一种仅需稀疏深度测量和对应图像的自监督深度补全方法，无需密集标签或多帧数据。


<details>
  <summary>Details</summary>
Motivation: 解决密集标注成本高和多帧依赖限制的问题，适用于静态或单帧场景。

Method: 利用深度分布特性设计新损失函数，结合视觉基础模型的分割图增强深度估计。

Result: 实验证明方法有效。

Conclusion: 新方法在自监督深度补全中表现优越，解决了现有方法的局限性。

Abstract: Depth completion is an important vision task, and many efforts have been made
to enhance the quality of depth maps from sparse depth measurements. Despite
significant advances, training these models to recover dense depth from sparse
measurements remains a challenging problem. Supervised learning methods rely on
dense depth labels to predict unobserved regions, while self-supervised
approaches require image sequences to enforce geometric constraints and
photometric consistency between frames. However, acquiring dense annotations is
costly, and multi-frame dependencies limit the applicability of self-supervised
methods in static or single-frame scenarios. To address these challenges, we
propose a novel self-supervised depth completion paradigm that requires only
sparse depth measurements and their corresponding image for training. Unlike
existing methods, our approach eliminates the need for dense depth labels or
additional images captured from neighboring viewpoints. By leveraging the
characteristics of depth distribution, we design novel loss functions that
effectively propagate depth information from observed points to unobserved
regions. Additionally, we incorporate segmentation maps generated by vision
foundation models to further enhance depth estimation. Extensive experiments
demonstrate the effectiveness of our proposed method.

</details>


### [64] [Grounding Degradations in Natural Language for All-In-One Video Restoration](https://arxiv.org/abs/2507.14851)
*Muhammad Kamran Janjua,Amirhosein Ghasemabadi,Kunlin Zhang,Mohammad Salameh,Chao Gao,Di Niu*

Main category: cs.CV

TL;DR: 提出了一种基于自然语言和基础模型的全能视频修复框架，无需预先了解退化信息，并在推理时无额外成本。同时呼吁标准化全能视频修复的基准测试，并提出了新的多退化基准测试和数据集。


<details>
  <summary>Details</summary>
Motivation: 现有视频修复方法通常需要预先了解退化信息，限制了其灵活性和可解释性。本文旨在通过自然语言和基础模型提供更灵活、可解释的修复指导。

Method: 利用基础模型通过自然语言捕捉视频帧的退化感知语义上下文，无需训练或测试时了解退化信息，并在推理时解耦基础模型以减少成本。

Result: 在提出的多退化基准测试和时间变化复合退化基准测试中，方法表现优于现有技术，达到了最先进的性能。

Conclusion: 该方法提供了一种无需退化知识的全能视频修复解决方案，并呼吁标准化基准测试以推动领域发展。

Abstract: In this work, we propose an all-in-one video restoration framework that
grounds degradation-aware semantic context of video frames in natural language
via foundation models, offering interpretable and flexible guidance. Unlike
prior art, our method assumes no degradation knowledge in train or test time
and learns an approximation to the grounded knowledge such that the foundation
model can be safely disentangled during inference adding no extra cost.
Further, we call for standardization of benchmarks in all-in-one video
restoration, and propose two benchmarks in multi-degradation setting,
three-task (3D) and four-task (4D), and two time-varying composite degradation
benchmarks; one of the latter being our proposed dataset with varying snow
intensity, simulating how weather degradations affect videos naturally. We
compare our method with prior works and report state-of-the-art performance on
all benchmarks.

</details>


### [65] [An Uncertainty-aware DETR Enhancement Framework for Object Detection](https://arxiv.org/abs/2507.14855)
*Xingshu Chen,Sicheng Yu,Chong Cheng,Hao Wang,Ting Tian*

Main category: cs.CV

TL;DR: 提出了一种基于DETR的不确定性感知目标检测框架，通过建模边界框为高斯分布并引入Gromov-Wasserstein距离优化损失函数，提升定位精度和预测可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统检测器忽略预测不确定性，限制了模型的鲁棒性，本文旨在解决这一问题。

Method: 将边界框建模为多元高斯分布，引入Gromov-Wasserstein距离优化损失，提出Bayes Risk过滤高风险信息，并设计算法量化定位不确定性。

Result: 在COCO基准测试中有效提升DETR变体性能，在白细胞检测任务（LISC和WBCDD数据集）上达到SOTA。

Conclusion: 框架在通用和领域特定检测任务中均具有可扩展性。

Abstract: This paper investigates the problem of object detection with a focus on
improving both the localization accuracy of bounding boxes and explicitly
modeling prediction uncertainty. Conventional detectors rely on deterministic
bounding box regression, ignoring uncertainty in predictions and limiting model
robustness. In this paper, we propose an uncertainty-aware enhancement
framework for DETR-based object detectors. We model bounding boxes as
multivariate Gaussian distributions and incorporate the Gromov-Wasserstein
distance into the loss function to better align the predicted and ground-truth
distributions. Building on this, we derive a Bayes Risk formulation to filter
high-risk information and improve detection reliability. We also propose a
simple algorithm to quantify localization uncertainty via confidence intervals.
Experiments on the COCO benchmark show that our method can be effectively
integrated into existing DETR variants, enhancing their performance. We further
extend our framework to leukocyte detection tasks, achieving state-of-the-art
results on the LISC and WBCDD datasets. These results confirm the scalability
of our framework across both general and domain-specific detection tasks. Code
page:
https://github.com/ParadiseforAndaChen/An-Uncertainty-aware-DETR-Enhancement-Framework-for-Object-Detection.

</details>


### [66] [Hybrid-supervised Hypergraph-enhanced Transformer for Micro-gesture Based Emotion Recognition](https://arxiv.org/abs/2507.14867)
*Zhaoqiang Xia,Hexiang Huang,Haoyu Chen,Xiaoyi Feng,Guoying Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种基于微手势的情感识别方法，通过超图增强的Transformer在混合监督框架中重建行为模式。


<details>
  <summary>Details</summary>
Motivation: 微手势能传达人类情感状态，但基于微手势的情感建模研究不足。

Method: 使用超图增强的Transformer编码器和解码器，结合自监督和监督学习，设计超图自注意力模块和多尺度时间卷积模块。

Result: 在两个公开数据集（iMiGUE和SMG）上表现最佳，优于现有方法。

Conclusion: 该方法通过混合监督框架有效建模微手势的局部运动与情感状态关系。

Abstract: Micro-gestures are unconsciously performed body gestures that can convey the
emotion states of humans and start to attract more research attention in the
fields of human behavior understanding and affective computing as an emerging
topic. However, the modeling of human emotion based on micro-gestures has not
been explored sufficiently. In this work, we propose to recognize the emotion
states based on the micro-gestures by reconstructing the behavior patterns with
a hypergraph-enhanced Transformer in a hybrid-supervised framework. In the
framework, hypergraph Transformer based encoder and decoder are separately
designed by stacking the hypergraph-enhanced self-attention and multiscale
temporal convolution modules. Especially, to better capture the subtle motion
of micro-gestures, we construct a decoder with additional upsampling operations
for a reconstruction task in a self-supervised learning manner. We further
propose a hypergraph-enhanced self-attention module where the hyperedges
between skeleton joints are gradually updated to present the relationships of
body joints for modeling the subtle local motion. Lastly, for exploiting the
relationship between the emotion states and local motion of micro-gestures, an
emotion recognition head from the output of encoder is designed with a shallow
architecture and learned in a supervised way. The end-to-end framework is
jointly trained in a one-stage way by comprehensively utilizing
self-reconstruction and supervision information. The proposed method is
evaluated on two publicly available datasets, namely iMiGUE and SMG, and
achieves the best performance under multiple metrics, which is superior to the
existing methods.

</details>


### [67] [Region-aware Depth Scale Adaptation with Sparse Measurements](https://arxiv.org/abs/2507.14879)
*Rizhao Fan,Tianfang Ma,Zhigen Li,Ning An,Jian Cheng*

Main category: cs.CV

TL;DR: 提出了一种无需学习的方法，利用稀疏深度测量将基础模型的相对尺度深度预测转换为度量尺度深度，避免了额外训练或微调。


<details>
  <summary>Details</summary>
Motivation: 解决基础模型在零样本单目深度估计中输出为相对尺度而非度量尺度的问题，避免传统方法的高成本和泛化能力损失。

Method: 通过稀疏深度测量调整基础模型的相对尺度预测，无需重新训练或微调。

Result: 实验证明该方法有效，能在不增加计算成本或牺牲泛化能力的情况下实现度量尺度深度。

Conclusion: 该方法成功填补了相对尺度与度量尺度深度之间的差距，具有实际应用潜力。

Abstract: In recent years, the emergence of foundation models for depth prediction has
led to remarkable progress, particularly in zero-shot monocular depth
estimation. These models generate impressive depth predictions; however, their
outputs are often in relative scale rather than metric scale. This limitation
poses challenges for direct deployment in real-world applications. To address
this, several scale adaptation methods have been proposed to enable foundation
models to produce metric depth. However, these methods are typically costly, as
they require additional training on new domains and datasets. Moreover,
fine-tuning these models often compromises their original generalization
capabilities, limiting their adaptability across diverse scenes. In this paper,
we introduce a non-learning-based approach that leverages sparse depth
measurements to adapt the relative-scale predictions of foundation models into
metric-scale depth. Our method requires neither retraining nor fine-tuning,
thereby preserving the strong generalization ability of the original foundation
models while enabling them to produce metric depth. Experimental results
demonstrate the effectiveness of our approach, high-lighting its potential to
bridge the gap between relative and metric depth without incurring additional
computational costs or sacrificing generalization ability.

</details>


### [68] [BeatFormer: Efficient motion-robust remote heart rate estimation through unsupervised spectral zoomed attention filters](https://arxiv.org/abs/2507.14885)
*Joaquim Comas,Federico Sukno*

Main category: cs.CV

TL;DR: BeatFormer是一种轻量级频谱注意力模型，结合了手工方法和深度学习的优势，用于远程光电容积描记术（rPPG）估计，并通过谱对比学习（SCL）实现无标签训练。


<details>
  <summary>Details</summary>
Motivation: 当前rPPG估计中，深度学习方法依赖大数据集，而手工方法在未见场景中泛化能力有限，需要结合两者优势。

Method: 提出BeatFormer模型，整合了放缩正交复数注意力和频域能量测量，并引入SCL实现无标签训练。

Result: 在PURE、UBFC-rPPG和MMPD数据集上验证了模型的鲁棒性和性能，尤其在运动场景的跨数据集评估中表现优异。

Conclusion: BeatFormer通过结合手工方法和深度学习的优势，实现了高效且鲁棒的rPPG估计，为无标签训练提供了新思路。

Abstract: Remote photoplethysmography (rPPG) captures cardiac signals from facial
videos and is gaining attention for its diverse applications. While deep
learning has advanced rPPG estimation, it relies on large, diverse datasets for
effective generalization. In contrast, handcrafted methods utilize
physiological priors for better generalization in unseen scenarios like motion
while maintaining computational efficiency. However, their linear assumptions
limit performance in complex conditions, where deep learning provides superior
pulsatile information extraction. This highlights the need for hybrid
approaches that combine the strengths of both methods. To address this, we
present BeatFormer, a lightweight spectral attention model for rPPG estimation,
which integrates zoomed orthonormal complex attention and frequency-domain
energy measurement, enabling a highly efficient model. Additionally, we
introduce Spectral Contrastive Learning (SCL), which allows BeatFormer to be
trained without any PPG or HR labels. We validate BeatFormer on the PURE,
UBFC-rPPG, and MMPD datasets, demonstrating its robustness and performance,
particularly in cross-dataset evaluations under motion scenarios.

</details>


### [69] [TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP](https://arxiv.org/abs/2507.14904)
*Fan Li,Zanyi Wang,Zeyi Huang,Guang Dai,Jingdong Wang,Mengmeng Wang*

Main category: cs.CV

TL;DR: 提出了一种统一的2D预训练多模态网络（GARF），简化了3D视觉定位模型架构，减少了参数并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉定位方法依赖多模态分离编码器，导致模型复杂且训练效率低。

Method: 利用2D CLIP双模态模型，通过适配器微调适应三模态（RGB图像、文本、点云），设计GARF模块融合几何特征，并引入多模态解码器。

Result: 参数减少约58%，3D检测任务提升6.52%，3D视觉定位任务提升6.25%。

Conclusion: 统一特征提取与融合方法显著简化模型并提升性能。

Abstract: 3D visual grounding allows an embodied agent to understand visual information
in real-world 3D environments based on human instructions, which is crucial for
embodied intelligence. Existing 3D visual grounding methods typically rely on
separate encoders for different modalities (e.g., RGB images, text, and 3D
point clouds), resulting in large and complex models that are inefficient to
train. While some approaches use pre-trained 2D multi-modal models like CLIP
for 3D tasks, they still struggle with aligning point cloud data to 2D
encoders. As a result, these methods continue to depend on 3D encoders for
feature extraction, further increasing model complexity and training
inefficiency. In this paper, we propose a unified 2D pre-trained multi-modal
network to process all three modalities (RGB images, text, and point clouds),
significantly simplifying the architecture. By leveraging a 2D CLIP bi-modal
model with adapter-based fine-tuning, this framework effectively adapts to the
tri-modal setting, improving both adaptability and performance across
modalities. Our Geometric-Aware 2D-3D Feature Recovery and Fusion (GARF) module
is designed to fuse geometric multi-scale features from point clouds and
images. We then integrate textual features for final modality fusion and
introduce a multi-modal decoder to facilitate deep cross-modal understanding.
Together, our method achieves unified feature extraction and fusion across the
three modalities, enabling an end-to-end 3D visual grounding model. Compared to
the baseline, our method reduces the number of trainable parameters by
approximately 58\%, while achieving a 6.52\% improvement in the 3D detection
task and a 6.25\% improvement in the 3D visual grounding task.

</details>


### [70] [Semantic-Aware Representation Learning for Multi-label Image Classification](https://arxiv.org/abs/2507.14918)
*Ren-Dong Xie,Zhi-Fen He,Bo Li,Bin Liu,Jin-Yan Hu*

Main category: cs.CV

TL;DR: 本文提出了一种语义感知表示学习（SARL）方法，用于多标签图像分类，通过语义相关特征学习和最优传输注意力机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在图像表示中可能存在噪声且无法精确定位对象，因此需要更有效的表示学习方法。

Method: 采用标签语义相关特征学习模块提取特征，设计最优传输注意力机制实现语义对齐，并使用区域分数聚合策略进行多标签预测。

Result: 在PASCAL VOC 2007和MS-COCO数据集上的实验表明，SARL优于现有方法。

Conclusion: SARL通过语义对齐和注意力机制显著提升了多标签图像分类的性能。

Abstract: Multi-label image classification, an important research area in computer
vision, focuses on identifying multiple labels or concepts within an image.
Existing approaches often employ attention mechanisms or graph convolutional
networks (GCNs) to learn image representation. However, this representation may
contain noise and may not locate objects precisely. Therefore, this paper
proposes a Semantic-Aware Representation Learning (SARL) for multi-label image
classification. First, a label semantic-related feature learning module is
utilized to extract semantic-related features. Then, an optimal transport-based
attention mechanism is designed to obtain semantically aligned image
representation. Finally, a regional score aggregation strategy is used for
multi-label prediction. Experimental results on two benchmark datasets, PASCAL
VOC 2007 and MS-COCO, demonstrate the superiority of SARL over existing
methods.

</details>


### [71] [Stereo-GS: Multi-View Stereo Vision Model for Generalizable 3D Gaussian Splatting Reconstruction](https://arxiv.org/abs/2507.14921)
*Xiufeng Huang,Ka Chun Cheung,Runmin Cong,Simon See,Renjie Wan*

Main category: cs.CV

TL;DR: 提出了一种解耦框架\method，用于高效预测3D高斯分布，通过立体视觉提取特征并融合，生成几何和外观的GS-maps，实现无姿态3D重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D高斯几何和外观预测上耦合度高，依赖数据驱动先验且回归速度慢，需要大量计算资源和数据集。

Method: 使用立体视觉骨干网络提取局部图像对特征，通过全局注意力块融合，生成多视点点图和外观高斯特征，结合为GS-maps，并通过细化网络提升重建质量。

Result: 实现了无姿态的高质量3D重建，减少资源需求，提升鲁棒性和实用性。

Conclusion: \method提供了一种高效、可扩展的解决方案，适用于实际3D内容生成。

Abstract: Generalizable 3D Gaussian Splatting reconstruction showcases advanced
Image-to-3D content creation but requires substantial computational resources
and large datasets, posing challenges to training models from scratch. Current
methods usually entangle the prediction of 3D Gaussian geometry and appearance,
which rely heavily on data-driven priors and result in slow regression speeds.
To address this, we propose \method, a disentangled framework for efficient 3D
Gaussian prediction. Our method extracts features from local image pairs using
a stereo vision backbone and fuses them via global attention blocks. Dedicated
point and Gaussian prediction heads generate multi-view point-maps for geometry
and Gaussian features for appearance, combined as GS-maps to represent the 3DGS
object. A refinement network enhances these GS-maps for high-quality
reconstruction. Unlike existing methods that depend on camera parameters, our
approach achieves pose-free 3D reconstruction, improving robustness and
practicality. By reducing resource demands while maintaining high-quality
outputs, \method provides an efficient, scalable solution for real-world 3D
content generation.

</details>


### [72] [3-Dimensional CryoEM Pose Estimation and Shift Correction Pipeline](https://arxiv.org/abs/2507.14924)
*Kaishva Chintan Shah,Virajith Boddapati,Karthik S. Gurumoorthy,Sandip Kaledhonkar,Ajit Rajwade*

Main category: cs.CV

TL;DR: 提出了一种基于多维尺度分析（MDS）和鲁棒优化的方法，用于解决冷冻电镜（cryo-EM）中低信噪比（SNR）下的姿态估计和位移校正问题。


<details>
  <summary>Details</summary>
Motivation: 冷冻电镜中的低信噪比导致姿态估计和位移校正困难，直接影响3D重建的准确性。

Method: 利用MDS技术从二面角对估计旋转矩阵，并通过鲁棒优化框架（如ℓ1范数）和迭代位移校正算法实现精确的姿态估计和位移校正。

Result: 该方法在欧拉角精度和重建保真度（通过傅里叶壳层相关性FSC衡量）上优于现有方法。

Conclusion: 提出的鲁棒优化框架和全局位移校正算法显著提升了低信噪比条件下的冷冻电镜重建质量。

Abstract: Accurate pose estimation and shift correction are key challenges in cryo-EM
due to the very low SNR, which directly impacts the fidelity of 3D
reconstructions. We present an approach for pose estimation in cryo-EM that
leverages multi-dimensional scaling (MDS) techniques in a robust manner to
estimate the 3D rotation matrix of each particle from pairs of dihedral angles.
We express the rotation matrix in the form of an axis of rotation and a unit
vector in the plane perpendicular to the axis. The technique leverages the
concept of common lines in 3D reconstruction from projections. However, common
line estimation is ridden with large errors due to the very low SNR of cryo-EM
projection images. To address this challenge, we introduce two complementary
components: (i) a robust joint optimization framework for pose estimation based
on an $\ell_1$-norm objective or a similar robust norm, which simultaneously
estimates rotation axes and in-plane vectors while exactly enforcing unit norm
and orthogonality constraints via projected coordinate descent; and (ii) an
iterative shift correction algorithm that estimates consistent in-plane
translations through a global least-squares formulation. While prior approaches
have leveraged such embeddings and common-line geometry for orientation
recovery, existing formulations typically rely on $\ell_2$-based objectives
that are sensitive to noise, and enforce geometric constraints only
approximately. These choices, combined with a sequential pipeline structure,
can lead to compounding errors and suboptimal reconstructions in low-SNR
regimes. Our pipeline consistently outperforms prior methods in both Euler
angle accuracy and reconstruction fidelity, as measured by the Fourier Shell
Correlation (FSC).

</details>


### [73] [Probabilistic smooth attention for deep multiple instance learning in medical imaging](https://arxiv.org/abs/2507.14932)
*Francisco M. Castro-Macías,Pablo Morales-Álvarez,Yunan Wu,Rafael Molina,Aggelos K. Katsaggelos*

Main category: cs.CV

TL;DR: 提出了一种新的概率框架，用于多实例学习（MIL）中的注意力机制，通过估计注意力值的概率分布来捕捉局部和全局交互，并在医学影像分类中取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度MIL方法通常确定性处理注意力值，可能忽略个体实例贡献的不确定性。

Method: 提出概率框架，估计注意力值的概率分布，同时考虑局部和全局交互。

Result: 在三个医学数据集和十一个基线方法中，取得了最佳预测性能，并提供可解释的不确定性图。

Conclusion: 概率框架提升了MIL在医学影像分类中的性能，并提供了可解释的不确定性分析。

Abstract: The Multiple Instance Learning (MIL) paradigm is attracting plenty of
attention in medical imaging classification, where labeled data is scarce. MIL
methods cast medical images as bags of instances (e.g. patches in whole slide
images, or slices in CT scans), and only bag labels are required for training.
Deep MIL approaches have obtained promising results by aggregating
instance-level representations via an attention mechanism to compute the
bag-level prediction. These methods typically capture both local interactions
among adjacent instances and global, long-range dependencies through various
mechanisms. However, they treat attention values deterministically, potentially
overlooking uncertainty in the contribution of individual instances. In this
work we propose a novel probabilistic framework that estimates a probability
distribution over the attention values, and accounts for both global and local
interactions. In a comprehensive evaluation involving {\color{review} eleven}
state-of-the-art baselines and three medical datasets, we show that our
approach achieves top predictive performance in different metrics. Moreover,
the probabilistic treatment of the attention provides uncertainty maps that are
interpretable in terms of illness localization.

</details>


### [74] [Open-set Cross Modal Generalization via Multimodal Unified Representation](https://arxiv.org/abs/2507.14935)
*Hai Huang,Yan Xia,Shulei Wang,Hanting Wang,Minghui Fang,Shengpeng Ji,Sashuai Zhou,Tao Jin,Zhou Zhao*

Main category: cs.CV

TL;DR: 论文提出开放集跨模态泛化任务（OSCMG），并设计MICU方法（包含FCMI和CUJP组件）以解决开放集环境下的多模态统一表示问题。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态泛化研究局限于封闭集环境，而实际应用中常需处理未见类别和新模态，因此需扩展至开放集条件。

Method: 提出MICU方法，包括FCMI（细粒度与粗粒度掩码对比学习）和CUJP（跨模态统一拼图任务），以增强多模态对齐和特征多样性。

Result: 在CMG和新提出的OSCMG任务上验证了方法的有效性。

Conclusion: MICU方法在开放集跨模态泛化任务中表现优异，为多模态统一表示提供了新思路。

Abstract: This paper extends Cross Modal Generalization (CMG) to open-set environments
by proposing the more challenging Open-set Cross Modal Generalization (OSCMG)
task. This task evaluates multimodal unified representations in open-set
conditions, addressing the limitations of prior closed-set cross-modal
evaluations. OSCMG requires not only cross-modal knowledge transfer but also
robust generalization to unseen classes within new modalities, a scenario
frequently encountered in real-world applications. Existing multimodal unified
representation work lacks consideration for open-set environments. To tackle
this, we propose MICU, comprising two key components: Fine-Coarse Masked
multimodal InfoNCE (FCMI) and Cross modal Unified Jigsaw Puzzles (CUJP). FCMI
enhances multimodal alignment by applying contrastive learning at both holistic
semantic and temporal levels, incorporating masking to enhance generalization.
CUJP enhances feature diversity and model uncertainty by integrating
modality-agnostic feature selection with self-supervised learning, thereby
strengthening the model's ability to handle unknown categories in open-set
tasks. Extensive experiments on CMG and the newly proposed OSCMG validate the
effectiveness of our approach. The code is available at
https://github.com/haihuangcode/CMG.

</details>


### [75] [Polymorph: Energy-Efficient Multi-Label Classification for Video Streams on Embedded Devices](https://arxiv.org/abs/2507.14959)
*Saeid Ghafouri,Mohsen Fayyaz,Xiangchen Li,Deepu John,Bo Ji,Dimitrios Nikolopoulos,Hans Vandierendonck*

Main category: cs.CV

TL;DR: Polymorph框架通过动态激活轻量级适配器，利用视频标签的稀疏性和共现性，显著降低嵌入式设备上的能耗并提高分类性能。


<details>
  <summary>Details</summary>
Motivation: 嵌入式设备上实时多标签视频分类受限于计算和能源预算，但视频流的结构特性（如标签稀疏性、时间连续性和标签共现性）可用于高效推理。

Method: 引入Polymorph框架，动态选择和组合轻量级低秩适配器（LoRA），每个适配器专用于基于共现模式的子类，避免全模型切换和权重合并。

Result: 在TAO数据集上，Polymorph能耗降低40%，mAP提高9个百分点。

Conclusion: Polymorph通过模块化策略显著提升嵌入式设备上视频分类的效率和性能。

Abstract: Real-time multi-label video classification on embedded devices is constrained
by limited compute and energy budgets. Yet, video streams exhibit structural
properties such as label sparsity, temporal continuity, and label co-occurrence
that can be leveraged for more efficient inference. We introduce Polymorph, a
context-aware framework that activates a minimal set of lightweight Low Rank
Adapters (LoRA) per frame. Each adapter specializes in a subset of classes
derived from co-occurrence patterns and is implemented as a LoRA weight over a
shared backbone. At runtime, Polymorph dynamically selects and composes only
the adapters needed to cover the active labels, avoiding full-model switching
and weight merging. This modular strategy improves scalability while reducing
latency and energy overhead. Polymorph achieves 40% lower energy consumption
and improves mAP by 9 points over strong baselines on the TAO dataset.
Polymorph is open source at https://github.com/inference-serving/polymorph/.

</details>


### [76] [Decision PCR: Decision version of the Point Cloud Registration task](https://arxiv.org/abs/2507.14965)
*Yaojie Zhang,Tianlun Huang,Weijun Wang,Wei Feng*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的方法来解决低重叠点云配准（PCR）任务中的评估问题，通过构建数据集和训练分类器，显著提升了现有配准方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统评估指标在极低内点比例下失效，因此需要重新审视配准结果评估问题，并提出数据驱动的解决方案。

Method: 构建基于3DMatch数据集的数据集，训练深度学习分类器以可靠评估配准质量，并将其集成到标准PCR流程中。

Result: 结合GeoTransformer等方法，在3DLoMatch基准上实现了86.97%的配准召回率，并在未见的ETH数据集上表现出强泛化能力。

Conclusion: 本文首次通过深度学习框架解决了PCR任务中的评估问题，显著提升了配准性能，并展示了方法的通用性。

Abstract: Low-overlap point cloud registration (PCR) remains a significant challenge in
3D vision. Traditional evaluation metrics, such as Maximum Inlier Count, become
ineffective under extremely low inlier ratios. In this paper, we revisit the
registration result evaluation problem and identify the Decision version of the
PCR task as the fundamental problem. To address this Decision PCR task, we
propose a data-driven approach. First, we construct a corresponding dataset
based on the 3DMatch dataset. Then, a deep learning-based classifier is trained
to reliably assess registration quality, overcoming the limitations of
traditional metrics. To our knowledge, this is the first comprehensive study to
address this task through a deep learning framework. We incorporate this
classifier into standard PCR pipelines. When integrated with our approach,
existing state-of-the-art PCR methods exhibit significantly enhanced
registration performance. For example, combining our framework with
GeoTransformer achieves a new SOTA registration recall of 86.97\% on the
challenging 3DLoMatch benchmark. Our method also demonstrates strong
generalization capabilities on the unseen outdoor ETH dataset.

</details>


### [77] [Hierarchical Cross-modal Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2507.14976)
*Hao Zheng,Shunzhi Yang,Zhuoxin He,Jinfeng Yang,Zhenhua Huang*

Main category: cs.CV

TL;DR: HiCroPL提出了一种分层跨模态提示学习框架，解决预训练视觉语言模型在适应下游任务时的模态隔离和语义衰减问题，通过在文本和视觉模态间建立双向知识流，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 预训练视觉语言模型（如CLIP）在下游任务中难以保持泛化能力，现有提示学习方法存在模态隔离和层次语义衰减的瓶颈。

Method: HiCroPL通过分层知识映射器和轻量级知识代理，实现文本与视觉模态的双向知识流动，早期层文本提示增强视觉语义，后期层视觉提示优化文本语义。

Result: 在四个任务的11个基准测试中取得最优性能，显著提升模型表现。

Conclusion: HiCroPL通过分层跨模态交互有效解决了泛化问题，为视觉语言模型的下游任务适应提供了新思路。

Abstract: Pre-trained Vision-Language Models (VLMs) such as CLIP have shown excellent
generalization abilities. However, adapting these large-scale models to
downstream tasks while preserving their generalization capabilities remains
challenging. Although prompt learning methods have shown promise, they suffer
from two fundamental bottlenecks that limit generalization: (a) modality
isolation, and (b) hierarchical semantic decay. To address these limitations,
we propose HiCroPL, a Hierarchical Cross-modal Prompt Learning framework that
establishes bidirectional knowledge flow between text and vision modalities,
enabling them to refine their semantics mutually. HiCroPL routes knowledge
flows by leveraging the complementary strengths of text and vision. In early
layers, text prompts inject relatively clear semantics into visual prompts
through a hierarchical knowledge mapper, enhancing the representation of
low-level visual semantics. In later layers, visual prompts encoding specific
task-relevant objects flow back to refine text prompts, enabling deeper
alignment. Crucially, our hierarchical knowledge mapper allows representations
at multi-scales to be fused, ensuring that deeper representations retain
transferable shallow semantics thereby enhancing generalization. We further
introduce a lightweight layer-specific knowledge proxy to enable efficient
cross-modal interactions. Extensive evaluations across four tasks demonstrate
HiCroPL's superior performance, achieving state-of-the-art results on 11
benchmarks with significant improvements. Code is available at:
https://github.com/zzeoZheng/HiCroPL.

</details>


### [78] [Language Integration in Fine-Tuning Multimodal Large Language Models for Image-Based Regression](https://arxiv.org/abs/2507.14997)
*Roy H. Jennings,Genady Paikin,Roy Shaul,Evgeny Soloveichik*

Main category: cs.CV

TL;DR: 论文提出RvTC方法，通过灵活的基于分箱的分类替代预设词汇分类，在图像评估任务中实现最佳性能，并证明数据特定提示能显著提升多模态大语言模型的表现。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在图像回归任务中表现不佳，预设词汇和通用提示无法利用文本输入的语义理解。

Method: 提出Regression via Transformer-Based Classification (RvTC)，采用基于分箱的灵活分类方法，并验证数据特定提示的有效性。

Result: RvTC在四个图像评估数据集上实现最佳性能，数据特定提示将AVA数据集的相关系数从0.83提升至0.90。

Conclusion: 语义提示信息对多模态回归任务至关重要，RvTC方法为图像评估提供了更优解决方案。

Abstract: Multimodal Large Language Models (MLLMs) show promise for image-based
regression tasks, but current approaches face key limitations. Recent methods
fine-tune MLLMs using preset output vocabularies and generic task-level prompts
(e.g., "How would you rate this image?"), assuming this mimics human rating
behavior. Our analysis reveals these approaches provide no benefit over
image-only training. Models using preset vocabularies and generic prompts
perform equivalently to image-only models, failing to leverage semantic
understanding from textual input. We propose Regression via Transformer-Based
Classification (RvTC), which replaces vocabulary-constrained classification
with a flexible bin-based approach. Unlike approaches that address
discretization errors through complex distributional modeling, RvTC eliminates
manual vocabulary crafting through straightforward bin increase, achieving
state-of-the-art performance on four image assessment datasets using only
images. More importantly, we demonstrate that data-specific prompts
dramatically improve performance. Unlike generic task descriptions, prompts
containing semantic information about specific images enable MLLMs to leverage
cross-modal understanding. On the AVA dataset, adding challenge titles to
prompts improves correlations from 0.83 to 0.90, a new state-of-the-art. We
demonstrate through empirical evidence from the AVA and AGIQA-3k datasets that
MLLMs benefit from semantic prompt information surpassing mere statistical
biases. This underscores the importance of incorporating meaningful textual
context in multimodal regression tasks.

</details>


### [79] [Axis-Aligned Document Dewarping](https://arxiv.org/abs/2507.15000)
*Chaoyun Wang,I-Chao Shen,Takeo Igarashi,Nanning Zheng,Caigui Jiang*

Main category: cs.CV

TL;DR: 提出了一种基于轴对齐几何约束的文档去扭曲方法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法依赖标注数据，未充分利用文档的几何特性。

Method: 在训练阶段引入轴对齐几何约束，推理阶段采用轴对齐预处理策略。

Result: 在多个基准测试中达到SOTA，AAD指标提升18.2%~34.5%。

Conclusion: 该方法通过几何约束和预处理策略，显著提升了文档去扭曲的效果。

Abstract: Document dewarping is crucial for many applications. However, existing
learning-based methods primarily rely on supervised regression with annotated
data without leveraging the inherent geometric properties in physical documents
to the dewarping process. Our key insight is that a well-dewarped document is
characterized by transforming distorted feature lines into axis-aligned ones.
This property aligns with the inherent axis-aligned nature of the discrete grid
geometry in planar documents. In the training phase, we propose an axis-aligned
geometric constraint to enhance document dewarping. In the inference phase, we
propose an axis alignment preprocessing strategy to reduce the dewarping
difficulty. In the evaluation phase, we introduce a new metric, Axis-Aligned
Distortion (AAD), that not only incorporates geometric meaning and aligns with
human visual perception but also demonstrates greater robustness. As a result,
our method achieves SOTA results on multiple existing benchmarks and achieves
18.2%~34.5% improvements on the AAD metric.

</details>


### [80] [FastSmoothSAM: A Fast Smooth Method For Segment Anything Model](https://arxiv.org/abs/2507.15008)
*Jiasheng Xu,Yewang Chen*

Main category: cs.CV

TL;DR: 本文提出了一种基于B样条曲线拟合的优化方法，用于提升FastSAM的边缘质量，解决了其生成的锯齿边缘问题，同时保持了实时处理能力。


<details>
  <summary>Details</summary>
Motivation: FastSAM虽然实现了实时分割，但其生成的边缘存在锯齿问题，影响了分割的视觉质量和分析精度。

Method: 采用四阶段优化流程，结合两轮B样条曲线拟合，平滑锯齿边缘。

Result: 显著提升了边缘的视觉质量和分析精度，同时保持了实时处理能力。

Conclusion: 该方法增强了FastSAM的实用性，适用于工业自动化、医疗影像和自主系统等需要精确高效边缘识别的场景。

Abstract: Accurately identifying and representing object edges is a challenging task in
computer vision and image processing. The Segment Anything Model (SAM) has
significantly influenced the field of image segmentation, but suffers from high
memory consumption and long inference times, limiting its efficiency in
real-time applications. To address these limitations, Fast Segment Anything
(FastSAM) was proposed, achieving real-time segmentation. However, FastSAM
often generates jagged edges that deviate from the true object shapes.
Therefore, this paper introduces a novel refinement approach using B-Spline
curve fitting techniques to enhance the edge quality in FastSAM. Leveraging the
robust shape control and flexible geometric construction of B-Splines, a
four-stage refining process involving two rounds of curve fitting is employed
to effectively smooth jagged edges. This approach significantly improves the
visual quality and analytical accuracy of object edges without compromising
critical geometric information. The proposed method improves the practical
utility of FastSAM by improving segmentation accuracy while maintaining
real-time processing capabilities. This advancement unlocks greater potential
for FastSAM technology in various real-world scenarios, such as industrial
automation, medical imaging, and autonomous systems, where precise and
efficient edge recognition is crucial.

</details>


### [81] [Towards Video Thinking Test: A Holistic Benchmark for Advanced Video Reasoning and Understanding](https://arxiv.org/abs/2507.15028)
*Yuanhan Zhang,Yunice Chew,Yuhao Dong,Aria Leo,Bo Hu,Ziwei Liu*

Main category: cs.CV

TL;DR: 论文提出了Video-TT测试，用于评估视频大语言模型在视频理解中的正确性和鲁棒性，发现其与人类表现存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在视频理解中的正确性和鲁棒性方面与人类智能存在差距，缺乏合适的评估基准。

Method: 引入Video-TT测试，包含1,000个YouTube Shorts视频，每个视频配有一个开放性问题及四个对抗性问题。

Result: 评估结果显示，视频大语言模型的表现与人类存在显著差距。

Conclusion: Video-TT揭示了视频大语言模型在复杂视觉叙事理解上的不足，为未来研究提供了方向。

Abstract: Human intelligence requires correctness and robustness, with the former being
foundational for the latter. In video understanding, correctness ensures the
accurate interpretation of visual content, and robustness maintains consistent
performance in challenging conditions. Despite advances in video large language
models (video LLMs), existing benchmarks inadequately reflect the gap between
these models and human intelligence in maintaining correctness and robustness
in video interpretation. We introduce the Video Thinking Test (Video-TT), to
assess if video LLMs can interpret real-world videos as effectively as humans.
Video-TT reflects genuine gaps in understanding complex visual narratives, and
evaluates robustness against natural adversarial questions. Video-TT comprises
1,000 YouTube Shorts videos, each with one open-ended question and four
adversarial questions that probe visual and narrative complexity. Our
evaluation shows a significant gap between video LLMs and human performance.

</details>


### [82] [OpenBreastUS: Benchmarking Neural Operators for Wave Imaging Using Breast Ultrasound Computed Tomography](https://arxiv.org/abs/2507.15035)
*Zhijun Zeng,Youjia Zheng,Hao Hu,Zeyuan Dong,Yihang Zheng,Xinliang Liu,Jinzhuo Wang,Zuoqiang Shi,Linfeng Zhang,Yubing Li,He Sun*

Main category: cs.CV

TL;DR: OpenBreastUS是一个大规模波动方程数据集，旨在解决传统数值求解器计算量大且不稳定的问题，通过提供8000个解剖学真实的人体乳房模型和1600万次频域波动模拟，为神经算子提供全面基准测试。


<details>
  <summary>Details</summary>
Motivation: 传统波动方程数值求解器计算量大且不稳定，限制了实时成像应用；现有神经算子数据集过于简化，无法满足实际成像需求。

Method: 提出OpenBreastUS数据集，包含8000个真实乳房模型和1600万次频域波动模拟，用于神经算子的基准测试。

Result: 首次展示了神经算子求解器在人体乳房活体成像中的高效应用。

Conclusion: OpenBreastUS为开发创新神经PDE求解器提供了平台，并推动了其在真实医学成像中的部署。

Abstract: Accurate and efficient simulation of wave equations is crucial in
computational wave imaging applications, such as ultrasound computed tomography
(USCT), which reconstructs tissue material properties from observed scattered
waves. Traditional numerical solvers for wave equations are computationally
intensive and often unstable, limiting their practical applications for
quasi-real-time image reconstruction. Neural operators offer an innovative
approach by accelerating PDE solving using neural networks; however, their
effectiveness in realistic imaging is limited because existing datasets
oversimplify real-world complexity. In this paper, we present OpenBreastUS, a
large-scale wave equation dataset designed to bridge the gap between
theoretical equations and practical imaging applications. OpenBreastUS includes
8,000 anatomically realistic human breast phantoms and over 16 million
frequency-domain wave simulations using real USCT configurations. It enables a
comprehensive benchmarking of popular neural operators for both forward
simulation and inverse imaging tasks, allowing analysis of their performance,
scalability, and generalization capabilities. By offering a realistic and
extensive dataset, OpenBreastUS not only serves as a platform for developing
innovative neural PDE solvers but also facilitates their deployment in
real-world medical imaging problems. For the first time, we demonstrate
efficient in vivo imaging of the human breast using neural operator solvers.

</details>


### [83] [EBA-AI: Ethics-Guided Bias-Aware AI for Efficient Underwater Image Enhancement and Coral Reef Monitoring](https://arxiv.org/abs/2507.15036)
*Lyes Saad Saoud,Irfan Hussain*

Main category: cs.CV

TL;DR: EBA-AI是一个基于伦理和偏见的AI框架，用于水下图像增强，解决数据集偏见、高计算成本和透明度问题。


<details>
  <summary>Details</summary>
Motivation: 水下图像增强对海洋保护（如珊瑚礁监测）至关重要，但现有AI模型存在数据集偏见、高计算成本和缺乏透明度的问题。

Method: EBA-AI利用CLIP嵌入检测和减轻数据集偏见，集成自适应处理优化能效，并引入不确定性估计和可解释性技术。

Result: 实验表明，EBA-AI在PSNR略有下降（1.0 dB）的情况下显著减少GPU使用，实现实时可行性，并在公平性和可解释性上优于其他模型。

Conclusion: EBA-AI通过平衡效率、公平性和可解释性，为可持续、偏见感知和高效计算的海洋保护提供了解决方案。

Abstract: Underwater image enhancement is vital for marine conservation, particularly
coral reef monitoring. However, AI-based enhancement models often face dataset
bias, high computational costs, and lack of transparency, leading to potential
misinterpretations. This paper introduces EBA-AI, an ethics-guided bias-aware
AI framework to address these challenges. EBA-AI leverages CLIP embeddings to
detect and mitigate dataset bias, ensuring balanced representation across
varied underwater environments. It also integrates adaptive processing to
optimize energy efficiency, significantly reducing GPU usage while maintaining
competitive enhancement quality. Experiments on LSUI400, Oceanex, and UIEB100
show that while PSNR drops by a controlled 1.0 dB, computational savings enable
real-time feasibility for large-scale marine monitoring. Additionally,
uncertainty estimation and explainability techniques enhance trust in AI-driven
environmental decisions. Comparisons with CycleGAN, FunIEGAN, RAUNENet,
WaterNet, UGAN, PUGAN, and UTUIE validate EBA-AI's effectiveness in balancing
efficiency, fairness, and interpretability in underwater image processing. By
addressing key limitations of AI-driven enhancement, this work contributes to
sustainable, bias-aware, and computationally efficient marine conservation
efforts. For interactive visualizations, animations, source code, and access to
the preprint, visit: https://lyessaadsaoud.github.io/EBA-AI/

</details>


### [84] [OmniVTON: Training-Free Universal Virtual Try-On](https://arxiv.org/abs/2507.15037)
*Zhaotong Yang,Yuhui Li,Shengfeng He,Xinzhe Li,Yangyang Xu,Junyu Dong,Yong Du*

Main category: cs.CV

TL;DR: OmniVTON是一种无需训练的统一虚拟试穿框架，通过解耦服装和姿势条件，实现跨场景的高保真纹理和姿势一致性。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿技术在跨域泛化和数据偏差方面存在局限，缺乏统一的解决方案。

Method: 提出服装先验生成机制和连续边界缝合技术以保留细节，利用DDIM反演实现精确姿势对齐。

Result: 实验表明OmniVTON在多样数据集和场景中表现优异，首次实现多人物虚拟试穿。

Conclusion: OmniVTON通过解耦条件，解决了扩散模型的多条件处理偏差，成为首个跨场景通用框架。

Abstract: Image-based Virtual Try-On (VTON) techniques rely on either supervised
in-shop approaches, which ensure high fidelity but struggle with cross-domain
generalization, or unsupervised in-the-wild methods, which improve adaptability
but remain constrained by data biases and limited universality. A unified,
training-free solution that works across both scenarios remains an open
challenge. We propose OmniVTON, the first training-free universal VTON
framework that decouples garment and pose conditioning to achieve both texture
fidelity and pose consistency across diverse settings. To preserve garment
details, we introduce a garment prior generation mechanism that aligns clothing
with the body, followed by continuous boundary stitching technique to achieve
fine-grained texture retention. For precise pose alignment, we utilize DDIM
inversion to capture structural cues while suppressing texture interference,
ensuring accurate body alignment independent of the original image textures. By
disentangling garment and pose constraints, OmniVTON eliminates the bias
inherent in diffusion models when handling multiple conditions simultaneously.
Experimental results demonstrate that OmniVTON achieves superior performance
across diverse datasets, garment types, and application scenarios. Notably, it
is the first framework capable of multi-human VTON, enabling realistic garment
transfer across multiple individuals in a single scene. Code is available at
https://github.com/Jerome-Young/OmniVTON

</details>


### [85] [StableAnimator++: Overcoming Pose Misalignment and Face Distortion for Human Image Animation](https://arxiv.org/abs/2507.15064)
*Shuyuan Tu,Zhen Xing,Xintong Han,Zhi-Qi Cheng,Qi Dai,Chong Luo,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: StableAnimator++是一种基于视频扩散模型的ID保持框架，通过可学习的姿态对齐和分布感知ID适配器，解决了现有方法在身份一致性上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前的人体图像动画扩散模型在参考图像和驱动视频差异较大时难以保持身份一致性。

Method: 采用可学习层预测相似变换矩阵对齐姿态，结合SVD引导；使用预训练编码器提取图像和面部嵌入，并通过全局内容感知面部编码器优化；引入分布感知ID适配器减少干扰；在推理阶段集成HJB面部优化。

Result: 实验证明StableAnimator++在质量和数量上均优于现有方法。

Conclusion: StableAnimator++通过创新的对齐和优化方法，显著提升了身份一致性和生成质量。

Abstract: Current diffusion models for human image animation often struggle to maintain
identity (ID) consistency, especially when the reference image and driving
video differ significantly in body size or position. We introduce
StableAnimator++, the first ID-preserving video diffusion framework with
learnable pose alignment, capable of generating high-quality videos conditioned
on a reference image and a pose sequence without any post-processing. Building
upon a video diffusion model, StableAnimator++ contains carefully designed
modules for both training and inference, striving for identity consistency. In
particular, StableAnimator++ first uses learnable layers to predict the
similarity transformation matrices between the reference image and the driven
poses via injecting guidance from Singular Value Decomposition (SVD). These
matrices align the driven poses with the reference image, mitigating
misalignment to a great extent. StableAnimator++ then computes image and face
embeddings using off-the-shelf encoders, refining the face embeddings via a
global content-aware Face Encoder. To further maintain ID, we introduce a
distribution-aware ID Adapter that counteracts interference caused by temporal
layers while preserving ID via distribution alignment. During the inference
stage, we propose a novel Hamilton-Jacobi-Bellman (HJB) based face optimization
integrated into the denoising process, guiding the diffusion trajectory for
enhanced facial fidelity. Experiments on benchmarks show the effectiveness of
StableAnimator++ both qualitatively and quantitatively.

</details>


### [86] [Rethinking Pan-sharpening: Principled Design, Unified Training, and a Universal Loss Surpass Brute-Force Scaling](https://arxiv.org/abs/2507.15059)
*Ran Zhang,Xuanhua He,Li Xueheng,Ke Cao,Liu Liu,Wenbo Xu,Fang Jiabin,Yang Qize,Jie Zhang*

Main category: cs.CV

TL;DR: 提出PanTiny，一种轻量级单步全色锐化框架，通过多数据集联合训练和复合损失函数，实现高效且泛化性强的性能。


<details>
  <summary>Details</summary>
Motivation: 当前全色锐化模型趋向于大而复杂，计算开销高且泛化性差，本文旨在解决这一问题。

Method: 提出PanTiny框架，采用多数据集联合训练（WV2、WV3、GF2）和复合损失函数。

Result: PanTiny在性能和效率上优于大型专用模型，泛化能力显著提升。

Conclusion: 通过模型设计、训练范式和损失函数的优化，可以超越暴力扩展，推动高效、泛化性强且数据敏感的模型发展。

Abstract: The field of pan-sharpening has recently seen a trend towards increasingly
large and complex models, often trained on single, specific satellite datasets.
This approach, however, leads to high computational overhead and poor
generalization on full resolution data, a paradigm we challenge in this paper.
In response to this issue, we propose PanTiny, a lightweight, single-step
pan-sharpening framework designed for both efficiency and robust performance.
More critically, we introduce multiple-in-one training paradigm, where a
single, compact model is trained simultaneously on three distinct satellite
datasets (WV2, WV3, and GF2) with different resolution and spectral
information. Our experiments show that this unified training strategy not only
simplifies deployment but also significantly boosts generalization on
full-resolution data. Further, we introduce a universally powerful composite
loss function that elevates the performance of almost all of models for
pan-sharpening, pushing state-of-the-art metrics into a new era. Our PanTiny
model, benefiting from these innovations, achieves a superior
performance-to-efficiency balance, outperforming most larger, specialized
models. Through extensive ablation studies, we validate that principled
engineering in model design, training paradigms, and loss functions can surpass
brute-force scaling. Our work advocates for a community-wide shift towards
creating efficient, generalizable, and data-conscious models for
pan-sharpening. The code is available at
https://github.com/Zirconium233/PanTiny .

</details>


### [87] [BleedOrigin: Dynamic Bleeding Source Localization in Endoscopic Submucosal Dissection via Dual-Stage Detection and Tracking](https://arxiv.org/abs/2507.15094)
*Mengya Xu,Rulin Zhou,An Wang,Chaoyang Lyu,Zhen Li,Ning Zhong,Hongliang Ren*

Main category: cs.CV

TL;DR: 论文提出了首个ESD出血源数据集BleedOrigin-Bench和双阶段检测-跟踪框架BleedOrigin-Net，显著提升了出血源定位的准确性和实时性。


<details>
  <summary>Details</summary>
Motivation: 解决ESD术中出血源实时定位和连续监测的挑战，填补现有AI方法在出血源检测和跟踪上的空白。

Method: 引入BleedOrigin-Bench数据集和BleedOrigin-Net双阶段框架，结合检测与跟踪技术。

Result: 在出血起始检测、初始源定位和点跟踪方面分别达到96.85%、70.24%和96.11%的准确率。

Conclusion: BleedOrigin-Net在ESD出血源定位中表现出色，为AI辅助手术提供了有效工具。

Abstract: Intraoperative bleeding during Endoscopic Submucosal Dissection (ESD) poses
significant risks, demanding precise, real-time localization and continuous
monitoring of the bleeding source for effective hemostatic intervention. In
particular, endoscopists have to repeatedly flush to clear blood, allowing only
milliseconds to identify bleeding sources, an inefficient process that prolongs
operations and elevates patient risks. However, current Artificial Intelligence
(AI) methods primarily focus on bleeding region segmentation, overlooking the
critical need for accurate bleeding source detection and temporal tracking in
the challenging ESD environment, which is marked by frequent visual
obstructions and dynamic scene changes. This gap is widened by the lack of
specialized datasets, hindering the development of robust AI-assisted guidance
systems. To address these challenges, we introduce BleedOrigin-Bench, the first
comprehensive ESD bleeding source dataset, featuring 1,771 expert-annotated
bleeding sources across 106,222 frames from 44 procedures, supplemented with
39,755 pseudo-labeled frames. This benchmark covers 8 anatomical sites and 6
challenging clinical scenarios. We also present BleedOrigin-Net, a novel
dual-stage detection-tracking framework for the bleeding source localization in
ESD procedures, addressing the complete workflow from bleeding onset detection
to continuous spatial tracking. We compare with widely-used object detection
models (YOLOv11/v12), multimodal large language models, and point tracking
methods. Extensive evaluation demonstrates state-of-the-art performance,
achieving 96.85% frame-level accuracy ($\pm\leq8$ frames) for bleeding onset
detection, 70.24% pixel-level accuracy ($\leq100$ px) for initial source
detection, and 96.11% pixel-level accuracy ($\leq100$ px) for point tracking.

</details>


### [88] [Cross-Domain Few-Shot Learning with Coalescent Projections and Latent Space Reservation](https://arxiv.org/abs/2507.15243)
*Naeem Paeedeh,Mahardhika Pratama,Wolfgang Mayer,Jimmy Cao,Ryszard Kowlczyk*

Main category: cs.CV

TL;DR: 提出了一种名为Coalescent Projection（CP）的新方法，结合伪类生成和自监督变换，解决了CD-FSL中参数过多导致过拟合的问题，并在BSCD-FSL基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决跨域少样本学习（CD-FSL）中因参数过多导致过拟合的问题，提升模型性能。

Method: 提出Coalescent Projection（CP）作为软提示的替代方案，结合伪类生成和自监督变换（SSTs）来优化模型。

Result: 在BSCD-FSL基准测试中表现优异，特别是在极端域偏移场景下。

Conclusion: CP方法有效解决了CD-FSL中的过拟合问题，显著提升了模型性能。

Abstract: Despite the progress in Cross-Domain Few-Shot Learning (CD-FSL), a model
pre-trained with DINO combined with a prototypical classifier outperforms the
latest SOTA methods. A crucial limitation that needs to be overcome is that
updating too many parameters of the transformers leads to overfitting due to
the scarcity of labeled samples. To address this challenge, we propose a new
concept, Coalescent Projection (CP), as an effective successor to soft prompts.
Additionally, we propose a novel pseudo-class generation method combined with
Self-Supervised Transformations (SSTs) that relies solely on the base domain to
prepare the network for encountering unseen samples from different domains. The
proposed method exhibits its effectiveness in comprehensive experiments on the
extreme domain shift scenario of the BSCD-FSL benchmark. Our code is published
at https://github.com/Naeem-Paeedeh/CPLSR.

</details>


### [89] [Aesthetics is Cheap, Show me the Text: An Empirical Evaluation of State-of-the-Art Generative Models for OCR](https://arxiv.org/abs/2507.15085)
*Peirong Zhang,Haowei Xu,Jiaxin Zhang,Guitao Xu,Xuhan Zheng,Zhenhua Yang,Junle Liu,Yuyi Zhang,Lianwen Jin*

Main category: cs.CV

TL;DR: 论文评估了当前最先进的生成模型在文本图像生成和编辑方面的能力，并提出了将其作为通用模型基础技能的建议。


<details>
  <summary>Details</summary>
Motivation: 研究现代生成模型是否能掌握文本图像生成和编辑的复杂性，并推动其成为通用模型的基础技能。

Method: 通过33个代表性任务评估6种模型，涵盖文档、手写文本、场景文本、艺术文本和复杂布局文本。

Result: 发现了当前生成模型在OCR任务中的弱点，并提出了改进方向。

Conclusion: 建议将逼真的文本图像生成和编辑作为通用模型的基础技能，而非依赖专用解决方案。

Abstract: Text image is a unique and crucial information medium that integrates visual
aesthetics and linguistic semantics in modern e-society. Due to their subtlety
and complexity, the generation of text images represents a challenging and
evolving frontier in the image generation field. The recent surge of
specialized image generators (\emph{e.g.}, Flux-series) and unified generative
models (\emph{e.g.}, GPT-4o), which demonstrate exceptional fidelity, raises a
natural question: can they master the intricacies of text image generation and
editing? Motivated by this, we assess current state-of-the-art generative
models' capabilities in terms of text image generation and editing. We
incorporate various typical optical character recognition (OCR) tasks into our
evaluation and broaden the concept of text-based generation tasks into OCR
generative tasks. We select 33 representative tasks and categorize them into
five categories: document, handwritten text, scene text, artistic text, and
complex \& layout-rich text. For comprehensive evaluation, we examine six
models across both closed-source and open-source domains, using tailored,
high-quality image inputs and prompts. Through this evaluation, we draw crucial
observations and identify the weaknesses of current generative models for OCR
tasks. We argue that photorealistic text image generation and editing should be
internalized as foundational skills into general-domain generative models,
rather than being delegated to specialized solutions, and we hope this
empirical analysis can provide valuable insights for the community to achieve
this goal. This evaluation is online and will be continuously updated at our
GitHub repository.

</details>


### [90] [Conditional Video Generation for High-Efficiency Video Compression](https://arxiv.org/abs/2507.15269)
*Fangqiu Yi,Jingyu Xu,Jiawei Shao,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 提出了一种基于条件扩散模型的视频压缩框架，通过生成模型从稀疏信号中重建视频，显著提升了感知质量。


<details>
  <summary>Details</summary>
Motivation: 利用条件扩散模型在人类视觉感知对齐重建中的优势，优化视频压缩的感知质量。

Method: 将视频压缩任务重新定义为条件生成任务，引入多粒度条件、紧凑表示和多条件训练模块。

Result: 在感知质量指标（如FVD和LPIPS）上显著优于传统和神经编解码器，尤其是在高压缩比下。

Conclusion: 该方法通过条件扩散模型实现了感知优化的视频压缩，具有高效和鲁棒性。

Abstract: Perceptual studies demonstrate that conditional diffusion models excel at
reconstructing video content aligned with human visual perception. Building on
this insight, we propose a video compression framework that leverages
conditional diffusion models for perceptually optimized reconstruction.
Specifically, we reframe video compression as a conditional generation task,
where a generative model synthesizes video from sparse, yet informative
signals. Our approach introduces three key modules: (1) Multi-granular
conditioning that captures both static scene structure and dynamic
spatio-temporal cues; (2) Compact representations designed for efficient
transmission without sacrificing semantic richness; (3) Multi-condition
training with modality dropout and role-aware embeddings, which prevent
over-reliance on any single modality and enhance robustness. Extensive
experiments show that our method significantly outperforms both traditional and
neural codecs on perceptual quality metrics such as Fr\'echet Video Distance
(FVD) and LPIPS, especially under high compression ratios.

</details>


### [91] [Visual Place Recognition for Large-Scale UAV Applications](https://arxiv.org/abs/2507.15089)
*Ioannis Tsampikos Papapetros,Ioannis Kansizoglou,Antonios Gasteratos*

Main category: cs.CV

TL;DR: 论文提出了LASED数据集和可转向CNN，以解决无人机视觉地点识别中的数据集不足和旋转模糊问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 无人机视觉地点识别面临大规模高空数据集稀缺和图像旋转模糊的挑战，限制了模型的泛化能力。

Method: 引入LASED大规模数据集，并采用可转向CNN处理旋转模糊，生成方向不变的特征表示。

Result: 实验表明，LASED训练的模型召回率显著提升，可转向CNN比传统CNN平均提高12%的召回率。

Conclusion: 结合大规模数据集和旋转等变网络，显著增强了无人机视觉地点识别的鲁棒性和泛化能力。

Abstract: Visual Place Recognition (vPR) plays a crucial role in Unmanned Aerial
Vehicle (UAV) navigation, enabling robust localization across diverse
environments. Despite significant advancements, aerial vPR faces unique
challenges due to the limited availability of large-scale, high-altitude
datasets, which limits model generalization, along with the inherent rotational
ambiguity in UAV imagery. To address these challenges, we introduce LASED, a
large-scale aerial dataset with approximately one million images,
systematically sampled from 170,000 unique locations throughout Estonia over a
decade, offering extensive geographic and temporal diversity. Its structured
design ensures clear place separation significantly enhancing model training
for aerial scenarios. Furthermore, we propose the integration of steerable
Convolutional Neural Networks (CNNs) to explicitly handle rotational variance,
leveraging their inherent rotational equivariance to produce robust,
orientation-invariant feature representations. Our extensive benchmarking
demonstrates that models trained on LASED achieve significantly higher recall
compared to those trained on smaller, less diverse datasets, highlighting the
benefits of extensive geographic coverage and temporal diversity. Moreover,
steerable CNNs effectively address rotational ambiguity inherent in aerial
imagery, consistently outperforming conventional convolutional architectures,
achieving on average 12\% recall improvement over the best-performing
non-steerable network. By combining structured, large-scale datasets with
rotation-equivariant neural networks, our approach significantly enhances model
robustness and generalization for aerial vPR.

</details>


### [92] [ExDD: Explicit Dual Distribution Learning for Surface Defect Detection via Diffusion Synthesis](https://arxiv.org/abs/2507.15335)
*Muhammad Aqeel,Federico Leonardi,Francesco Setti*

Main category: cs.CV

TL;DR: ExDD框架通过显式建模双特征分布，解决了工业缺陷检测中单类异常检测的局限性，利用潜在扩散模型生成合成缺陷数据，并通过邻域感知评分机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 工业缺陷检测系统在单类异常检测范式下存在局限性，假设异常分布均匀且难以应对真实制造环境中的数据稀缺问题。

Method: 提出ExDD框架，显式建模双特征分布，利用并行记忆库捕捉正常和异常模式的统计特性，结合潜在扩散模型生成合成缺陷数据，并通过邻域感知评分机制融合距离度量。

Result: 在KSDD2数据集上表现优异（94.2% I-AUROC, 97.7% P-AUROC），最佳增强效果在100个合成样本时达到。

Conclusion: ExDD框架通过双分布建模和合成数据生成，显著提升了工业缺陷检测的性能，解决了数据稀缺和异常分布假设问题。

Abstract: Industrial defect detection systems face critical limitations when confined
to one-class anomaly detection paradigms, which assume uniform outlier
distributions and struggle with data scarcity in realworld manufacturing
environments. We present ExDD (Explicit Dual Distribution), a novel framework
that transcends these limitations by explicitly modeling dual feature
distributions. Our approach leverages parallel memory banks that capture the
distinct statistical properties of both normality and anomalous patterns,
addressing the fundamental flaw of uniform outlier assumptions. To overcome
data scarcity, we employ latent diffusion models with domain-specific textual
conditioning, generating in-distribution synthetic defects that preserve
industrial context. Our neighborhood-aware ratio scoring mechanism elegantly
fuses complementary distance metrics, amplifying signals in regions exhibiting
both deviation from normality and similarity to known defect patterns.
Experimental validation on KSDD2 demonstrates superior performance (94.2%
I-AUROC, 97.7% P-AUROC), with optimal augmentation at 100 synthetic samples.

</details>


### [93] [EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent](https://arxiv.org/abs/2507.15428)
*Jiaao Li,Kaiyuan Li,Chen Gao,Yong Li,Xinlei Chen*

Main category: cs.CV

TL;DR: 提出了一种名为EgoPrune的无训练令牌剪枝方法，专为自我运动视频推理设计，通过关键帧选择、视角感知冗余过滤和基于MMR的令牌选择，显著提升了效率。


<details>
  <summary>Details</summary>
Motivation: 自我运动视频是具身AI代理的主要视觉输入，现有方法因计算成本高且未充分利用时空连续性而不适用。

Method: EgoPrune包括关键帧选择、视角感知冗余过滤（PARF）和基于MMR的令牌选择器。

Result: 在两个基准测试中表现优于现有方法，显著降低了计算资源消耗，并在边缘设备上验证了实用性。

Conclusion: EgoPrune是一种高效且适用于实际部署的自我运动视频推理方法。

Abstract: Egomotion videos are first-person recordings where the view changes
continuously due to the agent's movement. As they serve as the primary visual
input for embodied AI agents, making egomotion video reasoning more efficient
is therefore essential for real-world deployment. Recent advances in
vision-language models have enabled strong multimodal reasoning capabilities,
but their computational cost remains prohibitive for long, redundant video
inputs. Existing token pruning methods, typically designed for third-person
videos, fail to leverage the spatiotemporal continuity and motion constraints
inherent in egomotion settings. To address this, we propose EgoPrune, a
training-free token pruning method tailored for egomotion video reasoning.
EgoPrune comprises three components: a keyframe selector adapted from EmbodiedR
for temporally efficient sampling; Perspective-Aware Redundancy Filtering
(PARF), which aligns visual tokens using perspective transformations and
removes redundant tokens; and a Maximal Marginal Relevance (MMR)-based token
selector that jointly considers visual-text relevance and intra-frame
diversity. Experiments on two egomotion video benchmarks show that EgoPrune
consistently outperforms prior training-free methods across various pruning
ratios while significantly reducing FLOPs, memory usage, and latency. Moreover,
we deploy EgoPrune on an embodied agent equipped with a Jetson Orin NX 16GB
edge device, demonstrating its real-world efficiency and suitability for
on-device egomotion video reasoning.

</details>


### [94] [LoopNet: A Multitasking Few-Shot Learning Approach for Loop Closure in Large Scale SLAM](https://arxiv.org/abs/2507.15109)
*Mohammad-Maher Nakshbandi,Ziad Sharawy,Sorin Grigorescu*

Main category: cs.CV

TL;DR: LoopNet方法通过改进的ResNet架构和在线少样本学习，解决了SLAM闭环检测的精度和实时计算问题，并引入了新数据集LoopDB。


<details>
  <summary>Details</summary>
Motivation: 解决SLAM系统中闭环检测精度低和嵌入式硬件实时计算的挑战。

Method: 采用多任务ResNet变体，结合在线少样本学习和DISK描述符，优化嵌入式设备性能。

Result: LoopNet在多变条件下表现优于传统方法和手工特征。

Conclusion: LoopNet提供高效闭环检测方案，并开源代码和数据集LoopDB。

Abstract: One of the main challenges in the Simultaneous Localization and Mapping
(SLAM) loop closure problem is the recognition of previously visited places. In
this work, we tackle the two main problems of real-time SLAM systems: 1) loop
closure detection accuracy and 2) real-time computation constraints on the
embedded hardware. Our LoopNet method is based on a multitasking variant of the
classical ResNet architecture, adapted for online retraining on a dynamic
visual dataset and optimized for embedded devices. The online retraining is
designed using a few-shot learning approach. The architecture provides both an
index into the queried visual dataset, and a measurement of the prediction
quality. Moreover, by leveraging DISK (DIStinctive Keypoints) descriptors,
LoopNet surpasses the limitations of handcrafted features and traditional deep
learning methods, offering better performance under varying conditions. Code is
available at https://github.com/RovisLab/LoopNet. Additinally, we introduce a
new loop closure benchmarking dataset, coined LoopDB, which is available at
https://github.com/RovisLab/LoopDB.

</details>


### [95] [GeMix: Conditional GAN-Based Mixup for Improved Medical Image Augmentation](https://arxiv.org/abs/2507.15577)
*Hugo Carlesso,Maria Eliza Patulea,Moncef Garouani,Radu Tudor Ionescu,Josiane Mothe*

Main category: cs.CV

TL;DR: GeMix是一种基于GAN的两阶段图像增强框架，通过标签感知插值生成更真实的图像，优于传统Mixup方法。


<details>
  <summary>Details</summary>
Motivation: 传统Mixup的像素级插值生成的图像不真实，尤其在医学等高风险应用中可能阻碍学习。

Method: 使用StyleGAN2-ADA生成器，通过Dirichlet和Beta分布采样标签向量，生成连续类流形上的图像。

Result: 在COVIDx-CT-3数据集上，GeMix结合真实数据提高了所有骨干网络的macro-F1，降低了COVID-19检测的假阴性率。

Conclusion: GeMix是传统Mixup的替代方案，提供更强的正则化和语义保真度，且不破坏现有训练流程。

Abstract: Mixup has become a popular augmentation strategy for image classification,
yet its naive pixel-wise interpolation often produces unrealistic images that
can hinder learning, particularly in high-stakes medical applications. We
propose GeMix, a two-stage framework that replaces heuristic blending with a
learned, label-aware interpolation powered by class-conditional GANs. First, a
StyleGAN2-ADA generator is trained on the target dataset. During augmentation,
we sample two label vectors from Dirichlet priors biased toward different
classes and blend them via a Beta-distributed coefficient. Then, we condition
the generator on this soft label to synthesize visually coherent images that
lie along a continuous class manifold. We benchmark GeMix on the large-scale
COVIDx-CT-3 dataset using three backbones (ResNet-50, ResNet-101,
EfficientNet-B0). When combined with real data, our method increases macro-F1
over traditional mixup for all backbones, reducing the false negative rate for
COVID-19 detection. GeMix is thus a drop-in replacement for pixel-space mixup,
delivering stronger regularization and greater semantic fidelity, without
disrupting existing training pipelines. We publicly release our code at
https://github.com/hugocarlesso/GeMix to foster reproducibility and further
research.

</details>


### [96] [Enhancing Visual Planning with Auxiliary Tasks and Multi-token Prediction](https://arxiv.org/abs/2507.15130)
*Ce Zhang,Yale Song,Ruta Desai,Michael Louis Iuzzolino,Joseph Tighe,Gedas Bertasius,Satwik Kottur*

Main category: cs.CV

TL;DR: VPA通过视频预测用户行为序列，提出Auxiliary Task Augmentation和Multi-token Prediction解决数据稀缺和结构化动作空间问题，VideoPlan在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决长时视觉规划中数据稀缺和动作空间结构化建模的挑战。

Method: 引入Auxiliary Task Augmentation增强模型规划能力，采用Multi-token Prediction显式建模动作空间。

Result: VideoPlan在COIN和CrossTask数据集上分别提升7.3%和3.4%，在Ego4D任务中表现优异。

Conclusion: VideoPlan通过创新方法显著提升VPA性能，适用于多种视觉规划任务。

Abstract: Visual Planning for Assistance (VPA) aims to predict a sequence of user
actions required to achieve a specified goal based on a video showing the
user's progress. Although recent advances in multimodal large language models
(MLLMs) have shown promising results in video understanding, long-horizon
visual planning remains a challenging problem. We identify two challenges in
training large MLLMs for video-based planning tasks: (1) scarcity of procedural
annotations, limiting the model's ability to learn procedural task dynamics
effectively, and (2) inefficiency of next-token prediction objective to
explicitly capture the structured action space for visual planning when
compared to free-form, natural language. To tackle data scarcity, we introduce
Auxiliary Task Augmentation. We design and train our model on auxiliary tasks
relevant to long-horizon video-based planning (e.g., goal prediction) to
augment the model's planning ability. To more explicitly model the structured
action space unique to visual planning tasks, we leverage Multi-token
Prediction, extending traditional next-token prediction by using multiple heads
to predict multiple future tokens during training. Our approach, VideoPlan,
achieves state-of-the-art VPA performance on the COIN and CrossTask datasets,
surpassing prior methods by 7.3% and 3.4%, respectively, when predicting 3
future actions. We further extend our method to the challenging Ego4D Long-term
Action Anticipation task, and show that it is on par with the state-of-the-art
approaches despite not using specialized egocentric features. Code will be made
available.

</details>


### [97] [Uncovering Critical Features for Deepfake Detection through the Lottery Ticket Hypothesis](https://arxiv.org/abs/2507.15636)
*Lisan Al Amin,Md. Ismail Hossain,Thanh Thi Nguyen,Tasnim Jahan,Mahbubul Islam,Faisal Quader*

Main category: cs.CV

TL;DR: 该研究应用彩票假设（LTH）于深度伪造检测，通过剪枝神经网络识别关键特征，发现子网络在高稀疏度下仍能保持性能。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术对信息完整性和社会信任构成挑战，现有检测方法模型庞大且机制不明确，难以在资源有限环境中部署。

Method: 采用彩票假设（LTH）进行迭代幅度剪枝，测试MesoNet、CNN-5和ResNet-18架构在OpenForensic和FaceForensics++数据集上的表现。

Result: MesoNet在80%稀疏度下保持56.2%准确率（基线为62.6%），仅需3,000参数；LTH剪枝方法优于一次性剪枝。

Conclusion: LTH剪枝方法高效且可转移，为可部署的深度伪造检测系统提供了潜力。

Abstract: Recent advances in deepfake technology have created increasingly convincing
synthetic media that poses significant challenges to information integrity and
social trust. While current detection methods show promise, their underlying
mechanisms remain poorly understood, and the large sizes of their models make
them challenging to deploy in resource-limited environments. This study
investigates the application of the Lottery Ticket Hypothesis (LTH) to deepfake
detection, aiming to identify the key features crucial for recognizing
deepfakes. We examine how neural networks can be efficiently pruned while
maintaining high detection accuracy. Through extensive experiments with
MesoNet, CNN-5, and ResNet-18 architectures on the OpenForensic and
FaceForensics++ datasets, we find that deepfake detection networks contain
winning tickets, i.e., subnetworks, that preserve performance even at
substantial sparsity levels. Our results indicate that MesoNet retains 56.2%
accuracy at 80% sparsity on the OpenForensic dataset, with only 3,000
parameters, which is about 90% of its baseline accuracy (62.6%). The results
also show that our proposed LTH-based iterative magnitude pruning approach
consistently outperforms one-shot pruning methods. Using Grad-CAM
visualization, we analyze how pruned networks maintain their focus on critical
facial regions for deepfake detection. Additionally, we demonstrate the
transferability of winning tickets across datasets, suggesting potential for
efficient, deployable deepfake detection systems.

</details>


### [98] [Event-based Graph Representation with Spatial and Motion Vectors for Asynchronous Object Detection](https://arxiv.org/abs/2507.15150)
*Aayush Atul Verma,Arpitsinh Vaghela,Bharatesh Chakravarthi,Kaustav Chanda,Yezhou Yang*

Main category: cs.CV

TL;DR: 提出了一种新颖的时空多图表示方法，用于改进事件传感器的稀疏数据建模，显著提升了检测精度和效率。


<details>
  <summary>Details</summary>
Motivation: 事件传感器的稀疏异步数据在转换为密集张量时会丧失其优势，现有图表示方法在时空动态建模上表现不佳。

Method: 构建解耦的空间图（B样条基函数建模全局结构）和时间图（基于运动向量的注意力建模局部动态），替代昂贵的3D核。

Result: 在Gen1和eTraM数据集上，检测精度提升6%，速度提升5倍，参数减少且计算成本不变。

Conclusion: 结构化图建模有效提升了异步视觉任务的性能。

Abstract: Event-based sensors offer high temporal resolution and low latency by
generating sparse, asynchronous data. However, converting this irregular data
into dense tensors for use in standard neural networks diminishes these
inherent advantages, motivating research into graph representations. While such
methods preserve sparsity and support asynchronous inference, their performance
on downstream tasks remains limited due to suboptimal modeling of
spatiotemporal dynamics. In this work, we propose a novel spatiotemporal
multigraph representation to better capture spatial structure and temporal
changes. Our approach constructs two decoupled graphs: a spatial graph
leveraging B-spline basis functions to model global structure, and a temporal
graph utilizing motion vector-based attention for local dynamic changes. This
design enables the use of efficient 2D kernels in place of computationally
expensive 3D kernels. We evaluate our method on the Gen1 automotive and eTraM
datasets for event-based object detection, achieving over a 6% improvement in
detection accuracy compared to previous graph-based works, with a 5x speedup,
reduced parameter count, and no increase in computational cost. These results
highlight the effectiveness of structured graph modeling for asynchronous
vision. Project page: eventbasedvision.github.io/eGSMV.

</details>


### [99] [LINR-PCGC: Lossless Implicit Neural Representations for Point Cloud Geometry Compression](https://arxiv.org/abs/2507.15686)
*Wenjie Huang,Qi Yang,Shuting Xia,He Huang,Zhu Li,Yiling Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于隐式神经表示（INR）的无损点云几何压缩方法LINR-PCGC，解决了现有方法对训练数据分布的依赖问题，并通过优化编码框架和网络设计显著提升了编码速度和压缩效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于AI的点云压缩方法依赖于特定训练数据分布，限制了实际应用。INR方法虽解决了分布依赖问题，但当前仅支持有损几何压缩，且编码时间和解码器大小受限。

Method: 提出了一种点云级别的编码框架和有效的网络初始化策略，减少了60%的编码时间；设计了一个基于多尺度SparseConv的轻量级编码网络，包含尺度上下文提取、子节点预测和模型压缩模块。

Result: 实验表明，LINR-PCGC在MVUB数据集上比G-PCC TMC13v23减少21.21%的比特流，比SparsePCGC减少21.95%。

Conclusion: LINR-PCGC是首个基于INR的无损点云几何压缩方法，显著提升了压缩效率和实用性。

Abstract: Existing AI-based point cloud compression methods struggle with dependence on
specific training data distributions, which limits their real-world deployment.
Implicit Neural Representation (INR) methods solve the above problem by
encoding overfitted network parameters to the bitstream, resulting in more
distribution-agnostic results. However, due to the limitation of encoding time
and decoder size, current INR based methods only consider lossy geometry
compression. In this paper, we propose the first INR based lossless point cloud
geometry compression method called Lossless Implicit Neural Representations for
Point Cloud Geometry Compression (LINR-PCGC). To accelerate encoding speed, we
design a group of point clouds level coding framework with an effective network
initialization strategy, which can reduce around 60% encoding time. A
lightweight coding network based on multiscale SparseConv, consisting of scale
context extraction, child node prediction, and model compression modules, is
proposed to realize fast inference and compact decoder size. Experimental
results show that our method consistently outperforms traditional and AI-based
methods: for example, with the convergence time in the MVUB dataset, our method
reduces the bitstream by approximately 21.21% compared to G-PCC TMC13v23 and
21.95% compared to SparsePCGC. Our project can be seen on
https://huangwenjie2023.github.io/LINR-PCGC/.

</details>


### [100] [MeshMamba: State Space Models for Articulated 3D Mesh Generation and Reconstruction](https://arxiv.org/abs/2507.15212)
*Yusuke Yoshiyasu,Leyuan Sun,Ryusuke Sagawa*

Main category: cs.CV

TL;DR: MeshMamba是一种基于Mamba-SSMs的神经网络模型，用于高效学习和生成3D关节网格模型，支持超过10,000个顶点的处理。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在处理大规模3D网格模型时的效率和扩展性问题，特别是捕捉衣物和手部几何形状的需求。

Method: 通过序列化技术将网格顶点排序，利用Mamba-SSMs处理，并设计了MambaDiff3D和Mamba-HMR两个子模型。

Result: MambaDiff3D在生成3D人体网格时表现优于现有方法，Mamba-HMR扩展了非参数化人体网格恢复的能力，支持全身模型。

Conclusion: MeshMamba在3D人体网格生成和恢复任务中表现出高效性和扩展性，为复杂几何形状的处理提供了新方法。

Abstract: In this paper, we introduce MeshMamba, a neural network model for learning 3D
articulated mesh models by employing the recently proposed Mamba State Space
Models (Mamba-SSMs). MeshMamba is efficient and scalable in handling a large
number of input tokens, enabling the generation and reconstruction of body mesh
models with more than 10,000 vertices, capturing clothing and hand geometries.
The key to effectively learning MeshMamba is the serialization technique of
mesh vertices into orderings that are easily processed by Mamba. This is
achieved by sorting the vertices based on body part annotations or the 3D
vertex locations of a template mesh, such that the ordering respects the
structure of articulated shapes. Based on MeshMamba, we design 1) MambaDiff3D,
a denoising diffusion model for generating 3D articulated meshes and 2)
Mamba-HMR, a 3D human mesh recovery model that reconstructs a human body shape
and pose from a single image. Experimental results showed that MambaDiff3D can
generate dense 3D human meshes in clothes, with grasping hands, etc., and
outperforms previous approaches in the 3D human shape generation task.
Additionally, Mamba-HMR extends the capabilities of previous non-parametric
human mesh recovery approaches, which were limited to handling body-only poses
using around 500 vertex tokens, to the whole-body setting with face and hands,
while achieving competitive performance in (near) real-time.

</details>


### [101] [ConformalSAM: Unlocking the Potential of Foundational Segmentation Models in Semi-Supervised Semantic Segmentation with Conformal Prediction](https://arxiv.org/abs/2507.15803)
*Danhui Chen,Ziquan Liu,Chuxi Yang,Dan Wang,Yan Yan,Yi Xu,Xiangyang Ji*

Main category: cs.CV

TL;DR: ConformalSAM利用基础分割模型SEEM生成未标注数据的预测掩码，并通过不确定性校准和自依赖训练策略提升半监督语义分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决像素级视觉任务中标注数据稀缺的问题，利用基础分割模型的泛化能力减轻标注负担。

Method: 提出ConformalSAM框架，结合SEEM生成预测掩码，通过不确定性校准筛选高置信度标签，并采用自依赖训练策略避免过拟合。

Result: 在三个标准半监督语义分割基准测试中，ConformalSAM表现优于现有方法，并可作为插件提升其他方法性能。

Conclusion: ConformalSAM通过有效利用基础分割模型和不确定性校准，显著提升了半监督语义分割的性能。

Abstract: Pixel-level vision tasks, such as semantic segmentation, require extensive
and high-quality annotated data, which is costly to obtain. Semi-supervised
semantic segmentation (SSSS) has emerged as a solution to alleviate the
labeling burden by leveraging both labeled and unlabeled data through
self-training techniques. Meanwhile, the advent of foundational segmentation
models pre-trained on massive data, has shown the potential to generalize
across domains effectively. This work explores whether a foundational
segmentation model can address label scarcity in the pixel-level vision task as
an annotator for unlabeled images. Specifically, we investigate the efficacy of
using SEEM, a Segment Anything Model (SAM) variant fine-tuned for textual
input, to generate predictive masks for unlabeled data. To address the
shortcomings of using SEEM-generated masks as supervision, we propose
ConformalSAM, a novel SSSS framework which first calibrates the foundation
model using the target domain's labeled data and then filters out unreliable
pixel labels of unlabeled data so that only high-confidence labels are used as
supervision. By leveraging conformal prediction (CP) to adapt foundation models
to target data through uncertainty calibration, ConformalSAM exploits the
strong capability of the foundational segmentation model reliably which
benefits the early-stage learning, while a subsequent self-reliance training
strategy mitigates overfitting to SEEM-generated masks in the later training
stage. Our experiment demonstrates that, on three standard benchmarks of SSSS,
ConformalSAM achieves superior performance compared to recent SSSS methods and
helps boost the performance of those methods as a plug-in.

</details>


### [102] [Improving Joint Embedding Predictive Architecture with Diffusion Noise](https://arxiv.org/abs/2507.15216)
*Yuping Qiu,Rui Zhu,Ying-cong Chen*

Main category: cs.CV

TL;DR: 论文提出N-JEPA方法，将扩散噪声引入掩码图像建模（MIM），通过多级噪声调度增强模型鲁棒性，并在下游分类任务中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 自监督学习（SSL）在特征学习中表现优异，但在图像生成和细节增强方面不如生成模型。因此，探索SSL与生成模型的结合，以提升SSL的表征能力。

Method: 提出N-JEPA方法，通过扩散噪声（视为掩码的一种状态）与MIM结合，利用掩码标记的位置嵌入和多级噪声调度增强模型。

Result: 在下游分类任务中验证了N-JEPA的有效性。

Conclusion: N-JEPA成功将扩散噪声引入SSL，提升了模型的表征能力和鲁棒性。

Abstract: Self-supervised learning has become an incredibly successful method for
feature learning, widely applied to many downstream tasks. It has proven
especially effective for discriminative tasks, surpassing the trending
generative models. However, generative models perform better in image
generation and detail enhancement. Thus, it is natural for us to find a
connection between SSL and generative models to further enhance the
representation capacity of SSL. As generative models can create new samples by
approximating the data distribution, such modeling should also lead to a
semantic understanding of the raw visual data, which is necessary for
recognition tasks. This enlightens us to combine the core principle of the
diffusion model: diffusion noise, with SSL to learn a competitive recognition
model. Specifically, diffusion noise can be viewed as a particular state of
mask that reveals a close relationship between masked image modeling (MIM) and
diffusion models. In this paper, we propose N-JEPA (Noise-based JEPA) to
incorporate diffusion noise into MIM by the position embedding of masked
tokens. The multi-level noise schedule is a series of feature augmentations to
further enhance the robustness of our model. We perform a comprehensive study
to confirm its effectiveness in the classification of downstream tasks. Codes
will be released soon in public.

</details>


### [103] [True Multimodal In-Context Learning Needs Attention to the Visual Context](https://arxiv.org/abs/2507.15807)
*Shuo Chen,Jianzhe Liu,Zhen Han,Yan Xia,Daniel Cremers,Philip Torr,Volker Tresp,Jindong Gu*

Main category: cs.CV

TL;DR: 本文提出了一种动态注意力重分配（DARA）方法和TrueMICL数据集，以解决多模态大语言模型（MLLMs）在视觉信息利用上的不足，并提升多模态上下文学习（MICL）能力。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs在多模态上下文学习中过度依赖文本模式，忽视视觉线索，导致其实际效用受限。本文旨在解决这一问题。

Method: 提出动态注意力重分配（DARA）方法，通过调整视觉和文本令牌的注意力权重，鼓励模型关注视觉内容；同时构建TrueMICL数据集，明确要求整合多模态信息。

Result: 实验表明，该方法显著提升了模型在多模态上下文学习中的能力。

Conclusion: DARA和TrueMICL有效解决了MLLMs在视觉信息利用上的不足，为多模态上下文学习提供了可靠解决方案。

Abstract: Multimodal Large Language Models (MLLMs), built on powerful language
backbones, have enabled Multimodal In-Context Learning (MICL)-adapting to new
tasks from a few multimodal demonstrations consisting of images, questions, and
answers. Despite showing noticeable improvement on standard vision-language
datasets, current MLLMs struggle to leverage visual information in the
demonstrations. Specifically, they tend to neglect visual cues and over-rely on
textual patterns, leading to mere text imitation rather than genuine multimodal
adaptation. This behavior makes MICL still unimodal and largely restricts its
practical utility. More importantly, this limitation is often concealed by the
improved performance on tasks that do not require understanding the visual
context. As a result, how to effectively enhance MICL ability and reliably
evaluate the MICL performance remains underexplored. To address these issues,
we first introduce Dynamic Attention Reallocation (DARA), an efficient
fine-tuning strategy that encourages models to attend to the visual context by
rebalancing attention across visual and textual tokens. In addition, we present
TrueMICL, an MICL-dedicated dataset with both support and test sets that
explicitly requires the integration of multimodal information-particularly
visual content-for correct task completion. Extensive experiments demonstrate
the effectiveness of our holistic solution, showcasing substantial improvements
in the true multimodal in-context learning capabilities. Code and datasets are
available at https://chenxshuo.github.io/true-micl-colm .

</details>


### [104] [Hierarchical Part-based Generative Model for Realistic 3D Blood Vessel](https://arxiv.org/abs/2507.15223)
*Siqi Chen,Guoqing Zhang,Jiahao Lai,Bingzhi Shen,Sihong Zhang,Caixia Dong,Xuejin Chen,Yang Li*

Main category: cs.CV

TL;DR: 提出了一种分层部分框架用于3D血管生成，分离全局拓扑与局部几何细节，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 准确表示血管的复杂几何和拓扑结构是医学应用中的挑战。

Method: 分三阶段：关键图生成、血管段生成和分层血管组装。

Result: 在真实数据集上验证，性能优于现有方法。

Conclusion: 首次成功应用部分生成方法于3D血管建模，设定了新基准。

Abstract: Advancements in 3D vision have increased the impact of blood vessel modeling
on medical applications. However, accurately representing the complex geometry
and topology of blood vessels remains a challenge due to their intricate
branching patterns, curvatures, and irregular shapes. In this study, we propose
a hierarchical part-based frame work for 3D vessel generation that separates
the global binary tree-like topology from local geometric details. Our approach
proceeds in three stages: (1) key graph generation to model the overall
hierarchical struc ture, (2) vessel segment generation conditioned on geometric
properties, and (3) hierarchical vessel assembly by integrating the local
segments according to the global key graph. We validate our framework on real
world datasets, demonstrating superior performance over existing methods in
modeling complex vascular networks. This work marks the first successful
application of a part-based generative approach for 3D vessel modeling, setting
a new benchmark for vascular data generation. The code is available at:
https://github.com/CybercatChen/PartVessel.git.

</details>


### [105] [SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction](https://arxiv.org/abs/2507.15852)
*Zhixiong Zhang,Shuangrui Ding,Xiaoyi Dong,Songxin He,Jianfan Lin,Junsong Tang,Yuhang Zang,Yuhang Cao,Dahua Lin,Jiaqi Wang*

Main category: cs.CV

TL;DR: 提出Segment Concept (SeC)框架，通过概念驱动的方法改进视频对象分割，结合视觉语言模型和特征匹配，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频对象分割方法依赖外观匹配，缺乏人类对对象的概念理解，无法应对复杂场景变化。

Method: SeC利用大型视觉语言模型构建对象中心的高层表示，动态平衡语义推理和特征匹配。

Result: 在SeCVOS基准上，SeC比SAM 2.1提升11.8分，达到新SOTA。

Conclusion: SeC通过概念驱动方法显著提升了视频对象分割的鲁棒性和性能。

Abstract: Video Object Segmentation (VOS) is a core task in computer vision, requiring
models to track and segment target objects across video frames. Despite notable
advances with recent efforts, current techniques still lag behind human
capabilities in handling drastic visual variations, occlusions, and complex
scene changes. This limitation arises from their reliance on appearance
matching, neglecting the human-like conceptual understanding of objects that
enables robust identification across temporal dynamics. Motivated by this gap,
we propose Segment Concept (SeC), a concept-driven segmentation framework that
shifts from conventional feature matching to the progressive construction and
utilization of high-level, object-centric representations. SeC employs Large
Vision-Language Models (LVLMs) to integrate visual cues across diverse frames,
constructing robust conceptual priors. During inference, SeC forms a
comprehensive semantic representation of the target based on processed frames,
realizing robust segmentation of follow-up frames. Furthermore, SeC adaptively
balances LVLM-based semantic reasoning with enhanced feature matching,
dynamically adjusting computational efforts based on scene complexity. To
rigorously assess VOS methods in scenarios demanding high-level conceptual
reasoning and robust semantic understanding, we introduce the Semantic Complex
Scenarios Video Object Segmentation benchmark (SeCVOS). SeCVOS comprises 160
manually annotated multi-scenario videos designed to challenge models with
substantial appearance variations and dynamic scene transformations. In
particular, SeC achieves an 11.8-point improvement over SAM 2.1 on SeCVOS,
establishing a new state-of-the-art in concept-aware video object segmentation.

</details>


### [106] [Mammo-SAE: Interpreting Breast Cancer Concept Learning with Sparse Autoencoders](https://arxiv.org/abs/2507.15227)
*Krishna Kanth Nakka*

Main category: cs.CV

TL;DR: 该论文提出了一种基于稀疏自编码器（SAE）的方法，用于分析乳腺影像中的模型决策，揭示了与临床相关特征（如肿块和可疑钙化）的潜在神经元对齐情况。


<details>
  <summary>Details</summary>
Motivation: 在医疗影像等高风险领域，模型决策的可解释性对临床采用至关重要。

Method: 使用稀疏自编码器（SAE）分析预训练的Mammo-CLIP模型，识别与临床特征相关的潜在神经元。

Result: 发现潜在神经元与真实区域对齐，并揭示了影响模型决策的混杂因素。

Conclusion: SAE的潜在表示有助于深入理解乳腺影像基础模型的内部机制。

Abstract: Interpretability is critical in high-stakes domains such as medical imaging,
where understanding model decisions is essential for clinical adoption. In this
work, we introduce Sparse Autoencoder (SAE)-based interpretability to breast
imaging by analyzing {Mammo-CLIP}, a vision--language foundation model
pretrained on large-scale mammogram image--report pairs. We train a patch-level
\texttt{Mammo-SAE} on Mammo-CLIP to identify and probe latent features
associated with clinically relevant breast concepts such as \textit{mass} and
\textit{suspicious calcification}. Our findings reveal that top activated class
level latent neurons in the SAE latent space often tend to align with ground
truth regions, and also uncover several confounding factors influencing the
model's decision-making process. Additionally, we analyze which latent neurons
the model relies on during downstream finetuning for improving the breast
concept prediction. This study highlights the promise of interpretable SAE
latent representations in providing deeper insight into the internal workings
of foundation models at every layer for breast imaging.

</details>


### [107] [FreeCus: Free Lunch Subject-driven Customization in Diffusion Transformers](https://arxiv.org/abs/2507.15249)
*Yanbing Zhang,Zhe Wang,Qin Zhou,Mengping Yang*

Main category: cs.CV

TL;DR: FreeCus是一种无需训练的框架，通过注意力共享、动态移位分析和多模态大语言模型集成，激活扩散变换器的零样本能力，实现高质量的主题驱动合成。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖训练过程，限制了实际应用，且未能充分利用扩散变换器的零样本潜力。

Method: 提出三种创新：注意力共享机制、动态移位分析改进特征提取、集成多模态大语言模型。

Result: 实验表明，FreeCus在多样场景中实现一致的主题合成，性能达到或超越需训练的方法。

Conclusion: FreeCus展示了与现有流程的无缝兼容性，为设计和娱乐提供了更灵活的解决方案。

Abstract: In light of recent breakthroughs in text-to-image (T2I) generation,
particularly with diffusion transformers (DiT), subject-driven technologies are
increasingly being employed for high-fidelity customized production that
preserves subject identity from reference inputs, enabling thrilling design
workflows and engaging entertainment. Existing alternatives typically require
either per-subject optimization via trainable text embeddings or training
specialized encoders for subject feature extraction on large-scale datasets.
Such dependencies on training procedures fundamentally constrain their
practical applications. More importantly, current methodologies fail to fully
leverage the inherent zero-shot potential of modern diffusion transformers
(e.g., the Flux series) for authentic subject-driven synthesis. To bridge this
gap, we propose FreeCus, a genuinely training-free framework that activates
DiT's capabilities through three key innovations: 1) We introduce a pivotal
attention sharing mechanism that captures the subject's layout integrity while
preserving crucial editing flexibility. 2) Through a straightforward analysis
of DiT's dynamic shifting, we propose an upgraded variant that significantly
improves fine-grained feature extraction. 3) We further integrate advanced
Multimodal Large Language Models (MLLMs) to enrich cross-modal semantic
representations. Extensive experiments reflect that our method successfully
unlocks DiT's zero-shot ability for consistent subject synthesis across diverse
contexts, achieving state-of-the-art or comparable results compared to
approaches that require additional training. Notably, our framework
demonstrates seamless compatibility with existing inpainting pipelines and
control modules, facilitating more compelling experiences. Our code is
available at: https://github.com/Monalissaa/FreeCus.

</details>


### [108] [MinCD-PnP: Learning 2D-3D Correspondences with Approximate Blind PnP](https://arxiv.org/abs/2507.15257)
*Pei An,Jiaqi Yang,Muyao Peng,You Yang,Qiong Liu,Xiaolin Wu,Liangliang Nan*

Main category: cs.CV

TL;DR: 提出了一种基于近似盲PnP的对应学习方法MinCD-PnP，通过最小化学习到的2D和3D关键点之间的Chamfer距离，解决了传统微分PnP对噪声和异常值敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 传统微分PnP在图像到点云（I2P）注册中对噪声和异常值高度敏感，限制了对应学习的有效性。

Method: 提出MinCD-PnP方法，简化盲PnP为最小化Chamfer距离的任务，并设计轻量级多任务学习模块MinCD-Net。

Result: 在多个数据集上实验表明，MinCD-Net在跨场景和跨数据集设置中均优于现有方法，具有更高的内点比率（IR）和注册召回率（RR）。

Conclusion: MinCD-PnP和MinCD-Net有效提升了I2P注册的鲁棒性和性能。

Abstract: Image-to-point-cloud (I2P) registration is a fundamental problem in computer
vision, focusing on establishing 2D-3D correspondences between an image and a
point cloud. The differential perspective-n-point (PnP) has been widely used to
supervise I2P registration networks by enforcing the projective constraints on
2D-3D correspondences. However, differential PnP is highly sensitive to noise
and outliers in the predicted correspondences. This issue hinders the
effectiveness of correspondence learning. Inspired by the robustness of blind
PnP against noise and outliers in correspondences, we propose an approximated
blind PnP based correspondence learning approach. To mitigate the high
computational cost of blind PnP, we simplify blind PnP to an amenable task of
minimizing Chamfer distance between learned 2D and 3D keypoints, called
MinCD-PnP. To effectively solve MinCD-PnP, we design a lightweight multi-task
learning module, named as MinCD-Net, which can be easily integrated into the
existing I2P registration architectures. Extensive experiments on 7-Scenes,
RGBD-V2, ScanNet, and self-collected datasets demonstrate that MinCD-Net
outperforms state-of-the-art methods and achieves a higher inlier ratio (IR)
and registration recall (RR) in both cross-scene and cross-dataset settings.

</details>


### [109] [In-context Learning of Vision Language Models for Detection of Physical and Digital Attacks against Face Recognition Systems](https://arxiv.org/abs/2507.15285)
*Lazaro Janier Gonzalez-Soler,Maciej Salwowski,Christoph Busch*

Main category: cs.CV

TL;DR: 论文探讨了生物识别系统中攻击检测的挑战，提出了一种基于视觉语言模型（VLM）的上下文学习框架，用于检测物理和数字攻击，并在实验中验证了其性能优于传统CNN。


<details>
  <summary>Details</summary>
Motivation: 随着生物识别系统的发展，攻击技术日益复杂，传统深度学习模型在适应新攻击类型和环境条件时表现不佳，且需要大量训练数据。

Method: 提出了一种基于VLM的上下文学习框架，用于检测物理呈现攻击和数字变形攻击，并建立了首个系统性评估框架。

Result: 实验表明，该框架在物理和数字攻击检测中表现优异，优于部分传统CNN，且无需大量训练资源。

Conclusion: 该框架为生物识别系统中的攻击检测提供了一种高效且泛化能力强的解决方案。

Abstract: Recent advances in biometric systems have significantly improved the
detection and prevention of fraudulent activities. However, as detection
methods improve, attack techniques become increasingly sophisticated. Attacks
on face recognition systems can be broadly divided into physical and digital
approaches. Traditionally, deep learning models have been the primary defence
against such attacks. While these models perform exceptionally well in
scenarios for which they have been trained, they often struggle to adapt to
different types of attacks or varying environmental conditions. These
subsystems require substantial amounts of training data to achieve reliable
performance, yet biometric data collection faces significant challenges,
including privacy concerns and the logistical difficulties of capturing diverse
attack scenarios under controlled conditions. This work investigates the
application of Vision Language Models (VLM) and proposes an in-context learning
framework for detecting physical presentation attacks and digital morphing
attacks in biometric systems. Focusing on open-source models, the first
systematic framework for the quantitative evaluation of VLMs in
security-critical scenarios through in-context learning techniques is
established. The experimental evaluation conducted on freely available
databases demonstrates that the proposed subsystem achieves competitive
performance for physical and digital attack detection, outperforming some of
the traditional CNNs without resource-intensive training. The experimental
results validate the proposed framework as a promising tool for improving
generalisation in attack detection.

</details>


### [110] [Minutiae-Anchored Local Dense Representation for Fingerprint Matching](https://arxiv.org/abs/2507.15297)
*Zhiyu Pan,Xiongjun Guan,Yongjie Duan,Jianjiang Feng,Jie Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为DMD的指纹匹配方法，通过局部密集表示结合细节特征和纹理信息，实现了在多种采集条件下的高精度匹配。


<details>
  <summary>Details</summary>
Motivation: 解决指纹匹配在不同采集条件下鲁棒性和准确性的挑战。

Method: 基于细节特征的局部密集表示，提取三维张量描述符，结合空间结构和语义特征。

Result: 在多种指纹数据集上达到最先进精度，并保持高效计算。

Conclusion: DMD方法在指纹识别中表现出强大的泛化能力和应用潜力。

Abstract: Fingerprint matching under diverse capture conditions remains a fundamental
challenge in biometric recognition. To achieve robust and accurate performance
in such scenarios, we propose DMD, a minutiae-anchored local dense
representation which captures both fine-grained ridge textures and
discriminative minutiae features in a spatially structured manner.
Specifically, descriptors are extracted from local patches centered and
oriented on each detected minutia, forming a three-dimensional tensor, where
two dimensions represent spatial locations on the fingerprint plane and the
third encodes semantic features. This representation explicitly captures
abstract features of local image patches, enabling a multi-level, fine-grained
description that aggregates information from multiple minutiae and their
surrounding ridge structures. Furthermore, thanks to its strong spatial
correspondence with the patch image, DMD allows for the use of foreground
segmentation masks to identify valid descriptor regions. During matching,
comparisons are then restricted to overlapping foreground areas, improving
efficiency and robustness. Extensive experiments on rolled, plain, parital,
contactless, and latent fingerprint datasets demonstrate the effectiveness and
generalizability of the proposed method. It achieves state-of-the-art accuracy
across multiple benchmarks while maintaining high computational efficiency,
showing strong potential for large-scale fingerprint recognition. Corresponding
code is available at https://github.com/Yu-Yy/DMD.

</details>


### [111] [Few-Shot Object Detection via Spatial-Channel State Space Model](https://arxiv.org/abs/2507.15308)
*Zhimeng Xin,Tianxu Wu,Yixiong Zou,Shiming Chen,Dingjie Fu,Xinge You*

Main category: cs.CV

TL;DR: 论文提出了一种名为SCSM的模块，通过空间-通道状态建模解决少样本目标检测中通道特征提取不准确的问题，结合Mamba建模通道相关性，在VOC和COCO数据集上取得了最优性能。


<details>
  <summary>Details</summary>
Motivation: 当前少样本目标检测方法在有限训练样本下难以准确提取通道特征，高权重通道未必有效，低权重通道可能仍有价值。

Method: 提出SCSM模块，包含SFM模块平衡空间与通道关系学习，以及基于Mamba的CSM模块建模通道相关性。

Result: 在VOC和COCO数据集上，SCSM模块显著提升了特征表示质量，达到最优性能。

Conclusion: SCSM模块通过空间-通道状态建模有效解决了少样本目标检测中的通道特征提取问题。

Abstract: Due to the limited training samples in few-shot object detection (FSOD), we
observe that current methods may struggle to accurately extract effective
features from each channel. Specifically, this issue manifests in two aspects:
i) channels with high weights may not necessarily be effective, and ii)
channels with low weights may still hold significant value. To handle this
problem, we consider utilizing the inter-channel correlation to facilitate the
novel model's adaptation process to novel conditions, ensuring the model can
correctly highlight effective channels and rectify those incorrect ones. Since
the channel sequence is also 1-dimensional, its similarity with the temporal
sequence inspires us to take Mamba for modeling the correlation in the channel
sequence. Based on this concept, we propose a Spatial-Channel State Space
Modeling (SCSM) module for spatial-channel state modeling, which highlights the
effective patterns and rectifies those ineffective ones in feature channels. In
SCSM, we design the Spatial Feature Modeling (SFM) module to balance the
learning of spatial relationships and channel relationships, and then introduce
the Channel State Modeling (CSM) module based on Mamba to learn correlation in
channels. Extensive experiments on the VOC and COCO datasets show that the SCSM
module enables the novel detector to improve the quality of focused feature
representation in channels and achieve state-of-the-art performance.

</details>


### [112] [BenchDepth: Are We on the Right Way to Evaluate Depth Foundation Models?](https://arxiv.org/abs/2507.15321)
*Zhenyu Li,Haotong Lin,Jiashi Feng,Peter Wonka,Bingyi Kang*

Main category: cs.CV

TL;DR: 提出BenchDepth新基准，通过五个下游代理任务评估深度基础模型（DFMs），避免传统对齐指标的偏见。


<details>
  <summary>Details</summary>
Motivation: 现有深度评估协议存在不一致性和偏见，难以公平比较DFMs。

Method: 设计BenchDepth基准，选择五个下游任务（如深度补全、立体匹配等）评估DFMs的实际应用价值。

Result: 评估了八种先进DFMs，并分析了关键发现。

Conclusion: BenchDepth为深度模型评估提供新标准，推动未来研究。

Abstract: Depth estimation is a fundamental task in computer vision with diverse
applications. Recent advancements in deep learning have led to powerful depth
foundation models (DFMs), yet their evaluation remains challenging due to
inconsistencies in existing protocols. Traditional benchmarks rely on
alignment-based metrics that introduce biases, favor certain depth
representations, and complicate fair comparisons. In this work, we propose
BenchDepth, a new benchmark that evaluates DFMs through five carefully selected
downstream proxy tasks: depth completion, stereo matching, monocular
feed-forward 3D scene reconstruction, SLAM, and vision-language spatial
understanding. Unlike conventional evaluation protocols, our approach assesses
DFMs based on their practical utility in real-world applications, bypassing
problematic alignment procedures. We benchmark eight state-of-the-art DFMs and
provide an in-depth analysis of key findings and observations. We hope our work
sparks further discussion in the community on best practices for depth model
evaluation and paves the way for future research and advancements in depth
estimation.

</details>


### [113] [RoadFusion: Latent Diffusion Model for Pavement Defect Detection](https://arxiv.org/abs/2507.15346)
*Muhammad Aqeel,Kidus Dagnaw Bellete,Francesco Setti*

Main category: cs.CV

TL;DR: RoadFusion通过合成异常生成和双路径特征适应解决路面缺陷检测中的数据稀缺、领域偏移和缺陷多样性问题。


<details>
  <summary>Details</summary>
Motivation: 路面缺陷检测面临标注数据稀缺、训练与部署环境的领域偏移以及缺陷外观的高变异性等挑战。

Method: 采用潜在扩散模型生成多样化的合成缺陷，通过双路径特征适应器分别处理正常和异常输入，并使用轻量级判别器在补丁级别区分缺陷模式。

Result: 在六个基准数据集上，RoadFusion在分类和定位任务中表现优异，多项指标达到最新水平。

Conclusion: RoadFusion为实际道路检测提供了高效、鲁棒的解决方案。

Abstract: Pavement defect detection faces critical challenges including limited
annotated data, domain shift between training and deployment environments, and
high variability in defect appearances across different road conditions. We
propose RoadFusion, a framework that addresses these limitations through
synthetic anomaly generation with dual-path feature adaptation. A latent
diffusion model synthesizes diverse, realistic defects using text prompts and
spatial masks, enabling effective training under data scarcity. Two separate
feature adaptors specialize representations for normal and anomalous inputs,
improving robustness to domain shift and defect variability. A lightweight
discriminator learns to distinguish fine-grained defect patterns at the patch
level. Evaluated on six benchmark datasets, RoadFusion achieves consistently
strong performance across both classification and localization tasks, setting
new state-of-the-art in multiple metrics relevant to real-world road
inspection.

</details>


### [114] [DAViD: Data-efficient and Accurate Vision Models from Synthetic Data](https://arxiv.org/abs/2507.15365)
*Fatemeh Saleh,Sadegh Aliakbarian,Charlie Hewitt,Lohit Petikam,Xiao-Xian,Antonio Criminisi,Thomas J. Cashman,Tadas Baltrušaitis*

Main category: cs.CV

TL;DR: 论文提出了一种使用小型高保真合成数据集训练高效模型的方法，在保持精度的同时降低成本。


<details>
  <summary>Details</summary>
Motivation: 当前人类中心计算机视觉模型需要大量参数、数据和计算资源，成本高昂。

Method: 利用合成数据集训练模型，提供高细节和完美标签，同时控制数据多样性。

Result: 在深度估计、表面法线估计和软前景分割任务中，模型精度与大型模型相当，但成本显著降低。

Conclusion: 合成数据集是高效、低成本训练高精度模型的可行方案。

Abstract: The state of the art in human-centric computer vision achieves high accuracy
and robustness across a diverse range of tasks. The most effective models in
this domain have billions of parameters, thus requiring extremely large
datasets, expensive training regimes, and compute-intensive inference. In this
paper, we demonstrate that it is possible to train models on much smaller but
high-fidelity synthetic datasets, with no loss in accuracy and higher
efficiency. Using synthetic training data provides us with excellent levels of
detail and perfect labels, while providing strong guarantees for data
provenance, usage rights, and user consent. Procedural data synthesis also
provides us with explicit control on data diversity, that we can use to address
unfairness in the models we train. Extensive quantitative assessment on real
input images demonstrates accuracy of our models on three dense prediction
tasks: depth estimation, surface normal estimation, and soft foreground
segmentation. Our models require only a fraction of the cost of training and
inference when compared with foundational models of similar accuracy. Our
human-centric synthetic dataset and trained models are available at
https://aka.ms/DAViD.

</details>


### [115] [Rethinking Occlusion in FER: A Semantic-Aware Perspective and Go Beyond](https://arxiv.org/abs/2507.15401)
*Huiyu Zhai,Xingxing Yang,Yalan Ye,Chenyang Li,Bin Fan,Changze Li*

Main category: cs.CV

TL;DR: ORSANet通过多模态语义引导、多尺度交互模块和动态对抗排斥损失，提升了遮挡条件下面部表情识别的性能。


<details>
  <summary>Details</summary>
Motivation: 现有FER模型在面部部分遮挡时难以提取有效特征，导致分类不准确。

Method: 1. 引入多模态语义引导（语义分割图和面部关键点）；2. 设计多尺度交互模块（MCM）；3. 提出动态对抗排斥损失（DARELoss）。

Result: 在公开基准和自建数据集Occlu-FER上达到SOTA性能。

Conclusion: ORSANet通过多模态融合和动态损失设计，显著提升了遮挡条件下的FER性能。

Abstract: Facial expression recognition (FER) is a challenging task due to pervasive
occlusion and dataset biases. Especially when facial information is partially
occluded, existing FER models struggle to extract effective facial features,
leading to inaccurate classifications. In response, we present ORSANet, which
introduces the following three key contributions: First, we introduce auxiliary
multi-modal semantic guidance to disambiguate facial occlusion and learn
high-level semantic knowledge, which is two-fold: 1) we introduce semantic
segmentation maps as dense semantics prior to generate semantics-enhanced
facial representations; 2) we introduce facial landmarks as sparse geometric
prior to mitigate intrinsic noises in FER, such as identity and gender biases.
Second, to facilitate the effective incorporation of these two multi-modal
priors, we customize a Multi-scale Cross-interaction Module (MCM) to adaptively
fuse the landmark feature and semantics-enhanced representations within
different scales. Third, we design a Dynamic Adversarial Repulsion Enhancement
Loss (DARELoss) that dynamically adjusts the margins of ambiguous classes,
further enhancing the model's ability to distinguish similar expressions. We
further construct the first occlusion-oriented FER dataset to facilitate
specialized robustness analysis on various real-world occlusion conditions,
dubbed Occlu-FER. Extensive experiments on both public benchmarks and Occlu-FER
demonstrate that our proposed ORSANet achieves SOTA recognition performance.
Code is publicly available at https://github.com/Wenyuzhy/ORSANet-master.

</details>


### [116] [SurgX: Neuron-Concept Association for Explainable Surgical Phase Recognition](https://arxiv.org/abs/2507.15418)
*Ka Young Kim,Hyeon Bae Kim,Seong Tae Kim*

Main category: cs.CV

TL;DR: SurgX是一个新颖的概念解释框架，通过将神经元与相关概念关联，提升手术阶段识别模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在手术阶段识别中取得了进展，但其不透明性阻碍了信任和调试。

Method: 提出SurgX框架，包括选择代表性神经元序列、构建手术视频数据集的概念集、关联神经元与概念，并识别关键神经元。

Result: 在两个手术阶段识别模型上的实验验证了方法的有效性，并分析了预测解释。

Conclusion: SurgX展示了在解释手术阶段识别方面的潜力。

Abstract: Surgical phase recognition plays a crucial role in surgical workflow
analysis, enabling various applications such as surgical monitoring, skill
assessment, and workflow optimization. Despite significant advancements in deep
learning-based surgical phase recognition, these models remain inherently
opaque, making it difficult to understand how they make decisions. This lack of
interpretability hinders trust and makes it challenging to debug the model. To
address this challenge, we propose SurgX, a novel concept-based explanation
framework that enhances the interpretability of surgical phase recognition
models by associating neurons with relevant concepts. In this paper, we
introduce the process of selecting representative example sequences for
neurons, constructing a concept set tailored to the surgical video dataset,
associating neurons with concepts and identifying neurons crucial for
predictions. Through extensive experiments on two surgical phase recognition
models, we validate our method and analyze the explanation for prediction. This
highlights the potential of our method in explaining surgical phase
recognition. The code is available at https://github.com/ailab-kyunghee/SurgX

</details>


### [117] [One Last Attention for Your Vision-Language Model](https://arxiv.org/abs/2507.15480)
*Liang Chen,Ghazi Shazan Ahmad,Tianjun Yao,Lingqiao Liu,Zhiqiang Shen*

Main category: cs.CV

TL;DR: RAda是一种简单有效的视觉语言模型微调方法，通过动态校准融合表示来提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常忽略融合表示在决策中的关键作用，RAda旨在填补这一空白。

Method: RAda使用轻量级注意力层生成学习掩码，动态调整融合表示中每个元素的贡献。

Result: 在不同设置下，RAda均能显著提升基线性能，并与当前最佳方法相当。

Conclusion: RAda是一种通用且高效的微调技术，适用于多种场景。

Abstract: Pretrained vision-language models (VLMs), such as CLIP, achieve remarkable
zero-shot performance, yet their downstream potential hinges on effective
fine-tuning. Most adaptation methods typically focus on refining representation
from separate modalities (text or vision) but neglect the critical role of
their fused representations in the decision-making process, \emph{\ie} rational
matrix that drives the final prediction. To bridge the gap, we propose a simple
yet effective \textbf{R}ational \textbf{Ada}ptaion ({RAda}) to explicitly
exploit the final fused representation during fine-tuning. RAda employs a
learned mask, obtained from a lightweight attention layer attached at the end
of a VLM, to dynamically calibrate the contribution of each element in the
rational matrix, enabling targeted adjustments to the final cross-modal
interactions without incurring costly modifications to intermediate features.
Experiments in different settings (i.e., updating, or freezing pretrained
encoders in adaptation, and test-time training that can only access the
unlabeled test data) show that RAda serves as a versatile fine-tuning
technique, improving the baseline with minimal code and performing comparably
against current arts in most settings. Code is available at
\href{https://github.com/khufia/RAda/tree/main}{github.com/khufia/RAda}.

</details>


### [118] [An aerial color image anomaly dataset for search missions in complex forested terrain](https://arxiv.org/abs/2507.15492)
*Rakesh John Amala Arokia Nathan,Matthias Gessner,Nurullah Özkan,Marius Bock,Mohamed Youssef,Maximilian Mews,Björn Piltz,Ralf Berger,Oliver Bimber*

Main category: cs.CV

TL;DR: 论文描述了一起德国乡村谋杀案后，通过航空影像和众包搜索生成的数据集，用于改进复杂森林环境中的异常检测方法。


<details>
  <summary>Details</summary>
Motivation: 由于茂密植被遮挡，传统自动化分析失效，需开发更有效的异常检测方法以支持搜救行动。

Method: 利用高分辨率航空影像和众包标注生成数据集，并开发交互式网络界面支持动态标注。

Result: 现有方法在基准测试中表现不佳，凸显需要上下文感知的异常检测方法。

Conclusion: 该数据集为复杂环境下的异常检测提供了基准，支持搜救行动，并开放供离线处理和在线动态标注。

Abstract: After a family murder in rural Germany, authorities failed to locate the
suspect in a vast forest despite a massive search. To aid the search, a
research aircraft captured high-resolution aerial imagery. Due to dense
vegetation obscuring small clues, automated analysis was ineffective, prompting
a crowd-search initiative. This effort produced a unique dataset of labeled,
hard-to-detect anomalies under occluded, real-world conditions. It can serve as
a benchmark for improving anomaly detection approaches in complex forest
environments, supporting manhunts and rescue operations. Initial benchmark
tests showed existing methods performed poorly, highlighting the need for
context-aware approaches. The dataset is openly accessible for offline
processing. An additional interactive web interface supports online viewing and
dynamic growth by allowing users to annotate and submit new findings.

</details>


### [119] [Dense-depth map guided deep Lidar-Visual Odometry with Sparse Point Clouds and Images](https://arxiv.org/abs/2507.15496)
*JunYing Huang,Ao Xu,DongSun Yong,KeRen Li,YuanFeng Wang,Qi Qin*

Main category: cs.CV

TL;DR: 提出了一种结合LiDAR点云和图像的LiDAR-Visual里程计框架，通过深度补全和多尺度特征提取网络实现精确且鲁棒的位姿估计。


<details>
  <summary>Details</summary>
Motivation: 解决自主系统中自定位和导航的关键问题，提升在动态环境和遮挡区域的鲁棒性。

Method: 利用深度补全生成稠密深度图，结合多尺度特征提取网络和注意力机制，优化光流估计和位姿细化。

Result: 在KITTI里程计基准测试中表现优于或接近当前最先进的视觉和LiDAR里程计方法。

Conclusion: 该方法在准确性和鲁棒性上具有显著优势，适用于复杂环境。

Abstract: Odometry is a critical task for autonomous systems for self-localization and
navigation. We propose a novel LiDAR-Visual odometry framework that integrates
LiDAR point clouds and images for accurate and robust pose estimation. Our
method utilizes a dense-depth map estimated from point clouds and images
through depth completion, and incorporates a multi-scale feature extraction
network with attention mechanisms, enabling adaptive depth-aware
representations. Furthermore, we leverage dense depth information to refine
flow estimation and mitigate errors in occlusion-prone regions. Our
hierarchical pose refinement module optimizes motion estimation progressively,
ensuring robust predictions against dynamic environments and scale ambiguities.
Comprehensive experiments on the KITTI odometry benchmark demonstrate that our
approach achieves similar or superior accuracy and robustness compared to
state-of-the-art visual and LiDAR odometry methods.

</details>


### [120] [Quantifying and Narrowing the Unknown: Interactive Text-to-Video Retrieval via Uncertainty Minimization](https://arxiv.org/abs/2507.15504)
*Bingqing Zhang,Zhuo Cao,Heming Du,Yang Li,Xue Li,Jiajun Liu,Sen Wang*

Main category: cs.CV

TL;DR: UMIVR是一个基于不确定性最小化的交互式文本到视频检索框架，通过量化文本模糊性、映射不确定性和帧不确定性，生成针对性问题以优化检索效果。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频检索（TVR）存在文本模糊性、映射不确定性和低质量视频帧等问题，现有方法缺乏对这些不确定性的量化，限制了检索效果。

Method: UMIVR通过语义熵（TAS）、Jensen-Shannon散度（MUS）和时序质量帧采样器（TQFS）量化不确定性，并生成针对性问题迭代优化查询。

Result: 在MSR-VTT-1k数据集上，UMIVR在10轮交互后Recall@1达到69.2%，显著优于现有方法。

Conclusion: UMIVR为交互式TVR提供了不确定性最小化的基础，显著提升了检索性能。

Abstract: Despite recent advances, Text-to-video retrieval (TVR) is still hindered by
multiple inherent uncertainties, such as ambiguous textual queries, indistinct
text-video mappings, and low-quality video frames. Although interactive systems
have emerged to address these challenges by refining user intent through
clarifying questions, current methods typically rely on heuristic or ad-hoc
strategies without explicitly quantifying these uncertainties, limiting their
effectiveness. Motivated by this gap, we propose UMIVR, an
Uncertainty-Minimizing Interactive Text-to-Video Retrieval framework that
explicitly quantifies three critical uncertainties-text ambiguity, mapping
uncertainty, and frame uncertainty-via principled, training-free metrics:
semantic entropy-based Text Ambiguity Score (TAS), Jensen-Shannon
divergence-based Mapping Uncertainty Score (MUS), and a Temporal Quality-based
Frame Sampler (TQFS). By adaptively generating targeted clarifying questions
guided by these uncertainty measures, UMIVR iteratively refines user queries,
significantly reducing retrieval ambiguity. Extensive experiments on multiple
benchmarks validate UMIVR's effectiveness, achieving notable gains in Recall@1
(69.2\% after 10 interactive rounds) on the MSR-VTT-1k dataset, thereby
establishing an uncertainty-minimizing foundation for interactive TVR.

</details>


### [121] [SAIGFormer: A Spatially-Adaptive Illumination-Guided Network for Low-Light Image Enhancement](https://arxiv.org/abs/2507.15520)
*Hanting Li,Fei Zhou,Xin Sun,Yang Hua,Jungong Han,Liang-Jie Zhang*

Main category: cs.CV

TL;DR: SAIGFormer提出了一种基于Transformer的低光照增强方法，通过动态积分图像表示和光照引导的多头自注意力机制，有效解决了非均匀光照场景下的问题。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer方法在非均匀光照场景（如背光和阴影）中表现不佳，导致过曝或亮度恢复不足。

Method: 提出动态积分图像表示建模空间变化光照，构建SAI2E估计器，并引入IG-MSA机制校准光照相关特征。

Result: 在五个标准低光照数据集和跨域基准测试中，SAIGFormer在定量和定性指标上显著优于现有方法。

Conclusion: SAIGFormer在非均匀光照增强中表现优异，并展现出强大的跨数据集泛化能力。

Abstract: Recent Transformer-based low-light enhancement methods have made promising
progress in recovering global illumination. However, they still struggle with
non-uniform lighting scenarios, such as backlit and shadow, appearing as
over-exposure or inadequate brightness restoration. To address this challenge,
we present a Spatially-Adaptive Illumination-Guided Transformer (SAIGFormer)
framework that enables accurate illumination restoration. Specifically, we
propose a dynamic integral image representation to model the spatially-varying
illumination, and further construct a novel Spatially-Adaptive Integral
Illumination Estimator ($\text{SAI}^2\text{E}$). Moreover, we introduce an
Illumination-Guided Multi-head Self-Attention (IG-MSA) mechanism, which
leverages the illumination to calibrate the lightness-relevant features toward
visual-pleased illumination enhancement. Extensive experiments on five standard
low-light datasets and a cross-domain benchmark (LOL-Blur) demonstrate that our
SAIGFormer significantly outperforms state-of-the-art methods in both
quantitative and qualitative metrics. In particular, our method achieves
superior performance in non-uniform illumination enhancement while exhibiting
strong generalization capabilities across multiple datasets. Code is available
at https://github.com/LHTcode/SAIGFormer.git.

</details>


### [122] [Procedure Learning via Regularized Gromov-Wasserstein Optimal Transport](https://arxiv.org/abs/2507.15540)
*Syed Ahmed Mahmood,Ali Shah Ali,Umer Ahmed,Fawad Javed Fateh,M. Zeeshan Zia,Quoc-Huy Tran*

Main category: cs.CV

TL;DR: 提出一种自监督程序学习框架，通过融合Gromov-Wasserstein最优传输和对比正则化，解决视频中关键步骤发现和顺序确定的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视频间帧对帧对应学习中易受顺序变化、背景/冗余帧和重复动作影响，性能受限。

Method: 采用融合Gromov-Wasserstein最优传输和结构先验的框架，并引入对比正则化避免嵌入空间退化。

Result: 在EgoProceL、ProceL和CrossTask基准测试中表现优于传统方法OPEL。

Conclusion: 提出的框架有效解决了自监督程序学习中的关键挑战，性能显著提升。

Abstract: We study the problem of self-supervised procedure learning, which discovers
key steps and establishes their order from a set of unlabeled procedural
videos. Previous procedure learning methods typically learn frame-to-frame
correspondences between videos before determining key steps and their order.
However, their performance often suffers from order variations,
background/redundant frames, and repeated actions. To overcome these
challenges, we propose a self-supervised procedure learning framework, which
utilizes a fused Gromov-Wasserstein optimal transport formulation with a
structural prior for computing frame-to-frame mapping between videos. However,
optimizing exclusively for the above temporal alignment term may lead to
degenerate solutions, where all frames are mapped to a small cluster in the
embedding space and hence every video is associated with only one key step. To
address that limitation, we further integrate a contrastive regularization
term, which maps different frames to different points in the embedding space,
avoiding the collapse to trivial solutions. Finally, we conduct extensive
experiments on large-scale egocentric (i.e., EgoProceL) and third-person (i.e.,
ProceL and CrossTask) benchmarks to demonstrate superior performance by our
approach against previous methods, including OPEL which relies on a traditional
Kantorovich optimal transport formulation with an optimality prior.

</details>


### [123] [Towards Holistic Surgical Scene Graph](https://arxiv.org/abs/2507.15541)
*Jongmin Shin,Enki Cho,Ka Yong Kim,Jung Yong Kim,Seong Tae Kim,Namkee Oh*

Main category: cs.CV

TL;DR: 论文提出了一种基于图的方法SSG-Com，用于增强手术场景理解，通过引入工具-动作-目标组合和手部身份信息，并发布了Endoscapes-SG201数据集。


<details>
  <summary>Details</summary>
Motivation: 手术场景理解需要更全面地建模工具-动作-目标组合和手部身份信息，而现有图表示方法对此研究不足。

Method: 提出SSG-Com方法，结合工具-动作-目标组合和手部身份信息，并发布Endoscapes-SG201数据集。

Result: 实验证明，这些关键元素对手术场景理解任务（如安全视野评估和动作三元组识别）有显著贡献。

Conclusion: 通过SSG-Com和Endoscapes-SG201数据集，论文推动了手术场景图表示的研究，为计算机辅助干预系统提供了更全面的理解能力。

Abstract: Surgical scene understanding is crucial for computer-assisted intervention
systems, requiring visual comprehension of surgical scenes that involves
diverse elements such as surgical tools, anatomical structures, and their
interactions. To effectively represent the complex information in surgical
scenes, graph-based approaches have been explored to structurally model
surgical entities and their relationships. Previous surgical scene graph
studies have demonstrated the feasibility of representing surgical scenes using
graphs. However, certain aspects of surgical scenes-such as diverse
combinations of tool-action-target and the identity of the hand operating the
tool-remain underexplored in graph-based representations, despite their
importance. To incorporate these aspects into graph representations, we propose
Endoscapes-SG201 dataset, which includes annotations for tool-action-target
combinations and hand identity. We also introduce SSG-Com, a graph-based method
designed to learn and represent these critical elements. Through experiments on
downstream tasks such as critical view of safety assessment and action triplet
recognition, we demonstrated the importance of integrating these essential
scene graph components, highlighting their significant contribution to surgical
scene understanding. The code and dataset are available at
https://github.com/ailab-kyunghee/SSG-Com

</details>


### [124] [HOLa: Zero-Shot HOI Detection with Low-Rank Decomposed VLM Feature Adaptation](https://arxiv.org/abs/2507.15542)
*Qinqian Lei,Bo Wang,Robby T. Tan*

Main category: cs.CV

TL;DR: HOLa提出了一种新方法，通过低秩分解VLM特征适应，提升零样本HOI检测的泛化能力和动作区分度。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在零样本HOI检测中难以区分相同对象动作或泛化到未见类的问题。

Method: 低秩分解VLM文本特征，生成类共享基特征和可调权重，结合LLM动作正则化优化权重适应。

Result: 在HICO-DET上达到27.91的未见类mAP，性能领先。

Conclusion: HOLa通过特征分解和权重适应，显著提升零样本HOI检测的泛化和区分能力。

Abstract: Zero-shot human-object interaction (HOI) detection remains a challenging
task, particularly in generalizing to unseen actions. Existing methods address
this challenge by tapping Vision-Language Models (VLMs) to access knowledge
beyond the training data. However, they either struggle to distinguish actions
involving the same object or demonstrate limited generalization to unseen
classes. In this paper, we introduce HOLa (Zero-Shot HOI Detection with
Low-Rank Decomposed VLM Feature Adaptation), a novel approach that both
enhances generalization to unseen classes and improves action distinction. In
training, HOLa decomposes VLM text features for given HOI classes via low-rank
factorization, producing class-shared basis features and adaptable weights.
These features and weights form a compact HOI representation that preserves
shared information across classes, enhancing generalization to unseen classes.
Subsequently, we refine action distinction by adapting weights for each HOI
class and introducing human-object tokens to enrich visual interaction
representations. To further distinguish unseen actions, we guide the weight
adaptation with LLM-derived action regularization. Experimental results show
that our method sets a new state-of-the-art across zero-shot HOI settings on
HICO-DET, achieving an unseen-class mAP of 27.91 in the unseen-verb setting.
Our code is available at https://github.com/ChelsieLei/HOLa.

</details>


### [125] [DynImg: Key Frames with Visual Prompts are Good Representation for Multi-Modal Video Understanding](https://arxiv.org/abs/2507.15569)
*Xiaoyi Bao,Chenwei Xie,Hao Tang,Tingyu Weng,Xiaofeng Wang,Yun Zheng,Xingang Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为Dynamic-Image（DynImg）的视频表示方法，通过引入非关键帧作为时间提示，增强对快速移动物体空间特征的提取，并结合4D视频旋转位置嵌入保持时空顺序，显著提升了视频理解性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法将空间和时间信息分开处理，导致快速移动物体的空间信息难以准确表示，影响时空交互和视频理解。

Method: 提出DynImg方法，利用非关键帧作为时间提示，引导模型关注快速移动物体的细粒度空间特征，并采用4D视频旋转位置嵌入保持时空顺序。

Result: 实验表明，DynImg在多个视频理解基准上比现有方法提高了约2%。

Conclusion: DynImg通过时间提示和4D嵌入有效提升了视频理解的准确性，证明了其创新性和实用性。

Abstract: In recent years, the introduction of Multi-modal Large Language Models
(MLLMs) into video understanding tasks has become increasingly prevalent.
However, how to effectively integrate temporal information remains a critical
research focus. Traditional approaches treat spatial and temporal information
separately. Due to issues like motion blur, it is challenging to accurately
represent the spatial information of rapidly moving objects. This can lead to
temporally important regions being underemphasized during spatial feature
extraction, which in turn hinders accurate spatio-temporal interaction and
video understanding. To address this limitation, we propose an innovative video
representation method called Dynamic-Image (DynImg). Specifically, we introduce
a set of non-key frames as temporal prompts to highlight the spatial areas
containing fast-moving objects. During the process of visual feature
extraction, these prompts guide the model to pay additional attention to the
fine-grained spatial features corresponding to these regions. Moreover, to
maintain the correct sequence for DynImg, we employ a corresponding 4D video
Rotary Position Embedding. This retains both the temporal and spatial adjacency
of DynImg, helping MLLM understand the spatio-temporal order within this
combined format. Experimental evaluations reveal that DynImg surpasses the
state-of-the-art methods by approximately 2% across multiple video
understanding benchmarks, proving the effectiveness of our temporal prompts in
enhancing video comprehension.

</details>


### [126] [Compress-Align-Detect: onboard change detection from unregistered images](https://arxiv.org/abs/2507.15578)
*Gabriele Inzerillo,Diego Valsesia,Aniello Fiengo,Enrico Magli*

Main category: cs.CV

TL;DR: 提出一种卫星上实时变化检测框架，解决数据存储、图像配准和变化检测的挑战，通过端到端深度神经网络实现高效处理。


<details>
  <summary>Details</summary>
Motivation: 传统卫星图像变化检测存在延迟，无法满足实时或近实时应用需求。

Method: 采用端到端深度神经网络，包含图像压缩、轻量级配准和高效变化检测三个子模块。

Result: 在低功耗硬件上实现0.7 Mpixel/s的吞吐量，F1分数表现优异。

Conclusion: 该框架首次将卫星上变化检测任务整合为端到端解决方案，性能显著优于现有方法。

Abstract: Change detection from satellite images typically incurs a delay ranging from
several hours up to days because of latency in downlinking the acquired images
and generating orthorectified image products at the ground stations; this may
preclude real- or near real-time applications. To overcome this limitation, we
propose shifting the entire change detection workflow onboard satellites. This
requires to simultaneously solve challenges in data storage, image registration
and change detection with a strict complexity constraint. In this paper, we
present a novel and efficient framework for onboard change detection that
addresses the aforementioned challenges in an end-to-end fashion with a deep
neural network composed of three interlinked submodules: (1) image compression,
tailored to minimize onboard data storage resources; (2) lightweight
co-registration of non-orthorectified multi-temporal image pairs; and (3) a
novel temporally-invariant and computationally efficient change detection
model. This is the first approach in the literature combining all these tasks
in a single end-to-end framework with the constraints dictated by onboard
processing. Experimental results compare each submodule with the current
state-of-the-art, and evaluate the performance of the overall integrated system
in realistic setting on low-power hardware. Compelling change detection results
are obtained in terms of F1 score as a function of compression rate, sustaining
a throughput of 0.7 Mpixel/s on a 15W accelerator.

</details>


### [127] [SegDT: A Diffusion Transformer-Based Segmentation Model for Medical Imaging](https://arxiv.org/abs/2507.15595)
*Salah Eddine Bekhouche,Gaby Maroun,Fadi Dornaika,Abdenour Hadid*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散变压器（DiT）的皮肤病变分割模型SegDT，适用于低成本硬件，并通过Rectified Flow提升生成质量，实现了快速推理和最新性能。


<details>
  <summary>Details</summary>
Motivation: 皮肤病变分割对皮肤癌诊断和患者监测至关重要，但现有方法在性能和效率上仍有改进空间。

Method: SegDT结合扩散变压器和Rectified Flow，优化生成质量并减少推理步骤，适用于低成本硬件。

Result: 在三个基准数据集上测试，SegDT达到了最新性能，同时保持快速推理速度。

Conclusion: SegDT为医学图像分析提供了高效、准确的工具，适用于实际医疗应用。

Abstract: Medical image segmentation is crucial for many healthcare tasks, including
disease diagnosis and treatment planning. One key area is the segmentation of
skin lesions, which is vital for diagnosing skin cancer and monitoring
patients. In this context, this paper introduces SegDT, a new segmentation
model based on diffusion transformer (DiT). SegDT is designed to work on
low-cost hardware and incorporates Rectified Flow, which improves the
generation quality at reduced inference steps and maintains the flexibility of
standard diffusion models. Our method is evaluated on three benchmarking
datasets and compared against several existing works, achieving
state-of-the-art results while maintaining fast inference speeds. This makes
the proposed model appealing for real-world medical applications. This work
advances the performance and capabilities of deep learning models in medical
image analysis, enabling faster, more accurate diagnostic tools for healthcare
professionals. The code is made publicly available at
\href{https://github.com/Bekhouche/SegDT}{GitHub}.

</details>


### [128] [Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos](https://arxiv.org/abs/2507.15597)
*Hao Luo,Yicheng Feng,Wanpeng Zhang,Sipeng Zheng,Ye Wang,Haoqi Yuan,Jiazheng Liu,Chaoyi Xu,Qin Jin,Zongqing Lu*

Main category: cs.CV

TL;DR: Being-H0是一个基于人类视频训练的高灵巧视觉-语言-动作模型，通过物理指令调优和新颖的数据处理流程，显著提升了复杂操作任务的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有模型在复杂操作任务中表现不佳，主要依赖合成数据或有限规模的遥操作演示，导致泛化能力差。

Method: 提出物理指令调优范式，结合大规模VLA预训练、物理空间对齐和机器人任务后适应，并引入毫米级重建精度的部分级运动标记化方法。

Result: Being-H0在手部运动生成和指令跟随方面表现优异，且在模型和数据规模扩大时仍保持良好性能。

Conclusion: 物理指令调优显著提升了模型在真实机器人操作任务中的表现，证明了其有效性。

Abstract: We introduce Being-H0, a dexterous Vision-Language-Action model (VLA) trained
on large-scale human videos. Existing VLAs struggle with complex manipulation
tasks requiring high dexterity and generalize poorly to novel scenarios and
tasks, primarily due to their reliance on synthetic data with significant
sim-to-real gaps or teleoperated demonstrations lacking scale and diversity. To
address this data bottleneck, we propose leveraging human hands as a foundation
manipulator, capitalizing on the rich dexterity and scalability present in web
data. Our approach centers on physical instruction tuning, a novel training
paradigm that combines large-scale VLA pretraining from human videos, physical
space alignment for 3D reasoning, and post-training adaptation for robotic
tasks. Additionally, we introduce a part-level motion tokenization method which
achieves millimeter-level reconstruction accuracy to model precise hand
trajectories for action learning. To support our proposed paradigm, we further
develop a comprehensive data curation pipeline that integrates heterogeneous
sources -- including motion capture, VR, and RGB-only videos -- into a
large-scale dataset with millions of motion-based instructional instances. We
empirically show the excellence of Being-H0 in hand motion generation and
instruction following, and it also scales well with model and data sizes.
Importantly, we observe the expected gains of Being-H0 in real-world robotic
manipulation as physical instruction tuning is applied. More details are
available at https://beingbeyond.github.io/Being-H0.

</details>


### [129] [SurfaceSplat: Connecting Surface Reconstruction and Gaussian Splatting](https://arxiv.org/abs/2507.15602)
*Zihui Gao,Jia-Wang Bian,Guosheng Lin,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: 提出了一种结合SDF和3DGS的混合方法，用于稀疏视图图像中的表面重建和新视角渲染，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决SDF方法在细节捕捉和3DGS方法在全局几何一致性上的不足。

Method: 结合SDF捕获粗几何以增强3DGS渲染，同时利用3DGS新渲染图像优化SDF细节。

Result: 在DTU和MobileBrick数据集上，表面重建和新视角合成性能优于现有方法。

Conclusion: 混合方法有效结合了SDF和3DGS的优势，提升了性能。

Abstract: Surface reconstruction and novel view rendering from sparse-view images are
challenging. Signed Distance Function (SDF)-based methods struggle with fine
details, while 3D Gaussian Splatting (3DGS)-based approaches lack global
geometry coherence. We propose a novel hybrid method that combines the
strengths of both approaches: SDF captures coarse geometry to enhance
3DGS-based rendering, while newly rendered images from 3DGS refine the details
of SDF for accurate surface reconstruction. As a result, our method surpasses
state-of-the-art approaches in surface reconstruction and novel view synthesis
on the DTU and MobileBrick datasets. Code will be released at
https://github.com/Gaozihui/SurfaceSplat.

</details>


### [130] [CylinderPlane: Nested Cylinder Representation for 3D-aware Image Generation](https://arxiv.org/abs/2507.15606)
*Ru Jia,Xiaozhuang Ma,Jianji Wang,Nanning Zheng*

Main category: cs.CV

TL;DR: 提出了一种基于圆柱坐标系的CylinderPlane表示方法，解决了Tri-plane表示中的多面伪影问题，实现了高质量、无伪影的360°图像合成。


<details>
  <summary>Details</summary>
Motivation: Tri-plane表示在3D感知图像生成中存在多面伪影等问题，限制了360°视图图像的生成能力。

Method: 采用圆柱坐标系设计CylinderPlane表示，通过嵌套圆柱结构捕捉多尺度特征，提升细节学习和分辨率适应性。

Result: 在合成数据集和真实图像上的实验表明，该方法优于现有技术。

Conclusion: CylinderPlane表示有效解决了特征模糊问题，提升了360°图像合成的质量和一致性。

Abstract: While the proposal of the Tri-plane representation has advanced the
development of the 3D-aware image generative models, problems rooted in its
inherent structure, such as multi-face artifacts caused by sharing the same
features in symmetric regions, limit its ability to generate 360$^\circ$ view
images. In this paper, we propose CylinderPlane, a novel implicit
representation based on Cylindrical Coordinate System, to eliminate the feature
ambiguity issue and ensure multi-view consistency in 360$^\circ$. Different
from the inevitable feature entanglement in Cartesian coordinate-based
Tri-plane representation, the cylindrical coordinate system explicitly
separates features at different angles, allowing our cylindrical representation
possible to achieve high-quality, artifacts-free 360$^\circ$ image synthesis.
We further introduce the nested cylinder representation that composites
multiple cylinders at different scales, thereby enabling the model more
adaptable to complex geometry and varying resolutions. The combination of
cylinders with different resolutions can effectively capture more critical
locations and multi-scale features, greatly facilitates fine detail learning
and robustness to different resolutions. Moreover, our representation is
agnostic to implicit rendering methods and can be easily integrated into any
neural rendering pipeline. Extensive experiments on both synthetic dataset and
unstructured in-the-wild images demonstrate that our proposed representation
achieves superior performance over previous methods.

</details>


### [131] [A Survey on Efficiency Optimization Techniques for DNN-based Video Analytics: Process Systems, Algorithms, and Applications](https://arxiv.org/abs/2507.15628)
*Shanjiang Tang,Rui Huang,Hsinyu Luo,Chunjiang Wang,Ce Yu,Yusen Li,Hao Fu,Chao Sun,and Jian Xiao*

Main category: cs.CV

TL;DR: 本文综述了深度学习神经网络（DNN）在视频分析中效率优化的技术，从硬件支持、数据处理等多角度进行了系统梳理，并讨论了现有挑战。


<details>
  <summary>Details</summary>
Motivation: 视频数据的爆炸式增长对视频分析的准确性和效率提出了更高要求，而现有研究多关注准确性优化，本文旨在填补效率优化领域的空白。

Method: 采用自下而上的方式组织现有方法，涵盖硬件支持、数据处理和操作部署等多个视角。

Result: 提出了一个优化框架，并基于现有工作分析了DNN在视频分析中的性能优化问题和挑战。

Conclusion: 本文为DNN在视频分析中的效率优化提供了全面综述，并指出了未来研究的方向和挑战。

Abstract: The explosive growth of video data in recent years has brought higher demands
for video analytics, where accuracy and efficiency remain the two primary
concerns. Deep neural networks (DNNs) have been widely adopted to ensure
accuracy; however, improving their efficiency in video analytics remains an
open challenge. Different from existing surveys that make summaries of
DNN-based video mainly from the accuracy optimization aspect, in this survey,
we aim to provide a thorough review of optimization techniques focusing on the
improvement of the efficiency of DNNs in video analytics. We organize existing
methods in a bottom-up manner, covering multiple perspectives such as hardware
support, data processing, operational deployment, etc. Finally, based on the
optimization framework and existing works, we analyze and discuss the problems
and challenges in the performance optimization of DNN-based video analytics.

</details>


### [132] [Experimenting active and sequential learning in a medieval music manuscript](https://arxiv.org/abs/2507.15633)
*Sachin Sharma,Federico Simonetta,Michele Flammini*

Main category: cs.CV

TL;DR: 论文研究了主动学习（AL）和序列学习（SL）在光学音乐识别（OMR）中的应用，针对中世纪音乐手稿的物体检测和布局识别，使用YOLOv8模型，通过选择不确定性最高的样本进行迭代标注和训练，以减少手动标注需求。


<details>
  <summary>Details</summary>
Motivation: 解决光学音乐识别中标注数据稀缺和历史手稿复杂性的问题，探索在数据稀缺场景下高效训练模型的方法。

Method: 采用YOLOv8模型，结合主动学习和序列学习，选择预测置信度最低的样本进行迭代标注和训练。

Result: 实验表明，该方法在显著减少标注样本的情况下，能达到与全监督训练相当的准确率。但在特定手稿中，基于不确定性的主动学习效果不佳。

Conclusion: 研究为数据稀缺场景提供了初步探索，但需开发更实用的方法以应对特定手稿的挑战。

Abstract: Optical Music Recognition (OMR) is a cornerstone of music digitization
initiatives in cultural heritage, yet it remains limited by the scarcity of
annotated data and the complexity of historical manuscripts. In this paper, we
present a preliminary study of Active Learning (AL) and Sequential Learning
(SL) tailored for object detection and layout recognition in an old medieval
music manuscript. Leveraging YOLOv8, our system selects samples with the
highest uncertainty (lowest prediction confidence) for iterative labeling and
retraining. Our approach starts with a single annotated image and successfully
boosts performance while minimizing manual labeling. Experimental results
indicate that comparable accuracy to fully supervised training can be achieved
with significantly fewer labeled examples. We test the methodology as a
preliminary investigation on a novel dataset offered to the community by the
Anonymous project, which studies laude, a poetical-musical genre spread across
Italy during the 12th-16th Century. We show that in the manuscript at-hand,
uncertainty-based AL is not effective and advocates for more usable methods in
data-scarcity scenarios.

</details>


### [133] [Extracting Visual Facts from Intermediate Layers for Mitigating Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2507.15652)
*Haoran Zhou,Zihan Zhang,Hao Chen*

Main category: cs.CV

TL;DR: 论文提出了一种名为EVA的训练无关方法，通过动态选择中间层提取视觉事实信息，显著减少多模态大语言模型中的幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在结合视觉和语言理解方面取得进展，但仍存在对象幻觉问题，即生成看似合理但实际错误的输出。研究发现先验知识在深层抑制视觉信息，但中间层的机制尚不明确。

Method: 提出EVA方法，通过对比中间层概率分布差异，动态选择视觉事实信息最显著的层，并将其整合到最终层以修正输出。

Result: 实验表明，EVA显著降低了幻觉率，优于基线方法。

Conclusion: EVA是一种模型无关、无需训练的方法，能有效减少MLLMs中的幻觉现象。

Abstract: Multimodal Large Language Models (MLLMs) have made significant strides by
combining visual recognition and language understanding to generate content
that is both coherent and contextually accurate. However, MLLMs continue to
struggle with object hallucinations, where models produce seemingly plausible
but factually incorrect outputs, including objects that do not exist in the
image. Recent work has revealed that the prior knowledge in MLLMs significantly
suppresses visual information in deep layers, causing hallucinatory outputs.
However, how these priors suppress visual information at the intermediate layer
stage in MLLMs remains unclear. We observe that visual factual knowledge and
the differences between intermediate-layer prior/original probability
distributions show similar evolutionary trends in intermediate layers.
Motivated by this, we introduce Decoding by Extracting Visual Facts (EVA), a
simple, training-free method that dynamically selects intermediate layers with
the most significant visual factual information. By contrasting the output
distributions of the selected layer derived from the original input and
pure-text input, EVA extracts visual factual knowledge and proportionally
incorporates it into the final layer to correct the output logits. Importantly,
EVA is model-agnostic, seamlessly integrates with various classic decoding
strategies, and is applicable across different MLLMs. We validate EVA on
widely-used benchmarks, and the results show that it significantly reduces
hallucination rates compared to baseline methods, underscoring its
effectiveness in mitigating hallucinations.

</details>


### [134] [HW-MLVQA: Elucidating Multilingual Handwritten Document Understanding with a Comprehensive VQA Benchmark](https://arxiv.org/abs/2507.15655)
*Aniket Pal,Ajoy Mondal,Minesh Mathew,C. V. Jawahar*

Main category: cs.CV

TL;DR: HW-MLVQA是一个新的多语言手写文档视觉问答基准，旨在解决现有模型在手写文档理解上的不足，包含1600页手写文档和2400个问答对。


<details>
  <summary>Details</summary>
Motivation: 当前多语言视觉问答模型在处理手写文档时能力不足，缺乏真实的多语言手写文档理解基准。

Method: HW-MLVQA提供文本、图像及图文结合三种模态的评估框架，并测试专有和开源OCR模型。

Result: 基准包含丰富的手写文档和问答对，支持多模态评估。

Conclusion: HW-MLVQA旨在推动多语言手写文档理解的研究和创新。

Abstract: The proliferation of MultiLingual Visual Question Answering (MLVQA)
benchmarks augments the capabilities of large language models (LLMs) and
multi-modal LLMs, thereby enabling them to adeptly capture the intricate
linguistic subtleties and visual complexities inherent across diverse
languages. Despite its potential, the current MLVQA model struggles to fully
utilize its capabilities when dealing with the extensive variety of handwritten
documents. This article delineates HW-MLVQA, an avant-garde VQA benchmark
meticulously crafted to mitigate the dearth of authentic Multilingual
Handwritten document comprehension. HW-MLVQA encompasses an extensive
collection of 1,600 handwritten Pages complemented by 2,400 question-answers.
Furthermore, it provides a robust benchmark evaluation framework spanning three
distinct modalities: text, image, and an integrated image & text modality. To
simulate authentic real-world contexts devoid of ground truth textual
transcriptions, we facilitates a rigorous assessment of proprietary and
open-source OCR models. The benchmark aspires to facilitate pivotal
advancements in multilingual handwritten document interpretation, fostering
innovation and scholarly inquiry within this specialized domain.

</details>


### [135] [Visual-Language Model Knowledge Distillation Method for Image Quality Assessment](https://arxiv.org/abs/2507.15680)
*Yongkang Hou,Jiarun Song*

Main category: cs.CV

TL;DR: 提出了一种基于视觉语言模型知识蒸馏的方法，用于改进图像质量评估任务，减少模型复杂度并提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决CLIP在图像质量评估任务中参数过多和局部失真特征识别能力不足的问题。

Method: 设计质量分级提示模板，微调CLIP，并提出模态自适应知识蒸馏策略。

Result: 在多个IQA数据集上表现优于现有方法，同时显著降低模型复杂度。

Conclusion: 该方法展示了实际部署的潜力，为IQA任务提供了高效解决方案。

Abstract: Image Quality Assessment (IQA) is a core task in computer vision. Multimodal
methods based on vision-language models, such as CLIP, have demonstrated
exceptional generalization capabilities in IQA tasks. To address the issues of
excessive parameter burden and insufficient ability to identify local distorted
features in CLIP for IQA, this study proposes a visual-language model knowledge
distillation method aimed at guiding the training of models with architectural
advantages using CLIP's IQA knowledge. First, quality-graded prompt templates
were designed to guide CLIP to output quality scores. Then, CLIP is fine-tuned
to enhance its capabilities in IQA tasks. Finally, a modality-adaptive
knowledge distillation strategy is proposed to achieve guidance from the CLIP
teacher model to the student model. Our experiments were conducted on multiple
IQA datasets, and the results show that the proposed method significantly
reduces model complexity while outperforming existing IQA methods,
demonstrating strong potential for practical deployment.

</details>


### [136] [Hi^2-GSLoc: Dual-Hierarchical Gaussian-Specific Visual Relocalization for Remote Sensing](https://arxiv.org/abs/2507.15683)
*Boni Hu,Zhenyu Xia,Lin Chen,Pengcheng Han,Shuhui Bu*

Main category: cs.CV

TL;DR: 提出了一种基于3D高斯溅射（3DGS）的双层次视觉重定位框架Hi²-GSLoc，通过稀疏到密集、粗到细的范式，解决了现有方法在精度和计算复杂度上的权衡问题，适用于大规模遥感场景。


<details>
  <summary>Details</summary>
Motivation: 现有视觉重定位方法在精度和计算复杂度之间存在固有权衡，尤其在遥感场景中面临大规模、高海拔变化和领域差距的挑战。

Method: 采用3DGS作为场景表示，提出双层次框架Hi²-GSLoc，包括稀疏阶段的渲染感知采样和地标检测，以及密集阶段的迭代细化匹配。结合分区训练、GPU并行匹配和动态内存管理。

Result: 在仿真数据、公共数据集和实际飞行实验中，方法表现出竞争性的定位精度、召回率和计算效率，并能有效过滤不可靠位姿估计。

Conclusion: Hi²-GSLoc为遥感应用提供了一种高效且精确的视觉重定位解决方案。

Abstract: Visual relocalization, which estimates the 6-degree-of-freedom (6-DoF) camera
pose from query images, is fundamental to remote sensing and UAV applications.
Existing methods face inherent trade-offs: image-based retrieval and pose
regression approaches lack precision, while structure-based methods that
register queries to Structure-from-Motion (SfM) models suffer from
computational complexity and limited scalability. These challenges are
particularly pronounced in remote sensing scenarios due to large-scale scenes,
high altitude variations, and domain gaps of existing visual priors. To
overcome these limitations, we leverage 3D Gaussian Splatting (3DGS) as a novel
scene representation that compactly encodes both 3D geometry and appearance. We
introduce $\mathrm{Hi}^2$-GSLoc, a dual-hierarchical relocalization framework
that follows a sparse-to-dense and coarse-to-fine paradigm, fully exploiting
the rich semantic information and geometric constraints inherent in Gaussian
primitives. To handle large-scale remote sensing scenarios, we incorporate
partitioned Gaussian training, GPU-accelerated parallel matching, and dynamic
memory management strategies. Our approach consists of two stages: (1) a sparse
stage featuring a Gaussian-specific consistent render-aware sampling strategy
and landmark-guided detector for robust and accurate initial pose estimation,
and (2) a dense stage that iteratively refines poses through coarse-to-fine
dense rasterization matching while incorporating reliability verification.
Through comprehensive evaluation on simulation data, public datasets, and real
flight experiments, we demonstrate that our method delivers competitive
localization accuracy, recall rate, and computational efficiency while
effectively filtering unreliable pose estimates. The results confirm the
effectiveness of our approach for practical remote sensing applications.

</details>


### [137] [DWTGS: Rethinking Frequency Regularization for Sparse-view 3D Gaussian Splatting](https://arxiv.org/abs/2507.15690)
*Hung Nguyen,Runfa Li,An Le,Truong Nguyen*

Main category: cs.CV

TL;DR: DWTGS提出了一种基于小波变换的频率正则化方法，通过监督低频子带并自监督高频子带，改善了稀疏视图3D高斯泼溅的重建质量。


<details>
  <summary>Details</summary>
Motivation: 稀疏视图3D高斯泼溅（3DGS）在重建高质量新视图时容易过拟合高频细节，现有基于傅里叶变换的频率正则化方法参数调优困难且偏向有害高频学习。

Method: 提出DWTGS框架，利用小波空间损失提供额外的空间监督，仅监督低频LL子带，同时对高频HH子带进行自监督稀疏化。

Result: 实验表明，DWTGS在多个基准测试中优于基于傅里叶的方法，低频策略提高了泛化能力并减少了高频幻觉。

Conclusion: DWTGS通过小波变换的频率正则化方法，有效解决了稀疏视图3DGS的高频过拟合问题。

Abstract: Sparse-view 3D Gaussian Splatting (3DGS) presents significant challenges in
reconstructing high-quality novel views, as it often overfits to the
widely-varying high-frequency (HF) details of the sparse training views. While
frequency regularization can be a promising approach, its typical reliance on
Fourier transforms causes difficult parameter tuning and biases towards
detrimental HF learning. We propose DWTGS, a framework that rethinks frequency
regularization by leveraging wavelet-space losses that provide additional
spatial supervision. Specifically, we supervise only the low-frequency (LF) LL
subbands at multiple DWT levels, while enforcing sparsity on the HF HH subband
in a self-supervised manner. Experiments across benchmarks show that DWTGS
consistently outperforms Fourier-based counterparts, as this LF-centric
strategy improves generalization and reduces HF hallucinations.

</details>


### [138] [Efficient Face Image Quality Assessment via Self-training and Knowledge Distillation](https://arxiv.org/abs/2507.15709)
*Wei Sun,Weixia Zhang,Linhan Cao,Jun Jia,Xiangyang Zhu,Dandan Zhu,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提出了一种高效的人脸图像质量评估方法，通过教师-学生模型和自训练策略，实现了低计算开销的高性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有FIQA方法计算复杂度高、难以实际部署的问题。

Method: 采用两阶段方法：训练强大的教师模型，并通过自训练和知识蒸馏生成轻量级学生模型。

Result: 学生模型性能接近教师模型，计算开销极低，并在ICCV 2025 VQualA FIQA挑战赛中夺冠。

Conclusion: 该方法高效且实用，适合实际部署。

Abstract: Face image quality assessment (FIQA) is essential for various face-related
applications. Although FIQA has been extensively studied and achieved
significant progress, the computational complexity of FIQA algorithms remains a
key concern for ensuring scalability and practical deployment in real-world
systems. In this paper, we aim to develop a computationally efficient FIQA
method that can be easily deployed in real-world applications. Specifically,
our method consists of two stages: training a powerful teacher model and
distilling a lightweight student model from it. To build a strong teacher
model, we adopt a self-training strategy to improve its capacity. We first
train the teacher model using labeled face images, then use it to generate
pseudo-labels for a set of unlabeled images. These pseudo-labeled samples are
used in two ways: (1) to distill knowledge into the student model, and (2) to
combine with the original labeled images to further enhance the teacher model
through self-training. The enhanced teacher model is used to further
pseudo-label another set of unlabeled images for distilling the student models.
The student model is trained using a combination of labeled images,
pseudo-labeled images from the original teacher model, and pseudo-labeled
images from the enhanced teacher model. Experimental results demonstrate that
our student model achieves comparable performance to the teacher model with an
extremely low computational overhead. Moreover, our method achieved first place
in the ICCV 2025 VQualA FIQA Challenge. The code is available at
https://github.com/sunwei925/Efficient-FIQA.git.

</details>


### [139] [A Practical Investigation of Spatially-Controlled Image Generation with Transformers](https://arxiv.org/abs/2507.15724)
*Guoxuan Xia,Harleen Hanspal,Petru-Daniel Tudosiu,Shifeng Zhang,Sarah Parisot*

Main category: cs.CV

TL;DR: 论文探讨了空间控制图像生成模型的改进，通过对比实验澄清了不同生成范式的优劣，提出了控制标记预填充作为基线方法，并研究了采样时间增强的影响。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决现有模型在空间控制生成任务中缺乏科学比较的问题，澄清文献中的知识空白，并为实践者提供清晰的指导。

Method: 在ImageNet上进行控制实验，比较扩散模型、基于流的模型和自回归模型，提出控制标记预填充方法，并研究采样时间增强技术。

Result: 控制标记预填充是一种简单且高效的基线方法；采样时间增强（如分类器自由引导和softmax截断）显著提升了控制生成一致性；适配器方法在有限数据下保持生成质量但一致性较差。

Conclusion: 论文为空间控制图像生成提供了实践指导，澄清了不同方法的优缺点，并填补了文献中的知识空白。

Abstract: Enabling image generation models to be spatially controlled is an important
area of research, empowering users to better generate images according to their
own fine-grained specifications via e.g. edge maps, poses. Although this task
has seen impressive improvements in recent times, a focus on rapidly producing
stronger models has come at the cost of detailed and fair scientific
comparison. Differing training data, model architectures and generation
paradigms make it difficult to disentangle the factors contributing to
performance. Meanwhile, the motivations and nuances of certain approaches
become lost in the literature. In this work, we aim to provide clear takeaways
across generation paradigms for practitioners wishing to develop
transformer-based systems for spatially-controlled generation, clarifying the
literature and addressing knowledge gaps. We perform controlled experiments on
ImageNet across diffusion-based/flow-based and autoregressive (AR) models.
First, we establish control token prefilling as a simple, general and
performant baseline approach for transformers. We then investigate previously
underexplored sampling time enhancements, showing that extending
classifier-free guidance to control, as well as softmax truncation, have a
strong impact on control-generation consistency. Finally, we re-clarify the
motivation of adapter-based approaches, demonstrating that they mitigate
"forgetting" and maintain generation quality when trained on limited downstream
data, but underperform full training in terms of generation-control
consistency. Code will be released upon publication.

</details>


### [140] [TokensGen: Harnessing Condensed Tokens for Long Video Generation](https://arxiv.org/abs/2507.15728)
*Wenqi Ouyang,Zeqi Xiao,Danni Yang,Yifan Zhou,Shuai Yang,Lei Yang,Jianlou Si,Xingang Pan*

Main category: cs.CV

TL;DR: TokensGen是一个两阶段框架，通过视频令牌解决长视频生成中的内存和一致性挑战。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成短视频时表现优异，但扩展到长视频时面临内存瓶颈和长期不一致性问题。

Method: 1. 训练To2V（Token-to-Video）模型，生成短视频；2. 引入T2To（Text-to-Token）模型，确保全局一致性；3. 使用自适应FIFO-Diffusion策略平滑过渡相邻片段。

Result: 实验表明，该方法显著提升了长期时间和内容一致性，且计算开销可控。

Conclusion: TokensGen为长视频生成提供了可扩展的模块化解决方案，适用于故事叙述、电影制作和沉浸式模拟。

Abstract: Generating consistent long videos is a complex challenge: while
diffusion-based generative models generate visually impressive short clips,
extending them to longer durations often leads to memory bottlenecks and
long-term inconsistency. In this paper, we propose TokensGen, a novel two-stage
framework that leverages condensed tokens to address these issues. Our method
decomposes long video generation into three core tasks: (1) inner-clip semantic
control, (2) long-term consistency control, and (3) inter-clip smooth
transition. First, we train To2V (Token-to-Video), a short video diffusion
model guided by text and video tokens, with a Video Tokenizer that condenses
short clips into semantically rich tokens. Second, we introduce T2To
(Text-to-Token), a video token diffusion transformer that generates all tokens
at once, ensuring global consistency across clips. Finally, during inference,
an adaptive FIFO-Diffusion strategy seamlessly connects adjacent clips,
reducing boundary artifacts and enhancing smooth transitions. Experimental
results demonstrate that our approach significantly enhances long-term temporal
and content coherence without incurring prohibitive computational overhead. By
leveraging condensed tokens and pre-trained short video models, our method
provides a scalable, modular solution for long video generation, opening new
possibilities for storytelling, cinematic production, and immersive
simulations. Please see our project page at
https://vicky0522.github.io/tokensgen-webpage/ .

</details>


### [141] [Appearance Harmonization via Bilateral Grid Prediction with Transformers for 3DGS](https://arxiv.org/abs/2507.15748)
*Jisu Shin,Richard Shaw,Seunghyun Shin,Anton Pelykh,Zhensong Zhang,Hae-Gon Jeon,Eduardo Perez-Pellitero*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的方法，通过预测空间自适应的双边网格来校正多视角的光度变化，无需场景特定重训练，提升了重建质量和训练效率。


<details>
  <summary>Details</summary>
Motivation: 现代相机处理流程（如曝光调整、白平衡等）会导致多视角间的光度不一致，影响新视角合成的质量。现有方法通过联合优化场景表示和每张图像的外观嵌入来解决，但增加了计算复杂性和训练时间。

Method: 使用Transformer预测空间自适应的双边网格，校正光度变化，并将其集成到3D高斯泼溅流程中。

Result: 实验表明，该方法在重建质量和收敛速度上优于或匹配现有的场景特定优化方法。

Conclusion: 该方法在多视角一致性和跨场景泛化能力上表现优异，同时保持了高效的训练速度。

Abstract: Modern camera pipelines apply extensive on-device processing, such as
exposure adjustment, white balance, and color correction, which, while
beneficial individually, often introduce photometric inconsistencies across
views. These appearance variations violate multi-view consistency and degrade
the quality of novel view synthesis. Joint optimization of scene
representations and per-image appearance embeddings has been proposed to
address this issue, but at the cost of increased computational complexity and
slower training. In this work, we propose a transformer-based method that
predicts spatially adaptive bilateral grids to correct photometric variations
in a multi-view consistent manner, enabling robust cross-scene generalization
without the need for scene-specific retraining. By incorporating the learned
grids into the 3D Gaussian Splatting pipeline, we improve reconstruction
quality while maintaining high training efficiency. Extensive experiments show
that our approach outperforms or matches existing scene-specific optimization
methods in reconstruction fidelity and convergence speed.

</details>


### [142] [Learning from Heterogeneity: Generalizing Dynamic Facial Expression Recognition via Distributionally Robust Optimization](https://arxiv.org/abs/2507.15765)
*Feng-Qi Cui,Anyang Tong,Jinyang Huang,Jie Zhang,Dan Guo,Zhi Liu,Meng Wang*

Main category: cs.CV

TL;DR: 提出了一种名为HDF的新框架，通过两个模块增强时间-频率建模并优化样本不平衡问题，显著提升了动态面部表情识别的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决多源数据和个体表达差异导致的样本异质性对动态面部表情识别性能的影响。

Method: 设计了Time-Frequency Distributional Attention Module (DAM)和Distribution-aware Scaling Module (DSM)，分别用于时间-频率建模和动态平衡分类与对比损失。

Result: 在DFEW和FERV39k数据集上表现出色，显著提高了加权平均召回率(WAR)和非加权平均召回率(UAR)。

Conclusion: HDF框架有效提升了动态面部表情识别的性能，尤其在多样化和不平衡场景中表现优异。

Abstract: Dynamic Facial Expression Recognition (DFER) plays a critical role in
affective computing and human-computer interaction. Although existing methods
achieve comparable performance, they inevitably suffer from performance
degradation under sample heterogeneity caused by multi-source data and
individual expression variability. To address these challenges, we propose a
novel framework, called Heterogeneity-aware Distributional Framework (HDF), and
design two plug-and-play modules to enhance time-frequency modeling and
mitigate optimization imbalance caused by hard samples. Specifically, the
Time-Frequency Distributional Attention Module (DAM) captures both temporal
consistency and frequency robustness through a dual-branch attention design,
improving tolerance to sequence inconsistency and visual style shifts. Then,
based on gradient sensitivity and information bottleneck principles, an
adaptive optimization module Distribution-aware Scaling Module (DSM) is
introduced to dynamically balance classification and contrastive losses,
enabling more stable and discriminative representation learning. Extensive
experiments on two widely used datasets, DFEW and FERV39k, demonstrate that HDF
significantly improves both recognition accuracy and robustness. Our method
achieves superior weighted average recall (WAR) and unweighted average recall
(UAR) while maintaining strong generalization across diverse and imbalanced
scenarios. Codes are released at https://github.com/QIcita/HDF_DFER.

</details>


### [143] [Label tree semantic losses for rich multi-class medical image segmentation](https://arxiv.org/abs/2507.15777)
*Junwen Wang,Oscar MacCormac,William Rochford,Aaron Kujawa,Jonathan Shapey,Tom Vercauteren*

Main category: cs.CV

TL;DR: 论文提出两种基于树结构的语义损失函数，利用标签的层次结构优化医学图像分割任务，并在稀疏标注场景下验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法对所有错误同等惩罚，未能利用标签空间的语义信息，尤其在标签类别丰富且差异细微时表现不佳。

Method: 提出两种基于树结构的语义损失函数，结合稀疏标注训练方法，扩展其适用性。

Result: 在头部MRI全脑分区和神经外科高光谱成像任务中，方法达到SOTA性能。

Conclusion: 树结构语义损失函数能有效提升医学图像分割的准确性和鲁棒性。

Abstract: Rich and accurate medical image segmentation is poised to underpin the next
generation of AI-defined clinical practice by delineating critical anatomy for
pre-operative planning, guiding real-time intra-operative navigation, and
supporting precise post-operative assessment. However, commonly used learning
methods for medical and surgical imaging segmentation tasks penalise all errors
equivalently and thus fail to exploit any inter-class semantics in the labels
space. This becomes particularly problematic as the cardinality and richness of
labels increases to include subtly different classes. In this work, we propose
two tree-based semantic loss functions which take advantage of a hierarchical
organisation of the labels. We further incorporate our losses in a recently
proposed approach for training with sparse, background-free annotations to
extend the applicability of our proposed losses. Extensive experiments are
reported on two medical and surgical image segmentation tasks, namely head MRI
for whole brain parcellation (WBP) with full supervision and neurosurgical
hyperspectral imaging (HSI) for scene understanding with sparse annotations.
Results demonstrate that our proposed method reaches state-of-the-art
performance in both cases.

</details>


### [144] [Regularized Low-Rank Adaptation for Few-Shot Organ Segmentation](https://arxiv.org/abs/2507.15793)
*Ghassen Baklouti,Julio Silva-Rodríguez,Jose Dolz,Houda Bahig,Ismail Ben Ayed*

Main category: cs.CV

TL;DR: 论文提出了一种动态调整低秩适应（LoRA）秩的新方法，用于医学图像分割，通过引入稀疏正则化自动优化秩选择，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统LoRA方法需要固定秩，难以适应不同医学图像任务的复杂性，因此需要一种动态调整秩的方法。

Method: 通过奇异值分解和l_1稀疏正则化动态调整低秩表示的秩，并使用近端优化器优化。

Result: 在少样本微调实验中，新方法显著优于标准LoRA和其他PEFT方法，表现出高效性和鲁棒性。

Conclusion: 动态调整秩的方法在医学图像分割中具有显著优势，代码已开源。

Abstract: Parameter-efficient fine-tuning (PEFT) of pre-trained foundation models is
increasingly attracting interest in medical imaging due to its effectiveness
and computational efficiency. Among these methods, Low-Rank Adaptation (LoRA)
is a notable approach based on the assumption that the adaptation inherently
occurs in a low-dimensional subspace. While it has shown good performance, its
implementation requires a fixed and unalterable rank, which might be
challenging to select given the unique complexities and requirements of each
medical imaging downstream task. Inspired by advancements in natural image
processing, we introduce a novel approach for medical image segmentation that
dynamically adjusts the intrinsic rank during adaptation. Viewing the low-rank
representation of the trainable weight matrices as a singular value
decomposition, we introduce an l_1 sparsity regularizer to the loss function,
and tackle it with a proximal optimizer. The regularizer could be viewed as a
penalty on the decomposition rank. Hence, its minimization enables to find
task-adapted ranks automatically. Our method is evaluated in a realistic
few-shot fine-tuning setting, where we compare it first to the standard LoRA
and then to several other PEFT methods across two distinguishable tasks: base
organs and novel organs. Our extensive experiments demonstrate the significant
performance improvements driven by our method, highlighting its efficiency and
robustness against suboptimal rank initialization. Our code is publicly
available: https://github.com/ghassenbaklouti/ARENA

</details>


### [145] [Exploring Superposition and Interference in State-of-the-Art Low-Parameter Vision Models](https://arxiv.org/abs/2507.15798)
*Lilian Hollard,Lucas Mohimont,Nathalie Gaveau,Luiz-Angelo Steffenel*

Main category: cs.CV

TL;DR: 论文研究了低参数深度神经网络在计算机视觉中的性能，重点关注瓶颈架构及其使用超线性激活函数的行为，提出减少特征图干扰的方法，并设计了一个名为NoDepth Bottleneck的高效架构。


<details>
  <summary>Details</summary>
Motivation: 研究低参数深度神经网络中特征图干扰现象，以提升小规模网络（参数少于150万）的扩展性和准确性。

Method: 通过分析不同瓶颈架构，识别减少干扰的关键设计元素，并基于实验提出NoDepth Bottleneck架构。

Result: 在ImageNet数据集上验证了NoDepth Bottleneck的扩展性和准确性。

Conclusion: 研究为低参数范围的高效神经网络提供了新思路，并深化了对计算机视觉中瓶颈架构的理解。

Abstract: The paper investigates the performance of state-of-the-art low-parameter deep
neural networks for computer vision, focusing on bottleneck architectures and
their behavior using superlinear activation functions. We address interference
in feature maps, a phenomenon associated with superposition, where neurons
simultaneously encode multiple characteristics. Our research suggests that
limiting interference can enhance scaling and accuracy in very low-scaled
networks (under 1.5M parameters). We identify key design elements that reduce
interference by examining various bottleneck architectures, leading to a more
efficient neural network. Consequently, we propose a proof-of-concept
architecture named NoDepth Bottleneck built on mechanistic insights from our
experiments, demonstrating robust scaling accuracy on the ImageNet dataset.
These findings contribute to more efficient and scalable neural networks for
the low-parameter range and advance the understanding of bottlenecks in
computer vision. https://caiac.pubpub.org/pub/3dh6rsel

</details>


### [146] [Diffusion models for multivariate subsurface generation and efficient probabilistic inversion](https://arxiv.org/abs/2507.15809)
*Roberto Miele,Niklas Linde*

Main category: cs.CV

TL;DR: 扩散模型在多元地下建模和概率反演中表现出色，优于变分自编码器和生成对抗网络。提出对Diffusion Posterior Sampling方法的改进，提高了统计鲁棒性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 探索扩散模型在多元地下建模和概率反演中的应用，以解决现有方法（如变分自编码器和生成对抗网络）的局限性。

Method: 提出对Diffusion Posterior Sampling方法的改进，包括引入噪声污染似然近似，并应用于地质场景中的条件建模。

Result: 改进方法显著提高了统计鲁棒性、后验概率密度采样效率，并降低了计算成本。

Conclusion: 扩散模型在多元地下建模和概率反演中具有高效性和灵活性，适用于多种条件数据。

Abstract: Diffusion models offer stable training and state-of-the-art performance for
deep generative modeling tasks. Here, we consider their use in the context of
multivariate subsurface modeling and probabilistic inversion. We first
demonstrate that diffusion models enhance multivariate modeling capabilities
compared to variational autoencoders and generative adversarial networks. In
diffusion modeling, the generative process involves a comparatively large
number of time steps with update rules that can be modified to account for
conditioning data. We propose different corrections to the popular Diffusion
Posterior Sampling approach by Chung et al. (2023). In particular, we introduce
a likelihood approximation accounting for the noise-contamination that is
inherent in diffusion modeling. We assess performance in a multivariate
geological scenario involving facies and correlated acoustic impedance.
Conditional modeling is demonstrated using both local hard data (well logs) and
nonlinear geophysics (fullstack seismic data). Our tests show significantly
improved statistical robustness, enhanced sampling of the posterior probability
density function and reduced computational costs, compared to the original
approach. The method can be used with both hard and indirect conditioning data,
individually or simultaneously. As the inversion is included within the
diffusion process, it is faster than other methods requiring an outer-loop
around the generative model, such as Markov chain Monte Carlo.

</details>


### [147] [Can Your Model Separate Yolks with a Water Bottle? Benchmarking Physical Commonsense Understanding in Video Generation Models](https://arxiv.org/abs/2507.15824)
*Enes Sanli,Baris Sarper Tezcan,Aykut Erdem,Erkut Erdem*

Main category: cs.CV

TL;DR: PhysVidBench是一个评估文本到视频生成模型物理常识能力的基准，包含383个精心设计的提示，通过三阶段评估流程间接测试模型的物理合理性。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频生成模型在物理常识方面表现不足，常违反因果关系和对象行为等基本物理规则。

Method: 设计PhysVidBench基准，包含工具使用、材料属性等领域的提示，采用三阶段评估（问题生成、视频描述、语言模型回答）。

Result: 通过间接评估策略避免了直接视频评估中的幻觉问题，为生成视频模型的物理常识评估提供了结构化框架。

Conclusion: PhysVidBench填补了当前文本到视频评估的空白，强调了物理合理性的重要性。

Abstract: Recent progress in text-to-video (T2V) generation has enabled the synthesis
of visually compelling and temporally coherent videos from natural language.
However, these models often fall short in basic physical commonsense, producing
outputs that violate intuitive expectations around causality, object behavior,
and tool use. Addressing this gap, we present PhysVidBench, a benchmark
designed to evaluate the physical reasoning capabilities of T2V systems. The
benchmark includes 383 carefully curated prompts, emphasizing tool use,
material properties, and procedural interactions, and domains where physical
plausibility is crucial. For each prompt, we generate videos using diverse
state-of-the-art models and adopt a three-stage evaluation pipeline: (1)
formulate grounded physics questions from the prompt, (2) caption the generated
video with a vision-language model, and (3) task a language model to answer
several physics-involved questions using only the caption. This indirect
strategy circumvents common hallucination issues in direct video-based
evaluation. By highlighting affordances and tool-mediated actions, areas
overlooked in current T2V evaluations, PhysVidBench provides a structured,
interpretable framework for assessing physical commonsense in generative video
models.

</details>


### [148] [Latent Denoising Makes Good Visual Tokenizers](https://arxiv.org/abs/2507.15856)
*Jiawei Yang,Tianhong Li,Lijie Fan,Yonglong Tian,Yue Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为l-DeTok的视觉分词器，通过直接与下游去噪目标对齐，提升生成模型的效果。


<details>
  <summary>Details</summary>
Motivation: 现代生成模型共享类似的训练目标（去噪），但视觉分词器的有效属性尚不明确。作者希望通过对齐分词器嵌入与去噪目标，提升生成效果。

Method: 提出Latent Denoising Tokenizer (l-DeTok)，通过训练分词器从受噪声和掩码污染的潜在嵌入中重建干净图像。

Result: 在ImageNet 256x256上，l-DeTok在六种代表性生成模型中均优于标准分词器。

Conclusion: 去噪是分词器设计的基本原则，可为未来分词器开发提供新视角。

Abstract: Despite their fundamental role, it remains unclear what properties could make
visual tokenizers more effective for generative modeling. We observe that
modern generative models share a conceptually similar training objective --
reconstructing clean signals from corrupted inputs such as Gaussian noise or
masking -- a process we term denoising. Motivated by this insight, we propose
aligning tokenizer embeddings directly with the downstream denoising objective,
encouraging latent embeddings to be more easily reconstructed even when heavily
corrupted. To achieve this, we introduce the Latent Denoising Tokenizer
(l-DeTok), a simple yet effective tokenizer trained to reconstruct clean images
from latent embeddings corrupted by interpolative noise and random masking.
Extensive experiments on ImageNet 256x256 demonstrate that our tokenizer
consistently outperforms standard tokenizers across six representative
generative models. Our findings highlight denoising as a fundamental design
principle for tokenizer development, and we hope it could motivate new
perspectives for future tokenizer design.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [149] [The Free Will Equation: Quantum Field Analogies for AGI](https://arxiv.org/abs/2507.14154)
*Rahul Kabali*

Main category: cs.AI

TL;DR: 论文提出了一种名为“自由意志方程”的理论框架，借鉴量子场论，赋予AGI一种可控的随机性决策能力，以提升其适应性和创造力。


<details>
  <summary>Details</summary>
Motivation: 传统AGI研究专注于确定性规则下的目标优化，但人类智能具有自发性决策能力（类似“自由意志”），这对创造力和适应性至关重要。

Method: 通过将AI的认知状态视为潜在行动的叠加态（类似量子波函数），并结合量子场论机制和内在动机项，实现决策时的概率性选择。

Result: 在非稳态多臂老虎机环境中的实验表明，采用该框架的智能体比基线方法获得更高的奖励和策略多样性。

Conclusion: 该框架为AGI提供了一种模拟“自由意志”的方法，有望提升其在复杂环境中的适应性和创新能力。

Abstract: Artificial General Intelligence (AGI) research traditionally focuses on
algorithms that optimize for specific goals under deterministic rules. Yet,
human-like intelligence exhibits adaptive spontaneity - an ability to make
unexpected choices or free decisions not strictly dictated by past data or
immediate reward. This trait, often dubbed "free will" in a loose sense, might
be crucial for creativity, robust adaptation, and avoiding ruts in
problem-solving. This paper proposes a theoretical framework, called the Free
Will Equation, that draws analogies from quantum field theory to endow AGI
agents with a form of adaptive, controlled stochasticity in their
decision-making process. The core idea is to treat an AI agent's cognitive
state as a superposition of potential actions or thoughts, which collapses
probabilistically into a concrete action when a decision is made - much like a
quantum wavefunction collapsing upon measurement. By incorporating mechanisms
analogous to quantum fields, along with intrinsic motivation terms, we aim to
improve an agent's ability to explore novel strategies and adapt to unforeseen
changes. Experiments in a non-stationary multi-armed bandit environment
demonstrate that agents using this framework achieve higher rewards and policy
diversity compared to baseline methods.

</details>


### [150] [DREAMS: Density Functional Theory Based Research Engine for Agentic Materials Simulation](https://arxiv.org/abs/2507.14267)
*Ziqi Wang,Hongshuo Huang,Hancheng Zhao,Changwen Xu,Shang Zhu,Jan Janssen,Venkatasubramanian Viswanathan*

Main category: cs.AI

TL;DR: DREAMS是一个基于DFT的多智能体框架，通过LLM代理实现材料发现的高通量、高保真模拟，减少对人类专家的依赖。


<details>
  <summary>Details</summary>
Motivation: 解决DFT模拟中的训练时间长、参数调优复杂和系统误差处理问题。

Method: 采用分层多智能体框架，结合LLM规划代理和领域特定代理，共享画布辅助协作。

Result: 在Sol27LC基准测试中误差低于1%，解决了CO/Pt(111)吸附难题，并量化了功能驱动的不确定性。

Conclusion: DREAMS实现了L3级自动化，显著减少对人类干预的依赖，推动材料发现的民主化。

Abstract: Materials discovery relies on high-throughput, high-fidelity simulation
techniques such as Density Functional Theory (DFT), which require years of
training, extensive parameter fine-tuning and systematic error handling. To
address these challenges, we introduce the DFT-based Research Engine for
Agentic Materials Screening (DREAMS), a hierarchical, multi-agent framework for
DFT simulation that combines a central Large Language Model (LLM) planner agent
with domain-specific LLM agents for atomistic structure generation, systematic
DFT convergence testing, High-Performance Computing (HPC) scheduling, and error
handling. In addition, a shared canvas helps the LLM agents to structure their
discussions, preserve context and prevent hallucination. We validate DREAMS
capabilities on the Sol27LC lattice-constant benchmark, achieving average
errors below 1\% compared to the results of human DFT experts. Furthermore, we
apply DREAMS to the long-standing CO/Pt(111) adsorption puzzle, demonstrating
its long-term and complex problem-solving capabilities. The framework again
reproduces expert-level literature adsorption-energy differences. Finally,
DREAMS is employed to quantify functional-driven uncertainties with Bayesian
ensemble sampling, confirming the Face Centered Cubic (FCC)-site preference at
the Generalized Gradient Approximation (GGA) DFT level. In conclusion, DREAMS
approaches L3-level automation - autonomous exploration of a defined design
space - and significantly reduces the reliance on human expertise and
intervention, offering a scalable path toward democratized, high-throughput,
high-fidelity computational materials discovery.

</details>


### [151] [WebGuard: Building a Generalizable Guardrail for Web Agents](https://arxiv.org/abs/2507.14293)
*Boyuan Zheng,Zeyi Liao,Scott Salisbury,Zeyuan Liu,Michael Lin,Qinyuan Zheng,Zifan Wang,Xiang Deng,Dawn Song,Huan Sun,Yu Su*

Main category: cs.AI

TL;DR: WebGuard是一个用于评估网络代理行为风险的数据集，旨在开发安全措施。研究发现当前LLMs在预测高风险行为上表现不佳，但通过微调模型可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs驱动的自主网络代理快速发展，其潜在风险（如无意或有害行为）亟需有效安全措施。

Method: 引入WebGuard数据集，包含4,939条人工标注的网络行为，按风险分为SAFE、LOW、HIGH三类，并用于微调模型评估。

Result: 前沿LLMs在预测行为结果和高风险行为召回率上表现不足（<60%），但微调后的Qwen2.5VL-7B模型显著提升性能（准确率37%→80%，高风险召回率20%→76%）。

Conclusion: 尽管微调模型性能提升，但仍未达到高风险部署所需的近乎完美的准确率和召回率要求。

Abstract: The rapid development of autonomous web agents powered by Large Language
Models (LLMs), while greatly elevating efficiency, exposes the frontier risk of
taking unintended or harmful actions. This situation underscores an urgent need
for effective safety measures, akin to access controls for human users. To
address this critical challenge, we introduce WebGuard, the first comprehensive
dataset designed to support the assessment of web agent action risks and
facilitate the development of guardrails for real-world online environments. In
doing so, WebGuard specifically focuses on predicting the outcome of
state-changing actions and contains 4,939 human-annotated actions from 193
websites across 22 diverse domains, including often-overlooked long-tail
websites. These actions are categorized using a novel three-tier risk schema:
SAFE, LOW, and HIGH. The dataset includes designated training and test splits
to support evaluation under diverse generalization settings. Our initial
evaluations reveal a concerning deficiency: even frontier LLMs achieve less
than 60% accuracy in predicting action outcomes and less than 60% recall in
lagging HIGH-risk actions, highlighting the risks of deploying
current-generation agents without dedicated safeguards. We therefore
investigate fine-tuning specialized guardrail models using WebGuard. We conduct
comprehensive evaluations across multiple generalization settings and find that
a fine-tuned Qwen2.5VL-7B model yields a substantial improvement in
performance, boosting accuracy from 37% to 80% and HIGH-risk action recall from
20% to 76%. Despite these improvements, the performance still falls short of
the reliability required for high-stakes deployment, where guardrails must
approach near-perfect accuracy and recall.

</details>


### [152] [Manimator: Transforming Research Papers into Visual Explanations](https://arxiv.org/abs/2507.14306)
*Samarth P,Vyoman Jain,Shiva Golugula,Motamarri Sai Sathvik*

Main category: cs.AI

TL;DR: Manimator是一个开源系统，利用大型语言模型将研究论文和自然语言提示转换为解释性动画，提升复杂STEM概念的理解。


<details>
  <summary>Details</summary>
Motivation: 解决学习者理解复杂科学和数学概念的困难，同时降低动态可视化制作的难度。

Method: 通过LLM解析输入文本或PDF，生成结构化场景描述，再转换为可执行的Manim Python代码。

Result: 能够快速生成高质量的教育动画，简化复杂STEM主题的视觉解释。

Conclusion: Manimator有潜力成为教育工具，促进高质量教育内容的民主化。

Abstract: Understanding complex scientific and mathematical concepts, particularly
those presented in dense research papers, poses a significant challenge for
learners. Dynamic visualizations can greatly enhance comprehension, but
creating them manually is time-consuming and requires specialized knowledge and
skills. We introduce manimator, an open-source system that leverages Large
Language Models to transform research papers and natural language prompts into
explanatory animations using the Manim engine. Manimator employs a pipeline
where an LLM interprets the input text or research paper PDF to generate a
structured scene description outlining key concepts, mathematical formulas, and
visual elements and another LLM translates this description into executable
Manim Python code. We discuss its potential as an educational tool for rapidly
creating engaging visual explanations for complex STEM topics, democratizing
the creation of high-quality educational content.

</details>


### [153] [Language Models as Ontology Encoders](https://arxiv.org/abs/2507.14334)
*Hui Yang,Jiaoyan Chen,Yuan He,Yongsheng Gao,Ian Horrocks*

Main category: cs.AI

TL;DR: OnT是一种新的本体嵌入方法，通过结合预训练语言模型和双曲几何建模，有效整合文本信息并保留逻辑结构，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有本体嵌入方法在结合文本信息或保留逻辑结构方面存在不足，需要一种更有效的方法。

Method: 提出OnT方法，通过双曲几何建模调整预训练语言模型，整合文本标签并保留EL描述逻辑的层次结构和逻辑关系。

Result: 在四个真实本体上的实验表明，OnT在预测和推理任务中均优于基线方法，并展示了强大的迁移学习能力。

Conclusion: OnT是一种高效的本体嵌入方法，适用于实际应用，如从SNOMED CT构建新本体。

Abstract: OWL (Web Ontology Language) ontologies which are able to formally represent
complex knowledge and support semantic reasoning have been widely adopted
across various domains such as healthcare and bioinformatics. Recently,
ontology embeddings have gained wide attention due to its potential to infer
plausible new knowledge and approximate complex reasoning. However, existing
methods face notable limitations: geometric model-based embeddings typically
overlook valuable textual information, resulting in suboptimal performance,
while the approaches that incorporate text, which are often based on language
models, fail to preserve the logical structure. In this work, we propose a new
ontology embedding method OnT, which tunes a Pretrained Language Model (PLM)
via geometric modeling in a hyperbolic space for effectively incorporating
textual labels and simultaneously preserving class hierarchies and other
logical relationships of Description Logic EL. Extensive experiments on four
real-world ontologies show that OnT consistently outperforms the baselines
including the state-of-the-art across both tasks of prediction and inference of
axioms. OnT also demonstrates strong potential in real-world applications,
indicated by its robust transfer learning abilities and effectiveness in real
cases of constructing a new ontology from SNOMED CT. Data and code are
available at https://github.com/HuiYang1997/OnT.

</details>


### [154] [ProofCompass: Enhancing Specialized Provers with LLM Guidance](https://arxiv.org/abs/2507.14335)
*Nicolas Wischermann,Claudio Mayrink Verdun,Gabriel Poesia,Francesco Noseda*

Main category: cs.AI

TL;DR: ProofCompass是一种混合方法，结合大型语言模型（LLM）和专用证明器，显著提高了计算效率和准确性，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大型通用模型或小型专用模型，各有局限性，且训练大型专用模型计算成本高。

Method: ProofCompass通过LLM提供自然语言证明策略并分析失败尝试，指导专用证明器（如DSP-v1.5），实现问题分解。

Result: 在miniF2F基准测试中，ProofCompass以25倍更少的尝试次数（128 vs 3200）将准确率从54.9%提升至55.3%。

Conclusion: ProofCompass展示了在形式定理证明中同时提高计算效率和准确性的潜力。

Abstract: Language models have become increasingly powerful tools for formal
mathematical reasoning. However, most existing approaches rely exclusively on
either large general-purpose models or smaller specialized models, each with
distinct limitations, while training specialized large models still requires
significant computational resources. This paper introduces ProofCompass, a
novel hybrid methodology that achieves remarkable computational efficiency by
strategically guiding existing specialized prover methods, such as
DeepSeek-Prover-v1.5-RL (DSP-v1.5) with a Large Language Model (LLM) without
requiring additional model training. The LLM provides natural language proof
strategies and analyzes failed attempts to select intermediate lemmas, enabling
effective problem decomposition. On the miniF2F benchmark, ProofCompass
demonstrates substantial resource efficiency: it outperforms DSP-v1.5 ($54.9\%
\rightarrow 55.3\%$) while using 25x fewer attempts ($3200 \rightarrow 128$).
Our synergistic approach paves the way for simultaneously improving
computational efficiency and accuracy in formal theorem proving.

</details>


### [155] [Adaptive Multi-Agent Reasoning via Automated Workflow Generation](https://arxiv.org/abs/2507.14393)
*Humza Sami,Mubashir ul Islam,Pierre-Emmanuel Gaillardon,Valerio Tenace*

Main category: cs.AI

TL;DR: Nexus Architect是一种多代理系统框架，通过自动化工作流合成和提示优化，显著提升了推理模型的泛化能力和性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型（LRMs）在泛化能力上存在局限，容易过拟合，无法有效解决新问题。

Method: 引入Nexus Architect，结合自动化工作流合成和迭代提示优化机制，生成定制化推理流程。

Result: 在逻辑问题数据集上，Nexus Architect性能显著优于现有LRMs，最高提升66%通过率。

Conclusion: Nexus Architect通过优化工作流和提示，有效解决了LRMs的泛化问题，性能显著提升。

Abstract: The rise of Large Reasoning Models (LRMs) promises a significant leap forward
in language model capabilities, aiming to tackle increasingly sophisticated
tasks with unprecedented efficiency and accuracy. However, despite their
impressive performance, recent studies have highlighted how current reasoning
models frequently fail to generalize to novel, unseen problems, often resorting
to memorized solutions rather than genuine inferential reasoning. Such behavior
underscores a critical limitation in modern LRMs, i.e., their tendency toward
overfitting, which in turn results in poor generalization in problem-solving
capabilities.
  In this paper, we introduce Nexus Architect, an enhanced iteration of our
multi-agent system framework, Nexus, equipped with a novel automated workflow
synthesis mechanism. Given a user's prompt and a small set of representative
examples, the Architect autonomously generates a tailored reasoning workflow by
selecting suitable strategies, tool integrations, and adversarial techniques
for a specific problem class. Furthermore, the Architect includes an iterative
prompt refinement mechanism that fine-tunes agents' system prompts to maximize
performance and improve the generalization capabilities of the system.
  We empirically evaluate Nexus Architect by employing an off-the-shelf,
non-reasoning model on a custom dataset of challenging logical questions and
compare its performance against state-of-the-art LRMs. Results show that Nexus
Architect consistently outperforms existing solutions, achieving up to a 66%
increase in pass rate over Gemini 2.5 Flash Preview, nearly 2.5$\times$ against
Claude Sonnet 4 and DeepSeek-R1, and over 3$\times$ w.r.t. Llama 4 Scout.

</details>


### [156] [Fail Fast, or Ask: Mitigating the Deficiencies of Reasoning LLMs with Human-in-the-Loop Systems Engineering](https://arxiv.org/abs/2507.14406)
*Michael J. Zellinger,Matt Thomson*

Main category: cs.AI

TL;DR: 论文提出了一种结合推理模型与人类专家的协作系统，通过量化模型的不确定性来降低错误率，并探索了非推理模型前置以减少延迟和成本的方法。


<details>
  <summary>Details</summary>
Motivation: 当前推理模型虽强大但仍存在错误，而高风险领域需要接近0%的错误率。通过人类专家协作和系统优化，可以弥补这一差距。

Method: 1. 通过推理轨迹长度量化模型不确定性，用于决定是否转交人类专家。2. 前置非推理模型（Fail Fast, or Ask系统）以减少延迟和成本。

Result: 1. 错误率从3%降至1%以下（转交7.5%查询）。2. 延迟减少40%，成本节省50%，同时保持90%以上的准确率。3. 观察到延迟拖累现象。

Conclusion: 通过黑盒系统工程（如人类协作和非推理模型前置），可以显著缓解推理模型的高错误率和高延迟问题，无需修改模型内部。

Abstract: State-of-the-art reasoning LLMs are powerful problem solvers, but they still
occasionally make mistakes. However, adopting AI models in risk-sensitive
domains often requires error rates near 0%. To address this gap, we propose
collaboration between a reasoning model and a human expert who resolves queries
the model cannot confidently answer. We find that quantifying the uncertainty
of a reasoning model through the length of its reasoning trace yields an
effective basis for deferral to a human, e.g., cutting the error rate of Qwen3
235B-A22B on difficult MATH problems from 3% to less than 1% when deferring
7.5% of queries. However, the high latency of reasoning models still makes them
challenging to deploy on use cases with high query volume. To address this
challenge, we explore fronting a reasoning model with a large non-reasoning
model. We call this modified human-in-the-loop system "Fail Fast, or Ask",
since the non-reasoning model may defer difficult queries to the human expert
directly ("failing fast"), without incurring the reasoning model's higher
latency. We show that this approach yields around 40% latency reduction and
about 50% cost savings for DeepSeek R1 while maintaining 90+% area under the
accuracy-rejection curve. However, we observe that latency savings are lower
than expected because of "latency drag", the phenomenon that processing easier
queries with a non-reasoning model pushes the reasoning model's latency
distribution towards longer latencies. Broadly, our results suggest that the
deficiencies of state-of-the-art reasoning models -- nontrivial error rates and
high latency -- can be substantially mitigated through black-box systems
engineering, without requiring access to LLM internals.

</details>


### [157] [Inverse Scaling in Test-Time Compute](https://arxiv.org/abs/2507.14417)
*Aryo Pradipta Gema,Alexander Hägele,Runjin Chen,Andy Arditi,Jacob Goldman-Wetzler,Kit Fraser-Taliente,Henry Sleight,Linda Petrini,Julian Michael,Beatrice Alex,Pasquale Minervini,Yanda Chen,Joe Benton,Ethan Perez*

Main category: cs.AI

TL;DR: 研究发现，增加大型推理模型（LRMs）的推理长度会降低性能，揭示了测试计算量与准确性之间的反比关系。


<details>
  <summary>Details</summary>
Motivation: 探索测试计算量扩展对模型推理能力的影响，识别潜在的失败模式。

Method: 构建四类评估任务（计数、回归、演绎、AI风险），分析不同模型在延长推理时的表现。

Result: 识别出五种失败模式，包括分心、过拟合、虚假关联、注意力分散和行为放大。

Conclusion: 测试计算量扩展虽能提升能力，但可能强化问题推理模式，需多样化评估推理长度。

Abstract: We construct evaluation tasks where extending the reasoning length of Large
Reasoning Models (LRMs) deteriorates performance, exhibiting an inverse scaling
relationship between test-time compute and accuracy. Our evaluation tasks span
four categories: simple counting tasks with distractors, regression tasks with
spurious features, deduction tasks with constraint tracking, and advanced AI
risks. We identify five distinct failure modes when models reason for longer:
1) Claude models become increasingly distracted by irrelevant information; 2)
OpenAI o-series models resist distractors but overfit to problem framings; 3)
models shift from reasonable priors to spurious correlations; 4) all models
show difficulties in maintaining focus on complex deductive tasks; and 5)
extended reasoning may amplify concerning behaviors, with Claude Sonnet 4
showing increased expressions of self-preservation. These findings suggest that
while test-time compute scaling remains promising for improving model
capabilities, it may inadvertently reinforce problematic reasoning patterns.
Our results demonstrate the importance of evaluating models across diverse
reasoning lengths to identify and address these failure modes in LRMs.

</details>


### [158] [Routine: A Structural Planning Framework for LLM Agent System in Enterprise](https://arxiv.org/abs/2507.14447)
*Guancheng Zeng,Xueyi Chen,Jiawang Hu,Shaohua Qi,Yaxuan Mao,Zhantao Wang,Yifan Nie,Shuang Li,Qiuyang Feng,Pengxu Qiu,Yujia Wang,Wenqiang Han,Linyan Huang,Gang Li,Jingjing Mo,Haowen Hu*

Main category: cs.AI

TL;DR: 论文提出Routine框架，通过结构化规划和参数传递提升多步骤工具调用任务的执行稳定性，显著提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决企业环境中代理系统因缺乏领域知识导致的计划混乱和执行不稳定问题。

Method: 引入Routine框架，包含清晰结构、明确指令和参数传递，并构建训练数据集进行微调。

Result: 在真实企业场景中，Routine显著提升模型执行准确率，如GPT-4o从41.1%升至96.3%。

Conclusion: Routine有效提升代理系统稳定性和适应性，加速企业环境中AI代理的部署。

Abstract: The deployment of agent systems in an enterprise environment is often
hindered by several challenges: common models lack domain-specific process
knowledge, leading to disorganized plans, missing key tools, and poor execution
stability. To address this, this paper introduces Routine, a multi-step agent
planning framework designed with a clear structure, explicit instructions, and
seamless parameter passing to guide the agent's execution module in performing
multi-step tool-calling tasks with high stability. In evaluations conducted
within a real-world enterprise scenario, Routine significantly increases the
execution accuracy in model tool calls, increasing the performance of GPT-4o
from 41.1% to 96.3%, and Qwen3-14B from 32.6% to 83.3%. We further constructed
a Routine-following training dataset and fine-tuned Qwen3-14B, resulting in an
accuracy increase to 88.2% on scenario-specific evaluations, indicating
improved adherence to execution plans. In addition, we employed Routine-based
distillation to create a scenario-specific, multi-step tool-calling dataset.
Fine-tuning on this distilled dataset raised the model's accuracy to 95.5%,
approaching GPT-4o's performance. These results highlight Routine's
effectiveness in distilling domain-specific tool-usage patterns and enhancing
model adaptability to new scenarios. Our experimental results demonstrate that
Routine provides a practical and accessible approach to building stable agent
workflows, accelerating the deployment and adoption of agent systems in
enterprise environments, and advancing the technical vision of AI for Process.

</details>


### [159] [BioGraphFusion: Graph Knowledge Embedding for Biological Completion and Reasoning](https://arxiv.org/abs/2507.14468)
*Yitong Lin,Jiaying He,Jiahe Chen,Xinnan Zhu,Jianwei Zheng,Tao Bo*

Main category: cs.AI

TL;DR: BioGraphFusion是一个结合语义与结构学习的框架，通过张量分解和LSTM动态优化关系嵌入，在生物医学知识图谱中表现优异。


<details>
  <summary>Details</summary>
Motivation: 生物医学知识图谱的完成和推理具有挑战性，现有方法在语义理解和结构学习之间缺乏协同进化。

Method: BioGraphFusion通过张量分解建立全局语义基础，利用LSTM动态优化关系嵌入，并结合查询引导的子图构建和混合评分机制。

Result: 在三个关键生物医学任务中，BioGraphFusion表现优于现有方法，并通过案例研究揭示了生物学意义通路。

Conclusion: BioGraphFusion在生物医学知识图谱中实现了语义与结构学习的深度协同，具有重要应用价值。

Abstract: Motivation: Biomedical knowledge graphs (KGs) are crucial for drug discovery
and disease understanding, yet their completion and reasoning are challenging.
Knowledge Embedding (KE) methods capture global semantics but struggle with
dynamic structural integration, while Graph Neural Networks (GNNs) excel
locally but often lack semantic understanding. Even ensemble approaches,
including those leveraging language models, often fail to achieve a deep,
adaptive, and synergistic co-evolution between semantic comprehension and
structural learning. Addressing this critical gap in fostering continuous,
reciprocal refinement between these two aspects in complex biomedical KGs is
paramount.
  Results: We introduce BioGraphFusion, a novel framework for deeply
synergistic semantic and structural learning. BioGraphFusion establishes a
global semantic foundation via tensor decomposition, guiding an LSTM-driven
mechanism to dynamically refine relation embeddings during graph propagation.
This fosters adaptive interplay between semantic understanding and structural
learning, further enhanced by query-guided subgraph construction and a hybrid
scoring mechanism. Experiments across three key biomedical tasks demonstrate
BioGraphFusion's superior performance over state-of-the-art KE, GNN, and
ensemble models. A case study on Cutaneous Malignant Melanoma 1 (CMM1)
highlights its ability to unveil biologically meaningful pathways.
  Availability and Implementation: Source code and all training data are freely
available for download at https://github.com/Y-TARL/BioGraphFusion.
  Contact: zjw@zjut.edu.cn, botao666666@126.com.
  Supplementary information: Supplementary data are available at Bioinformatics
online.

</details>


### [160] [Amico: An Event-Driven Modular Framework for Persistent and Embedded Autonomy](https://arxiv.org/abs/2507.14513)
*Hongyi Yang,Yue Pan,Jiayi Xu,Kelsen Liu*

Main category: cs.AI

TL;DR: Amico是一个模块化、事件驱动的框架，专为嵌入式系统优化的自主代理构建，支持高效运行和跨平台部署。


<details>
  <summary>Details</summary>
Motivation: 现有框架在现实或资源受限环境中表现不佳，依赖云端计算、动态环境下的鲁棒性不足，缺乏持久自主性和环境感知能力。

Method: Amico采用Rust编写，支持通过WebAssembly在嵌入式平台和浏览器环境中高效运行，提供事件处理、状态管理、行为执行和推理模块集成的抽象。

Result: Amico为构建适应有限计算和间歇性连接环境的弹性交互代理提供了统一基础设施。

Conclusion: Amico是一个适用于资源受限环境的自主代理框架，具有高效、跨平台和模块化特点。

Abstract: Recent advances in large language models (LLMs) and autonomous agents have
enabled systems capable of performing complex tasks across domains such as
human-computer interaction, planning, and web navigation. However, many
existing frameworks struggle in real-world or resource-constrained environments
due to their reliance on cloud-based computation, limited robustness in dynamic
contexts, and lack of persistent autonomy and environmental awareness.
  We present Amico, a modular, event-driven framework for building autonomous
agents optimized for embedded systems. Written in Rust for safety and
performance, Amico supports reactive, persistent agents that operate
efficiently across embedded platforms and browser environments via WebAssembly.
It provides clean abstractions for event handling, state management, behavior
execution, and integration with reasoning modules. Amico delivers a unified
infrastructure for constructing resilient, interactive agents suitable for
deployment in settings with limited compute and intermittent connectivity.

</details>


### [161] [What if Othello-Playing Language Models Could See?](https://arxiv.org/abs/2507.14520)
*Xinyi Chen,Yifei Yuan,Jiaang Li,Serge Belongie,Maarten de Rijke,Anders Søgaard*

Main category: cs.AI

TL;DR: 多模态训练（结合文本和视觉输入）在Othello游戏中提升了模型性能和内部表示的鲁棒性，表明视觉输入有助于语言模型推断结构化世界表示。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型是否仅通过文本就能理解世界，还是需要多模态（如视觉）输入更高效。

Method: 引入VISOTHELLO模型，结合移动历史和棋盘图像进行多模态训练，并通过下一步移动预测与单模态基线对比。

Result: 多模态训练提升了模型性能和内部表示的鲁棒性。

Conclusion: 视觉输入有助于语言模型推断结构化世界表示，支持多模态学习的优势。

Abstract: Language models are often said to face a symbol grounding problem. While some
argue that world understanding can emerge from text alone, others suggest
grounded learning is more efficient. We explore this through Othello, where the
board state defines a simplified, rule-based world. Building on prior work, we
introduce VISOTHELLO, a multi-modal model trained on move histories and board
images. Using next-move prediction, we compare it to mono-modal baselines and
test robustness to semantically irrelevant perturbations. We find that
multi-modal training improves both performance and the robustness of internal
representations. These results suggest that grounding language in visual input
helps models infer structured world representations.

</details>


### [162] [Large Language Models Assisting Ontology Evaluation](https://arxiv.org/abs/2507.14552)
*Anna Sofia Lippolis,Mohammad Javad Saeedizade,Robin Keskisärkkä,Aldo Gangemi,Eva Blomqvist,Andrea Giovanni Nuzzolese*

Main category: cs.AI

TL;DR: 论文介绍了OE-Assist框架，利用大型语言模型（LLM）自动化或半自动化验证能力问题（CQ），以降低本体评估的成本和复杂性。


<details>
  <summary>Details</summary>
Motivation: 本体评估通常依赖人工验证能力问题（CQ），这一过程耗时、费力且易出错，亟需自动化解决方案。

Method: 提出OE-Assist框架，利用LLM自动或半自动验证CQ，并基于1,393个CQ及其对应本体和故事的数据集进行实验。

Result: 实验表明，基于LLM的自动化评估（o1-preview和o3-mini）性能接近普通用户的平均水平。

Conclusion: LLM辅助的本体评估具有潜力，可显著降低评估成本并提高效率。

Abstract: Ontology evaluation through functional requirements, such as testing via
competency question (CQ) verification, is a well-established yet costly,
labour-intensive, and error-prone endeavour, even for ontology engineering
experts. In this work, we introduce OE-Assist, a novel framework designed to
assist ontology evaluation through automated and semi-automated CQ
verification. By presenting and leveraging a dataset of 1,393 CQs paired with
corresponding ontologies and ontology stories, our contributions present, to
our knowledge, the first systematic investigation into large language model
(LLM)-assisted ontology evaluation, and include: (i) evaluating the
effectiveness of a LLM-based approach for automatically performing CQ
verification against a manually created gold standard, and (ii) developing and
assessing an LLM-powered framework to assist CQ verification with Prot\'eg\'e,
by providing suggestions. We found that automated LLM-based evaluation with
o1-preview and o3-mini perform at a similar level to the average user's
performance.

</details>


### [163] [Coordinate Heart System: A Geometric Framework for Emotion Representation](https://arxiv.org/abs/2507.14593)
*Omar Al-Desi*

Main category: cs.AI

TL;DR: 论文提出Coordinate Heart System (CHS)，一种用于AI情感表示的几何框架，通过八种核心情感坐标实现复杂情感状态的计算。


<details>
  <summary>Details</summary>
Motivation: 传统五情感模型存在覆盖不足问题，需开发更完整的几何表示系统。

Method: 将八种情感定位为单位圆上的坐标，支持坐标混合、向量运算及实时情感插值，引入稳定性参数S。

Result: 八情感系统消除了表示盲点，实验验证了其在复杂心理场景中的优越性。

Conclusion: CHS为AI情感建模提供了新的数学基础。

Abstract: This paper presents the Coordinate Heart System (CHS), a geometric framework
for emotion representation in artificial intelligence applications. We position
eight core emotions as coordinates on a unit circle, enabling mathematical
computation of complex emotional states through coordinate mixing and vector
operations. Our initial five-emotion model revealed significant coverage gaps
in the emotion space, leading to the development of an eight-emotion system
that provides complete geometric coverage with mathematical guarantees. The
framework converts natural language input to emotion coordinates and supports
real-time emotion interpolation through computational algorithms. The system
introduces a re-calibrated stability parameter S in [0,1], which dynamically
integrates emotional load, conflict resolution, and contextual drain factors.
This stability model leverages advanced Large Language Model interpretation of
textual cues and incorporates hybrid temporal tracking mechanisms to provide
nuanced assessment of psychological well-being states. Our key contributions
include: (i) mathematical proof demonstrating why five emotions are
insufficient for complete geometric coverage, (ii) an eight-coordinate system
that eliminates representational blind spots, (iii) novel algorithms for
emotion mixing, conflict resolution, and distance calculation in emotion space,
and (iv) a comprehensive computational framework for AI emotion recognition
with enhanced multi-dimensional stability modeling. Experimental validation
through case studies demonstrates the system's capability to handle emotionally
conflicted states, contextual distress factors, and complex psychological
scenarios that traditional categorical emotion models cannot adequately
represent. This work establishes a new mathematical foundation for emotion
modeling in artificial intelligence systems.

</details>


### [164] [Efficient Story Point Estimation With Comparative Learning](https://arxiv.org/abs/2507.14642)
*Monoshiz Mahbub Khan,Xioayin Xi,Andrew Meneely,Zhe Yu*

Main category: cs.AI

TL;DR: 论文提出了一种基于比较学习的框架，用于校准项目特定的故事点预测模型，以减少敏捷开发中的估算负担。


<details>
  <summary>Details</summary>
Motivation: 传统的故事点估算方法（如规划扑克）在团队达成共识后变得繁琐且耗时，机器学习可以减轻负担，但现有模型需要同一项目的历史数据。

Method: 通过让开发者比较待办事项对的努力程度，训练机器学习模型预测故事点估算，而非直接分配具体值。

Result: 在16个项目、23,313条手动估算数据上，模型预测与真实故事点的Spearman等级相关系数平均为0.34，性能与回归模型相当或更好。

Conclusion: 比较学习方法比回归方法更高效，符合比较判断法则，降低了人类的认知负担。

Abstract: Story point estimation is an essential part of agile software development.
Story points are unitless, project-specific effort estimates that help
developers plan their sprints. Traditionally, developers estimate story points
collaboratively using planning poker or other manual techniques. While the
initial calibrating of the estimates to each project is helpful, once a team
has converged on a set of precedents, story point estimation can become tedious
and labor-intensive. Machine learning can reduce this burden, but only with
enough context from the historical decisions made by the project team. That is,
state-of-the-art models, such as GPT2SP and FastText-SVM, only make accurate
predictions (within-project) when trained on data from the same project. The
goal of this work is to streamline story point estimation by evaluating a
comparative learning-based framework for calibrating project-specific story
point prediction models. Instead of assigning a specific story point value to
every backlog item, developers are presented with pairs of items, and indicate
which item requires more effort. Using these comparative judgments, a machine
learning model is trained to predict the story point estimates. We empirically
evaluated our technique using data with 23,313 manual estimates in 16 projects.
The model learned from comparative judgments can achieve on average 0.34
Spearman's rank correlation coefficient between its predictions and the ground
truth story points. This is similar to, if not better than, the performance of
a regression model learned from the ground truth story points. Therefore, the
proposed comparative learning approach is more efficient than state-of-the-art
regression-based approaches according to the law of comparative judgments -
providing comparative judgments yields a lower cognitive burden on humans than
providing ratings or categorical labels.

</details>


### [165] [When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems](https://arxiv.org/abs/2507.14660)
*Qibing Ren,Sitao Xie,Longxuan Wei,Zhenfei Yin,Junchi Yan,Lizhuang Ma,Jing Shao*

Main category: cs.AI

TL;DR: 论文探讨了多智能体系统（MAS）在恶意合谋中的风险，提出了一种模拟框架，并发现去中心化系统比中心化系统更具破坏性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统的自主性增强，多智能体系统可能带来类似人类群体的危害，但目前研究较少。

Method: 提出了一种支持中心和去中心化结构的框架，模拟恶意MAS合谋，应用于虚假信息传播和电商欺诈。

Result: 去中心化系统更高效且能适应策略，传统干预措施难以检测。

Conclusion: 需改进检测系统和反制措施以应对恶意MAS合谋。

Abstract: Recent large-scale events like election fraud and financial scams have shown
how harmful coordinated efforts by human groups can be. With the rise of
autonomous AI systems, there is growing concern that AI-driven groups could
also cause similar harm. While most AI safety research focuses on individual AI
systems, the risks posed by multi-agent systems (MAS) in complex real-world
situations are still underexplored. In this paper, we introduce a
proof-of-concept to simulate the risks of malicious MAS collusion, using a
flexible framework that supports both centralized and decentralized
coordination structures. We apply this framework to two high-risk fields:
misinformation spread and e-commerce fraud. Our findings show that
decentralized systems are more effective at carrying out malicious actions than
centralized ones. The increased autonomy of decentralized systems allows them
to adapt their strategies and cause more damage. Even when traditional
interventions, like content flagging, are applied, decentralized groups can
adjust their tactics to avoid detection. We present key insights into how these
malicious groups operate and the need for better detection systems and
countermeasures. Code is available at https://github.com/renqibing/RogueAgent.

</details>


### [166] [Configurable multi-agent framework for scalable and realistic testing of llm-based agents](https://arxiv.org/abs/2507.14705)
*Sai Wang,Senthilnathan Subramanian,Mudit Sahni,Praneeth Gone,Lingjie Meng,Xiaochen Wang,Nicolas Ferradas Bertoli,Tingxian Cheng,Jun Xu*

Main category: cs.AI

TL;DR: Neo是一个可配置的多代理框架，用于自动化评估基于LLM的系统，通过动态生成多样化的测试输入，显著提高了测试效率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 静态基准和手动测试无法满足LLM代理的复杂行为评估需求，需要一种自动化、动态的测试方法。

Method: Neo结合问题生成代理和评估代理，通过共享上下文中心动态生成测试输入，模拟多样化的人类对话。

Result: 在测试中，Neo发现了边缘案例故障，效率比人工测试高10-12倍，且覆盖范围更广。

Conclusion: Neo为可扩展、自进化的LLM质量评估奠定了基础，其框架具有模型无关性和可扩展性。

Abstract: Large-language-model (LLM) agents exhibit complex, context-sensitive
behaviour that quickly renders static benchmarks and ad-hoc manual testing
obsolete.
  We present Neo, a configurable, multi-agent framework that automates
realistic, multi-turn evaluation of LLM-based systems. Neo couples a Question
Generation Agent and an Evaluation Agent through a shared context-hub, allowing
domain prompts, scenario controls and dynamic feedback to be composed
modularly. Test inputs are sampled from a probabilistic state model spanning
dialogue flow, user intent and emotional tone, enabling diverse, human-like
conversations that adapt after every turn.
  Applied to a production-grade Seller Financial Assistant chatbot, Neo (i)
uncovered edge-case failures across five attack categories with a 3.3% break
rate close to the 5.8% achieved by expert human red-teamers, and (ii) delivered
10-12X higher throughput, generating 180 coherent test questions in around 45
mins versus 16h of human effort. Beyond security probing, Neo's stochastic
policies balanced topic coverage and conversational depth, yielding broader
behavioural exploration than manually crafted scripts.
  Neo therefore lays a foundation for scalable, self-evolving LLM QA: its agent
interfaces, state controller and feedback loops are model-agnostic and
extensible to richer factual-grounding and policy-compliance checks. We release
the framework to facilitate reproducible, high-fidelity testing of emerging
agentic systems.

</details>


### [167] [Automated Safety Evaluations Across 20 Large Language Models: The Aymara LLM Risk and Responsibility Matrix](https://arxiv.org/abs/2507.14719)
*Juan Manuel Contreras*

Main category: cs.AI

TL;DR: Aymara AI是一个用于生成和管理定制化、基于政策的安全评估的平台，通过将自然语言安全政策转化为对抗性提示，并使用AI评分器评估模型响应。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）在现实应用中的普及，亟需可扩展且严格的安全性评估工具。

Method: Aymara AI将自然语言安全政策转化为对抗性提示，并使用基于AI的评分器（经人类判断验证）评估模型响应。

Result: 评估了20个商业LLM在10个安全领域的表现，结果显示性能差异显著，平均安全分数从86.2%到52.4%不等。复杂领域（如隐私与冒充）表现较差（平均24.3%）。

Conclusion: LLM的安全性表现不一致且依赖上下文，需要可扩展的定制化工具（如Aymara AI）来支持负责任的AI开发和监管。

Abstract: As large language models (LLMs) become increasingly integrated into
real-world applications, scalable and rigorous safety evaluation is essential.
This paper introduces Aymara AI, a programmatic platform for generating and
administering customized, policy-grounded safety evaluations. Aymara AI
transforms natural-language safety policies into adversarial prompts and scores
model responses using an AI-based rater validated against human judgments. We
demonstrate its capabilities through the Aymara LLM Risk and Responsibility
Matrix, which evaluates 20 commercially available LLMs across 10 real-world
safety domains. Results reveal wide performance disparities, with mean safety
scores ranging from 86.2% to 52.4%. While models performed well in
well-established safety domains such as Misinformation (mean = 95.7%), they
consistently failed in more complex or underspecified domains, notably Privacy
& Impersonation (mean = 24.3%). Analyses of Variance confirmed that safety
scores differed significantly across both models and domains (p < .05). These
findings underscore the inconsistent and context-dependent nature of LLM safety
and highlight the need for scalable, customizable tools like Aymara AI to
support responsible AI development and oversight.

</details>


### [168] [Towards AI Urban Planner in the Age of GenAI, LLMs, and Agentic AI](https://arxiv.org/abs/2507.14730)
*Yanjie Fu*

Main category: cs.AI

TL;DR: 论文探讨了生成式AI与城市规划的融合，提出将城市规划视为生成任务，并指出当前研究的四大局限及未来方向。


<details>
  <summary>Details</summary>
Motivation: 探索生成式AI（如VAEs、GANs、transformers和扩散模型）如何重塑城市规划，填补现有研究的空白。

Method: 通过文献综述，分析生成式AI在城市规划中的应用，并识别关键研究缺口。

Result: 发现四大研究局限：缺乏理论指导、多尺度分析不足、数据知识增强不足及现实交互研究有限。

Conclusion: 提出未来研究方向，包括理论指导生成、数字孪生和人机协同设计，呼吁生成智能与参与式城市主义的新结合。

Abstract: Generative AI, large language models, and agentic AI have emerged separately
of urban planning. However, the convergence between AI and urban planning
presents an interesting opportunity towards AI urban planners. This paper
conceptualizes urban planning as a generative AI task, where AI synthesizes
land-use configurations under geospatial, social, and human-centric
constraints. We survey how generative AI approaches, including VAEs, GANs,
transformers, and diffusion models, reshape urban design. We further identify
critical gaps: 1) limited research on integrating urban theory guidance, 2)
limited research of AI urban planning over multiple spatial resolutions or
angularities, 3) limited research on augmenting urban design knowledge from
data, and 4) limited research on addressing real-world interactions. To address
these limitations, we outline future research directions in theory-guided
generation, digital twins, and human-machine co-design, calling for a new
synthesis of generative intelligence and participatory urbanism.

</details>


### [169] [AgentFly: Extensible and Scalable Reinforcement Learning for LM Agents](https://arxiv.org/abs/2507.14897)
*Renxi Wang,Rifo Ahmad Genadi,Bilal El Bouardi,Yongxin Wang,Fajri Koto,Zhengzhong Liu,Timothy Baldwin,Haonan Li*

Main category: cs.AI

TL;DR: AgentFly是一个结合语言模型（LM）与强化学习（RL）的可扩展框架，旨在通过多轮交互和工具定义提升LM代理的能力。


<details>
  <summary>Details</summary>
Motivation: 当前LM代理主要通过提示工程或监督微调构建，而RL的应用尚未系统化研究，因此需要一种结合两者的框架。

Method: 开发了AgentFly框架，支持多轮交互、工具定义和异步执行，并采用集中式资源管理系统。

Result: 框架通过预构建工具和环境成功训练了多个任务的代理，验证了其有效性。

Conclusion: AgentFly为LM代理与RL的结合提供了系统化的解决方案，具有可扩展性和易用性。

Abstract: Language model (LM) agents have gained significant attention for their
ability to autonomously complete tasks through interactions with environments,
tools, and APIs. LM agents are primarily built with prompt engineering or
supervised finetuning. At the same time, reinforcement learning (RL) has been
explored to enhance LM's capabilities, such as reasoning and factuality.
However, the combination of the LM agents and reinforcement learning (Agent-RL)
remains underexplored and lacks systematic study. To this end, we built
AgentFly, a scalable and extensible Agent-RL framework designed to empower LM
agents with a variety of RL algorithms. Our framework supports multi-turn
interactions by adapting traditional RL methods with token-level masking. It
features a decorator-based interface for defining tools and reward functions,
enabling seamless extension and ease of use. To support high-throughput
training, we implement asynchronous execution of tool calls and reward
computations, and design a centralized resource management system for scalable
environment coordination. We also provide a suite of prebuilt tools and
environments, demonstrating the framework's effectiveness through successful
agent training across multiple tasks.

</details>


### [170] [InsightX Agent: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis](https://arxiv.org/abs/2507.14899)
*Jiale Liu,Huan Wang,Yue Zhang,Xiaoyu Luo,Jiaxiang Hu,Zhiliang Liu,Min Xie*

Main category: cs.AI

TL;DR: 论文提出InsightX Agent，一种基于LMM的框架，用于提升X射线无损检测的可靠性、可解释性和交互性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在X射线检测中缺乏交互性、可解释性和自我评估能力，限制了其可靠性和操作员信任。

Method: InsightX Agent以LMM为核心，协调SDMSD和EGR工具。SDMSD生成多尺度缺陷区域提议并通过NMS优化，EGR通过链式思维验证和优化提议。

Result: 在GDXray+数据集上，InsightX Agent达到96.35%的F1分数，显著提升了解释性和可信度。

Conclusion: InsightX Agent展示了基于LMM的代理框架在工业检测任务中的变革潜力。

Abstract: Non-destructive testing (NDT), particularly X-ray inspection, is vital for
industrial quality assurance, yet existing deep-learning-based approaches often
lack interactivity, interpretability, and the capacity for critical
self-assessment, limiting their reliability and operator trust. To address
these shortcomings, this paper proposes InsightX Agent, a novel LMM-based
agentic framework designed to deliver reliable, interpretable, and interactive
X-ray NDT analysis. Unlike typical sequential pipelines, InsightX Agent
positions a Large Multimodal Model (LMM) as a central orchestrator,
coordinating between the Sparse Deformable Multi-Scale Detector (SDMSD) and the
Evidence-Grounded Reflection (EGR) tool. The SDMSD generates dense defect
region proposals for multi-scale feature maps and sparsifies them through
Non-Maximum Suppression (NMS), optimizing detection of small, dense targets in
X-ray images while maintaining computational efficiency. The EGR tool guides
the LMM agent through a chain-of-thought-inspired review process, incorporating
context assessment, individual defect analysis, false positive elimination,
confidence recalibration and quality assurance to validate and refine the
SDMSD's initial proposals. By strategically employing and intelligently using
tools, InsightX Agent moves beyond passive data processing to active reasoning,
enhancing diagnostic reliability and providing interpretations that integrate
diverse information sources. Experimental evaluations on the GDXray+ dataset
demonstrate that InsightX Agent not only achieves a high object detection
F1-score of 96.35% but also offers significantly improved interpretability and
trustworthiness in its analyses, highlighting the transformative potential of
agentic LLM frameworks for industrial inspection tasks.

</details>


### [171] [Feedback-Induced Performance Decline in LLM-Based Decision-Making](https://arxiv.org/abs/2507.14906)
*Xiao Yang,Juxi Leitner,Michael Burke*

Main category: cs.AI

TL;DR: 研究探讨了大型语言模型（LLMs）在马尔可夫决策过程中的表现，发现其在简单环境中表现优于传统强化学习方法，但在复杂场景中需进一步优化。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在自主决策中的适用性，尤其是其通过预训练知识快速适应的潜力。

Method: 采用在线结构化提示策略，比较LLM与传统强化学习在序列决策任务中的零样本性能。

Result: LLMs在简单环境中初始表现更优，但在复杂环境中规划与推理能力不足；反馈机制可能降低性能。

Conclusion: 需进一步研究混合策略、微调及高级记忆整合以提升LLM的决策能力。

Abstract: The ability of Large Language Models (LLMs) to extract context from natural
language problem descriptions naturally raises questions about their
suitability in autonomous decision-making settings. This paper studies the
behaviour of these models within a Markov Decision Process (MDPs). While
traditional reinforcement learning (RL) strategies commonly employed in this
setting rely on iterative exploration, LLMs, pre-trained on diverse datasets,
offer the capability to leverage prior knowledge for faster adaptation. We
investigate online structured prompting strategies in sequential decision
making tasks, comparing the zero-shot performance of LLM-based approaches to
that of classical RL methods. Our findings reveal that although LLMs
demonstrate improved initial performance in simpler environments, they struggle
with planning and reasoning in complex scenarios without fine-tuning or
additional guidance. Our results show that feedback mechanisms, intended to
improve decision-making, often introduce confusion, leading to diminished
performance in intricate environments. These insights underscore the need for
further exploration into hybrid strategies, fine-tuning, and advanced memory
integration to enhance LLM-based decision-making capabilities.

</details>


### [172] [The Endless Tuning. An Artificial Intelligence Design To Avoid Human Replacement and Trace Back Responsibilities](https://arxiv.org/abs/2507.14909)
*Elio Grande*

Main category: cs.AI

TL;DR: 《Endless Tuning》是一种基于双重镜像过程的人工智能可靠部署设计方法，旨在避免人类被替代并填补责任缺口。通过三个原型应用测试，该方法在用户体验和问责制方面取得了积极成果。


<details>
  <summary>Details</summary>
Motivation: 解决人工智能部署中的人类替代问题和责任缺口问题，推动伦理与技术结合。

Method: 采用双重镜像过程，开发协议并在贷款审批、肺炎诊断和艺术风格识别三个领域进行原型测试。

Result: 实验显示用户对决策过程有完全控制感，并在问责与责任之间建立了桥梁。

Conclusion: 该方法为人工智能伦理提供了新视角，强调用户体验而非统计准确性，展示了技术与伦理的可行结合。

Abstract: The Endless Tuning is a design method for a reliable deployment of artificial
intelligence based on a double mirroring process, which pursues both the goals
of avoiding human replacement and filling the so-called responsibility gap
(Matthias 2004). Originally depicted in (Fabris et al. 2024) and ensuing the
relational approach urged therein, it was then actualized in a protocol,
implemented in three prototypical applications regarding decision-making
processes (respectively: loan granting, pneumonia diagnosis, and art style
recognition) and tested with such as many domain experts. Step by step
illustrating the protocol, giving insights concretely showing a different voice
(Gilligan 1993) in the ethics of artificial intelligence, a philosophical
account of technical choices (e.g., a reversed and hermeneutic deployment of
XAI algorithms) will be provided in the present study together with the results
of the experiments, focusing on user experience rather than statistical
accuracy. Even thoroughly employing deep learning models, full control was
perceived by the interviewees in the decision-making setting, while it appeared
that a bridge can be built between accountability and liability in case of
damage.

</details>


### [173] [Redefining Elderly Care with Agentic AI: Challenges and Opportunities](https://arxiv.org/abs/2507.14912)
*Ruhul Amin Khalil,Kashif Ahmad,Hazrat Ali*

Main category: cs.AI

TL;DR: 本文探讨了基于大型语言模型的代理人工智能（Agentic AI）在老年护理中的潜力与挑战，强调了其个性化健康追踪、认知护理和环境管理的应用，同时提出数据隐私、决策独立性和伦理问题。


<details>
  <summary>Details</summary>
Motivation: 全球老龄化问题需要创新解决方案，代理AI有望通过自主决策提升老年护理质量，但目前缺乏相关研究。

Method: 分析代理AI在老年护理中的独特能力、应用和限制，结合伦理框架探讨其负责任的使用。

Result: 代理AI在老年护理中具有变革潜力，但需解决隐私、安全和伦理问题，并推动以人为中心的研究。

Conclusion: 代理AI为老年护理带来新机遇，但需平衡技术潜力与伦理挑战，未来研究应关注人本主义整合。

Abstract: The global ageing population necessitates new and emerging strategies for
caring for older adults. In this article, we explore the potential for
transformation in elderly care through Agentic Artificial Intelligence (AI),
powered by Large Language Models (LLMs). We discuss the proactive and
autonomous decision-making facilitated by Agentic AI in elderly care.
Personalized tracking of health, cognitive care, and environmental management,
all aimed at enhancing independence and high-level living for older adults,
represents important areas of application. With a potential for significant
transformation of elderly care, Agentic AI also raises profound concerns about
data privacy and security, decision independence, and access. We share key
insights to emphasize the need for ethical safeguards, privacy protections, and
transparent decision-making. Our goal in this article is to provide a balanced
discussion of both the potential and the challenges associated with Agentic AI,
and to provide insights into its responsible use in elderly care, to bring
Agentic AI into harmony with the requirements and vulnerabilities specific to
the elderly. Finally, we identify the priorities for the academic research
communities, to achieve human-centered advancements and integration of Agentic
AI in elderly care. To the best of our knowledge, this is no existing study
that reviews the role of Agentic AI in elderly care. Hence, we address the
literature gap by analyzing the unique capabilities, applications, and
limitations of LLM-based Agentic AI in elderly care. We also provide a
companion interactive dashboard at https://hazratali.github.io/agenticai/.

</details>


### [174] [Complexity of Faceted Explanations in Propositional Abduction](https://arxiv.org/abs/2507.14962)
*Johannes Schmidt,Mohamed Maizia,Victor Lagerkvist,Johannes K. Fichte*

Main category: cs.AI

TL;DR: 本文探讨了命题溯因中的精细推理方法，引入了“facet”概念以更好地理解解释的异质性，并分析了其在Post框架中的表现。


<details>
  <summary>Details</summary>
Motivation: 命题溯因在人工智能和数据库更新中有广泛应用，但其复杂推理问题（如计数和枚举）计算难度高。本文旨在通过引入facet概念，提供更细粒度的解释分析。

Method: 引入facet（部分解释中出现的文字）和解释间距离的概念，分析其在命题溯因中的表现，并在Post框架中进行了全面分类。

Result: 研究发现facet能更好地捕捉解释的异质性，且在Post框架中几乎完成了完全分类。

Conclusion: 通过facet和距离分析，命题溯因的解释异质性得到更深入理解，为复杂推理问题提供了新视角。

Abstract: Abductive reasoning is a popular non-monotonic paradigm that aims to explain
observed symptoms and manifestations. It has many applications, such as
diagnosis and planning in artificial intelligence and database updates. In
propositional abduction, we focus on specifying knowledge by a propositional
formula. The computational complexity of tasks in propositional abduction has
been systematically characterized - even with detailed classifications for
Boolean fragments. Unsurprisingly, the most insightful reasoning problems
(counting and enumeration) are computationally highly challenging. Therefore,
we consider reasoning between decisions and counting, allowing us to understand
explanations better while maintaining favorable complexity. We introduce facets
to propositional abductions, which are literals that occur in some explanation
(relevant) but not all explanations (dispensable). Reasoning with facets
provides a more fine-grained understanding of variability in explanations
(heterogeneous). In addition, we consider the distance between two
explanations, enabling a better understanding of heterogeneity/homogeneity. We
comprehensively analyze facets of propositional abduction in various settings,
including an almost complete characterization in Post's framework.

</details>


### [175] [AlphaAlign: Incentivizing Safety Alignment with Extremely Simplified Reinforcement Learning](https://arxiv.org/abs/2507.14987)
*Yi Zhang,An Zhang,XiuYu Zhang,Leheng Sheng,Yuxin Chen,Zhenkai Liang,Xiang Wang*

Main category: cs.AI

TL;DR: AlphaAlign是一个基于纯强化学习的框架，通过可验证的安全奖励激发大语言模型的内在安全意识，提升安全推理能力，同时避免过度拒绝和效用下降。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法存在浅层拒绝或依赖密集监督的问题，未能充分利用模型内在的安全意识。

Method: AlphaAlign采用双奖励系统：安全奖励鼓励对有害查询的正确拒绝和明确理由，帮助奖励指导高质量响应。

Result: AlphaAlign在简化流程、打破安全-效用权衡、深化对齐方面表现出色。

Conclusion: AlphaAlign通过强化学习有效提升了模型的安全性和实用性，同时减少了过度拒绝。

Abstract: Large language models (LLMs), despite possessing latent safety understanding
from their vast pretraining data, remain vulnerable to generating harmful
content and exhibit issues such as over-refusal and utility degradation after
safety alignment. Current safety alignment methods often result in superficial
refusal shortcuts or rely on intensive supervision for reasoning-based
approaches, failing to fully leverage the model's intrinsic safety
self-awareness. We propose \textbf{AlphaAlign}, a simple yet effective pure
reinforcement learning (RL) framework with verifiable safety reward designed to
incentivize this latent safety awareness through proactive safety reasoning.}
AlphaAlign employs a dual-reward system: a verifiable safety reward encourages
correctly formatted and explicitly justified refusals for harmful queries while
penalizing over-refusals, and a normalized helpfulness reward guides
high-quality responses to benign inputs. This allows the model to develop
proactive safety reasoning capabilities without depending on supervised
safety-specific reasoning data. AlphaAlign demonstrates three key advantages:
(1) Simplicity and efficiency, requiring only binary prompt safety labels and
minimal RL steps for substantial improvements. (2) Breaking the safety-utility
trade-off, by enhancing refusal of harmful content and reducing over-refusals,
while simultaneously maintaining or even improving general task performance and
robustness to unseen jailbreaks. (3) Deep alignment, fostering proactive safety
reasoning that generates explicit safety rationales rather than relying on
shallow refusal patterns.

</details>


### [176] [A Forced-Choice Neural Cognitive Diagnostic Model of Personality Testing](https://arxiv.org/abs/2507.15013)
*Xiaoyu Li,Jin Wu,Shaoyang Guo,Haoran Shi,Chanjin Zheng*

Main category: cs.AI

TL;DR: 提出了一种基于深度学习的强制选择神经认知诊断模型（FCNCD），用于改进传统模型在强制选择测试中的局限性，并通过实验验证了其准确性、可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在智能时代，心理测量测试在人员选拔、职业发展和心理健康评估中日益重要。强制选择测试因其能降低回答失真风险而常用，但传统模型存在局限性。

Method: 通过非线性映射挖掘参与者和项目特征，利用多层神经网络建模其交互，并结合单调性假设提升诊断结果的可解释性。

Result: 在真实和模拟数据集上的实验验证了FCNCD的准确性、可解释性和鲁棒性。

Conclusion: FCNCD模型有效克服了传统模型的局限性，适用于强制选择测试的三种常见项目块类型。

Abstract: In the smart era, psychometric tests are becoming increasingly important for
personnel selection, career development, and mental health assessment.
Forced-choice tests are common in personality assessments because they require
participants to select from closely related options, lowering the risk of
response distortion. This study presents a deep learning-based Forced-Choice
Neural Cognitive Diagnostic Model (FCNCD) that overcomes the limitations of
traditional models and is applicable to the three most common item block types
found in forced-choice tests. To account for the unidimensionality of items in
forced-choice tests, we create interpretable participant and item parameters.
We model the interactions between participant and item features using
multilayer neural networks after mining them using nonlinear mapping. In
addition, we use the monotonicity assumption to improve the interpretability of
the diagnostic results. The FCNCD's effectiveness is validated by experiments
on real-world and simulated datasets that show its accuracy, interpretability,
and robustness.

</details>


### [177] [DeRAG: Black-box Adversarial Attacks on Multiple Retrieval-Augmented Generation Applications via Prompt Injection](https://arxiv.org/abs/2507.15042)
*Jerry Wang,Fang Yu*

Main category: cs.AI

TL;DR: 本文提出了一种基于差分进化（DE）的方法，优化对抗性提示后缀以攻击RAG系统，实验表明其攻击成功率优于现有方法，且能逃避检测。


<details>
  <summary>Details</summary>
Motivation: 对抗性提示攻击会显著影响RAG系统的可靠性，因此需要一种更有效的方法来优化攻击策略。

Method: 采用差分进化（DE）优化对抗性提示后缀，将RAG视为黑箱，通过进化候选后缀来最大化目标错误文档的检索排名。

Result: 在BEIR QA数据集上的实验显示，DE方法在攻击成功率和隐蔽性上优于GGPP和PRADA，且仅需少量标记（<=5）。

Conclusion: DE方法在对抗性提示攻击中表现出色，同时通过可读性策略和检测规避验证了其实际应用潜力。

Abstract: Adversarial prompt attacks can significantly alter the reliability of
Retrieval-Augmented Generation (RAG) systems by re-ranking them to produce
incorrect outputs. In this paper, we present a novel method that applies
Differential Evolution (DE) to optimize adversarial prompt suffixes for
RAG-based question answering. Our approach is gradient-free, treating the RAG
pipeline as a black box and evolving a population of candidate suffixes to
maximize the retrieval rank of a targeted incorrect document to be closer to
real world scenarios. We conducted experiments on the BEIR QA datasets to
evaluate attack success at certain retrieval rank thresholds under multiple
retrieving applications. Our results demonstrate that DE-based prompt
optimization attains competitive (and in some cases higher) success rates
compared to GGPP to dense retrievers and PRADA to sparse retrievers, while
using only a small number of tokens (<=5 tokens) in the adversarial suffix.
Furthermore, we introduce a readability-aware suffix construction strategy,
validated by a statistically significant reduction in MLM negative
log-likelihood with Welch's t-test. Through evaluations with a BERT-based
adversarial suffix detector, we show that DE-generated suffixes evade
detection, yielding near-chance detection accuracy.

</details>


### [178] [From Kicking to Causality: Simulating Infant Agency Detection with a Robust Intrinsic Reward](https://arxiv.org/abs/2507.15106)
*Xia Xu,Jochen Triesch*

Main category: cs.AI

TL;DR: 论文提出了一种基于因果推理的新型内在奖励机制CAIS，用于增强强化学习代理在噪声环境中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 人类婴儿能够有效发现自身的因果效应，而传统强化学习代理在噪声环境中表现脆弱，依赖相关性奖励容易失败。

Method: 引入Causal Action Influence Score (CAIS)，通过计算动作对感官结果分布的影响（1-Wasserstein距离）来量化因果效应。

Result: 在模拟婴儿-移动环境中，CAIS成功过滤噪声并学习正确策略，而传统方法完全失败。

Conclusion: 显式推断因果性是发展鲁棒代理感的关键机制，为自适应自主系统提供了心理学合理的框架。

Abstract: While human infants robustly discover their own causal efficacy, standard
reinforcement learning agents remain brittle, as their reliance on
correlation-based rewards fails in noisy, ecologically valid scenarios. To
address this, we introduce the Causal Action Influence Score (CAIS), a novel
intrinsic reward rooted in causal inference. CAIS quantifies an action's
influence by measuring the 1-Wasserstein distance between the learned
distribution of sensory outcomes conditional on that action, $p(h|a)$, and the
baseline outcome distribution, $p(h)$. This divergence provides a robust reward
that isolates the agent's causal impact from confounding environmental noise.
We test our approach in a simulated infant-mobile environment where
correlation-based perceptual rewards fail completely when the mobile is
subjected to external forces. In stark contrast, CAIS enables the agent to
filter this noise, identify its influence, and learn the correct policy.
Furthermore, the high-quality predictive model learned for CAIS allows our
agent, when augmented with a surprise signal, to successfully reproduce the
"extinction burst" phenomenon. We conclude that explicitly inferring causality
is a crucial mechanism for developing a robust sense of agency, offering a
psychologically plausible framework for more adaptive autonomous systems.

</details>


### [179] [Automated planning with ontologies under coherence update semantics](https://arxiv.org/abs/2507.15120)
*Stefan Borgwardt,Duy Nhu,Gabriele Röger*

Main category: cs.AI

TL;DR: 提出了一种结合DL-Lite本体和动作条件的新方法，用于自动化规划，复杂度不高于现有方法，并通过多项式编译实现。


<details>
  <summary>Details</summary>
Motivation: 将背景知识（如本体）融入自动化规划问题，以提升规划能力。

Method: 结合显式输入知识（eKABs）和本体感知动作效果，采用一致性更新语义。

Result: 新方法的复杂度与现有方法相当，并通过多项式编译实现高效规划。

Conclusion: 实验验证了新编译方法的性能，展示了在不同基准测试中的表现。

Abstract: Standard automated planning employs first-order formulas under closed-world
semantics to achieve a goal with a given set of actions from an initial state.
We follow a line of research that aims to incorporate background knowledge into
automated planning problems, for example, by means of ontologies, which are
usually interpreted under open-world semantics. We present a new approach for
planning with DL-Lite ontologies that combines the advantages of ontology-based
action conditions provided by explicit-input knowledge and action bases (eKABs)
and ontology-aware action effects under the coherence update semantics. We show
that the complexity of the resulting formalism is not higher than that of
previous approaches and provide an implementation via a polynomial compilation
into classical planning. An evaluation of existing and new benchmarks examines
the performance of a planning system on different variants of our compilation.

</details>


### [180] [Clinical Semantic Intelligence (CSI): Emulating the Cognitive Framework of the Expert Clinician for Comprehensive Oral Disease Diagnosis](https://arxiv.org/abs/2507.15140)
*Mohammad Mashayekhi,Sara Ahmadi Majd,Arian AmirAmjadi,Parsa Hosseini*

Main category: cs.AI

TL;DR: CSI是一种新型AI框架，通过模拟专家临床推理诊断118种口腔疾病，结合多模态CLIP模型和ChatGLM-6B语言模型，采用分层诊断推理树（HDRT）提高诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 口腔疾病诊断复杂且症状重叠，传统模式匹配方法不足以满足临床需求，需模拟专家推理过程以提高诊断准确性。

Method: CSI整合了多模态CLIP模型和ChatGLM-6B语言模型，采用HDRT框架，提供快速筛查和标准交互诊断两种模式。

Result: 在431张内部测试图像上，快速模式准确率为73.4%，标准模式提升至89.5%，验证了HDRT的有效性。

Conclusion: CSI通过模拟专家推理显著提升诊断准确性，为临床提供了实用的辅助工具。

Abstract: The diagnosis of oral diseases presents a problematic clinical challenge,
characterized by a wide spectrum of pathologies with overlapping
symptomatology. To address this, we developed Clinical Semantic Intelligence
(CSI), a novel artificial intelligence framework that diagnoses 118 different
oral diseases by computationally modeling the cognitive processes of an expert
clinician. Our core hypothesis is that moving beyond simple pattern matching to
emulate expert reasoning is critical to building clinically useful diagnostic
aids.
  CSI's architecture integrates a fine-tuned multimodal CLIP model with a
specialized ChatGLM-6B language model. This system executes a Hierarchical
Diagnostic Reasoning Tree (HDRT), a structured framework that distills the
systematic, multi-step logic of differential diagnosis. The framework operates
in two modes: a Fast Mode for rapid screening and a Standard Mode that
leverages the full HDRT for an interactive and in-depth diagnostic workup.
  To train and validate our system, we curated a primary dataset of 4,310
images, supplemented by an external hold-out set of 176 images for final
validation. A clinically-informed augmentation strategy expanded our training
data to over 30,000 image-text pairs. On a 431-image internal test set, CSI's
Fast Mode achieved an accuracy of 73.4%, which increased to 89.5% with the
HDRT-driven Standard Mode. The performance gain is directly attributable to the
hierarchical reasoning process. Herein, we detail the architectural philosophy,
development, and rigorous evaluation of the CSI framework.

</details>


### [181] [Can We Move Freely in NEOM's The Line? An Agent-Based Simulation of Human Mobility in a Futuristic Smart City](https://arxiv.org/abs/2507.15143)
*Abderaouf Bahi,Amel Ourici*

Main category: cs.AI

TL;DR: 研究评估了沙特NEOM线性智能城市The Line中人类移动的可行性，通过混合仿真框架验证了AI支持下的高效移动性。


<details>
  <summary>Details</summary>
Motivation: 探讨在170公里线性城市The Line中，居民能否自由移动，验证新型城市拓扑的可行性。

Method: 结合基于代理的建模、强化学习、监督学习和图神经网络，模拟多模式交通行为。

Result: AI架构下，平均通勤时间7.8-8.4分钟，满意度超89%，可达性超91%；移除智能模块性能显著下降。

Conclusion: The Line中的自由移动在AI系统、可持续设施和实时反馈支持下是可行的。

Abstract: This paper investigates the feasibility of human mobility in The Line, a
proposed 170-kilometer linear smart city in NEOM, Saudi Arabia. To assess
whether citizens can move freely within this unprecedented urban topology, we
develop a hybrid simulation framework that integrates agent-based modeling,
reinforcement learning, supervised learning, and graph neural networks. The
simulation captures multi-modal transportation behaviors across 50 vertical
levels and varying density scenarios using both synthetic data and real-world
traces from high-density cities. Our experiments reveal that with the full
AI-integrated architecture, agents achieved an average commute time of 7.8 to
8.4 minutes, a satisfaction rate exceeding 89 percent, and a reachability index
of over 91 percent, even during peak congestion periods. Ablation studies
confirmed that the removal of intelligent modules such as reinforcement
learning or graph neural networks significantly degrades performance, with
commute times increasing by up to 85 percent and reachability falling below 70
percent. Environmental modeling further demonstrated low energy consumption and
minimal CO2 emissions when electric modes are prioritized. The findings suggest
that freedom of movement is not only conceptually achievable in The Line, but
also operationally realistic if supported by adaptive AI systems, sustainable
infrastructure, and real-time feedback loops.

</details>


### [182] [Solving Formal Math Problems by Decomposition and Iterative Reflection](https://arxiv.org/abs/2507.15225)
*Yichi Zhou,Jianqiu Zhao,Yongxin Zhang,Bohan Wang,Siran Wang,Luoxin Chen,Jiahui Wang,Haowei Chen,Allan Jie,Xinbo Zhang,Haocheng Wang,Luong Trung,Rong Ye,Phan Nhat Hoang,Huishuai Zhang,Peng Sun,Hang Li*

Main category: cs.AI

TL;DR: Delta Prover是一个基于代理的框架，利用通用LLM与Lean 4交互，无需专门化模型即可实现高效定理证明，成功率达95.9%。


<details>
  <summary>Details</summary>
Motivation: 通用LLM在复杂推理任务中表现优异，但在形式化证明（如Lean 4）中仍面临挑战，现有方法需高成本专门化模型。

Method: Delta Prover结合反射分解、迭代证明修复和自定义DSL，通过代理框架协调LLM与Lean 4的交互。

Result: 在miniF2F-test基准测试中达到95.9%成功率，超越现有方法，且测试时扩展性更强。

Conclusion: 通用LLM在有效代理结构引导下具备未开发的定理证明潜力，为形式化环境中的自动推理提供了高效替代方案。

Abstract: General-purpose Large Language Models (LLMs) have achieved remarkable success
in intelligence, performing comparably to human experts on complex reasoning
tasks such as coding and mathematical reasoning. However, generating formal
proofs in specialized languages like Lean 4 remains a significant challenge for
these models, limiting their application in complex theorem proving and
automated verification. Current approaches typically require specializing
models through fine-tuning on dedicated formal corpora, incurring high costs
for data collection and training. In this work, we introduce \textbf{Delta
Prover}, an agent-based framework that orchestrates the interaction between a
general-purpose LLM and the Lean 4 proof environment. Delta Prover leverages
the reflection and reasoning capabilities of general-purpose LLMs to
interactively construct formal proofs in Lean 4, circumventing the need for
model specialization. At its core, the agent integrates two novel,
interdependent components: an algorithmic framework for reflective
decomposition and iterative proof repair, and a custom Domain-Specific Language
(DSL) built upon Lean 4 for streamlined subproblem management. \textbf{Delta
Prover achieves a state-of-the-art 95.9\% success rate on the miniF2F-test
benchmark, surpassing all existing approaches, including those requiring model
specialization.} Furthermore, Delta Prover exhibits a significantly stronger
test-time scaling law compared to standard Best-of-N proof strategies.
Crucially, our findings demonstrate that general-purpose LLMs, when guided by
an effective agentic structure, possess substantial untapped theorem-proving
capabilities. This presents a computationally efficient alternative to
specialized models for robust automated reasoning in formal environments.

</details>


### [183] [Explainable Artificial Intelligence based Soft Evaluation Indicator for Arc Fault Diagnosis](https://arxiv.org/abs/2507.15239)
*Qianchao Wang,Yuxuan Ding,Chuanzhen Jia,Zhe Li,Yaping Du*

Main category: cs.AI

TL;DR: 论文提出了一种软评估指标，结合可解释AI和真实电弧故障实验，解释电弧故障诊断模型的输出，并设计了一个轻量级平衡神经网络以保证准确性和特征提取能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI电弧故障诊断模型虽准确率高，但其可信度存疑，需一种方法来解释和验证模型的输出。

Method: 提出软评估指标，结合可解释AI和真实实验；设计轻量级平衡神经网络。

Result: 在多个数据集上测试，验证了软评估指标的有效性，模型更易理解和信任。

Conclusion: 该方法提升了电弧故障诊断模型的可解释性和可信度，有助于实际决策。

Abstract: Novel AI-based arc fault diagnosis models have demonstrated outstanding
performance in terms of classification accuracy. However, an inherent problem
is whether these models can actually be trusted to find arc faults. In this
light, this work proposes a soft evaluation indicator that explains the outputs
of arc fault diagnosis models, by defining the the correct explanation of arc
faults and leveraging Explainable Artificial Intelligence and real arc fault
experiments. Meanwhile, a lightweight balanced neural network is proposed to
guarantee competitive accuracy and soft feature extraction score. In our
experiments, several traditional machine learning methods and deep learning
methods across two arc fault datasets with different sample times and noise
levels are utilized to test the effectiveness of the soft evaluation indicator.
Through this approach, the arc fault diagnosis models are easy to understand
and trust, allowing practitioners to make informed and trustworthy decisions.

</details>


### [184] [Disentangling Homophily and Heterophily in Multimodal Graph Clustering](https://arxiv.org/abs/2507.15253)
*Zhaochen Guo,Zhixiang Shen,Xuanting Xie,Liangjian Wen,Zhao Kang*

Main category: cs.AI

TL;DR: 本文提出了一种名为DMGC的新型多模态图聚类框架，通过分解混合图并引入双频融合机制，实现了无监督学习中的高性能聚类。


<details>
  <summary>Details</summary>
Motivation: 多模态图在现实世界中有广泛应用，但在无监督学习中的研究不足，尤其是混合邻域模式（同质性和异质性关系并存）的挑战尚未解决。

Method: 提出DMGC框架，将混合图分解为同质性增强图和异质性感知图，并通过双频融合机制进行联合过滤，结合自监督对齐目标进行学习。

Result: 在多个多模态和多关系图数据集上的实验表明，DMGC达到了最先进的性能。

Conclusion: DMGC通过解耦和融合多模态图，有效解决了混合邻域模式的挑战，具有广泛的适用性和高效性。

Abstract: Multimodal graphs, which integrate unstructured heterogeneous data with
structured interconnections, offer substantial real-world utility but remain
insufficiently explored in unsupervised learning. In this work, we initiate the
study of multimodal graph clustering, aiming to bridge this critical gap.
Through empirical analysis, we observe that real-world multimodal graphs often
exhibit hybrid neighborhood patterns, combining both homophilic and
heterophilic relationships. To address this challenge, we propose a novel
framework -- \textsc{Disentangled Multimodal Graph Clustering (DMGC)} -- which
decomposes the original hybrid graph into two complementary views: (1) a
homophily-enhanced graph that captures cross-modal class consistency, and (2)
heterophily-aware graphs that preserve modality-specific inter-class
distinctions. We introduce a \emph{Multimodal Dual-frequency Fusion} mechanism
that jointly filters these disentangled graphs through a dual-pass strategy,
enabling effective multimodal integration while mitigating category confusion.
Our self-supervised alignment objectives further guide the learning process
without requiring labels. Extensive experiments on both multimodal and
multi-relational graph datasets demonstrate that DMGC achieves state-of-the-art
performance, highlighting its effectiveness and generalizability across diverse
settings. Our code is available at https://github.com/Uncnbb/DMGC.

</details>


### [185] [IM-Chat: A Multi-agent LLM-based Framework for Knowledge Transfer in Injection Molding Industry](https://arxiv.org/abs/2507.15268)
*Junhyeong Lee,Joon-Young Kim,Heekyu Kim,Inhyo Lee,Seunghwa Ryu*

Main category: cs.AI

TL;DR: IM-Chat是一个基于大语言模型的多代理框架，旨在解决注塑成型行业中的知识转移问题，结合文档知识和现场数据，通过检索增强生成和工具调用代理实现适应性。


<details>
  <summary>Details</summary>
Motivation: 解决注塑成型行业因经验工人退休和多语言障碍导致的知识转移难题。

Method: 采用多代理框架IM-Chat，结合检索增强生成（RAG）策略和工具调用代理，利用数据驱动的工艺条件生成器推断最优制造设置。

Result: 评估显示，性能更强的模型（如GPT-4o）在复杂任务中表现更优，验证了多代理LLM系统在工业知识工作流中的可行性。

Conclusion: IM-Chat为制造业中的AI辅助决策支持提供了一种可扩展且通用的方法。

Abstract: The injection molding industry faces critical challenges in preserving and
transferring field knowledge, particularly as experienced workers retire and
multilingual barriers hinder effective communication. This study introduces
IM-Chat, a multi-agent framework based on large language models (LLMs),
designed to facilitate knowledge transfer in injection molding. IM-Chat
integrates both limited documented knowledge (e.g., troubleshooting tables,
manuals) and extensive field data modeled through a data-driven process
condition generator that infers optimal manufacturing settings from
environmental inputs such as temperature and humidity, enabling robust and
context-aware task resolution. By adopting a retrieval-augmented generation
(RAG) strategy and tool-calling agents within a modular architecture, IM-Chat
ensures adaptability without the need for fine-tuning. Performance was assessed
across 100 single-tool and 60 hybrid tasks for GPT-4o, GPT-4o-mini, and
GPT-3.5-turbo by domain experts using a 10-point rubric focused on relevance
and correctness, and was further supplemented by automated evaluation using
GPT-4o guided by a domain-adapted instruction prompt. The evaluation results
indicate that more capable models tend to achieve higher accuracy, particularly
in complex, tool-integrated scenarios. Overall, these findings demonstrate the
viability of multi-agent LLM systems for industrial knowledge workflows and
establish IM-Chat as a scalable and generalizable approach to AI-assisted
decision support in manufacturing.

</details>


### [186] [QSAF: A Novel Mitigation Framework for Cognitive Degradation in Agentic AI](https://arxiv.org/abs/2507.15330)
*Hammad Atta,Muhammad Zeeshan Baig,Yasir Mehmood,Nadeem Shahzad,Ken Huang,Muhammad Aziz Ul Haq,Muhammad Awais,Kamal Ahmed*

Main category: cs.AI

TL;DR: 论文提出了一种新型的AI系统漏洞类别——认知退化，并提出了Qorvex安全AI框架（QSAF Domain 10）来应对此类问题。


<details>
  <summary>Details</summary>
Motivation: 传统的外部对抗威胁（如提示注入）无法解决AI系统内部的认知退化问题，如内存不足、规划递归等，这些会导致系统性能下降和逻辑崩溃。

Method: 通过六阶段认知退化生命周期和七个运行时控制（QSAF-BC-001至BC-007），实时监控并主动缓解问题。

Result: QSAF框架能够检测并缓解认知退化问题，提升AI系统的行为与认知韧性。

Conclusion: 认知退化是AI系统的重要漏洞类别，QSAF框架为跨平台防御提供了首个解决方案。

Abstract: We introduce Cognitive Degradation as a novel vulnerability class in agentic
AI systems. Unlike traditional adversarial external threats such as prompt
injection, these failures originate internally, arising from memory starvation,
planner recursion, context flooding, and output suppression. These systemic
weaknesses lead to silent agent drift, logic collapse, and persistent
hallucinations over time. To address this class of failures, we introduce the
Qorvex Security AI Framework for Behavioral & Cognitive Resilience (QSAF Domain
10), a lifecycle-aware defense framework defined by a six-stage cognitive
degradation lifecycle. The framework includes seven runtime controls
(QSAF-BC-001 to BC-007) that monitor agent subsystems in real time and trigger
proactive mitigation through fallback routing, starvation detection, and memory
integrity enforcement. Drawing from cognitive neuroscience, we map agentic
architectures to human analogs, enabling early detection of fatigue,
starvation, and role collapse. By introducing a formal lifecycle and real-time
mitigation controls, this work establishes Cognitive Degradation as a critical
new class of AI system vulnerability and proposes the first cross-platform
defense model for resilient agentic behavior.

</details>


### [187] [One Step is Enough: Multi-Agent Reinforcement Learning based on One-Step Policy Optimization for Order Dispatch on Ride-Sharing Platforms](https://arxiv.org/abs/2507.15351)
*Zijian Zhao,Sen Li*

Main category: cs.AI

TL;DR: 论文提出两种新方法（GRPO和OSPO）解决传统多智能体强化学习在拼车平台中因依赖Q/V值估计而导致的训练不稳定和偏差问题。


<details>
  <summary>Details</summary>
Motivation: 拼车平台需实时匹配乘客与车辆，传统方法因依赖Q/V值估计在不确定环境中表现不佳。

Method: 1. 将GRPO应用于拼车，用组平均奖励替代PPO基线；2. 基于GRPO思想，提出OSPO，仅使用一步奖励训练策略。

Result: 在真实曼哈顿拼车数据集上，GRPO和OSPO在多数场景中表现优异，优化了接客时间和订单数量。

Conclusion: GRPO和OSPO通过绕过值函数估计，显著提升了拼车平台的匹配效率和稳定性。

Abstract: On-demand ride-sharing platforms face the fundamental challenge of
dynamically bundling passengers with diverse origins and destinations and
matching them with vehicles in real time, all under significant uncertainty.
Recently, MARL has emerged as a promising solution for this problem, leveraging
decentralized learning to address the curse of dimensionality caused by the
large number of agents in the ride-hailing market and the resulting expansive
state and action spaces. However, conventional MARL-based ride-sharing
approaches heavily rely on the accurate estimation of Q-values or V-values,
which becomes problematic in large-scale, highly uncertain environments.
Specifically, most of these approaches adopt an independent paradigm,
exacerbating this issue, as each agent treats others as part of the
environment, leading to unstable training and substantial estimation bias in
value functions. To address these challenges, we propose two novel alternative
methods that bypass value function estimation. First, we adapt GRPO to
ride-sharing, replacing the PPO baseline with the group average reward to
eliminate critic estimation errors and reduce training bias. Second, inspired
by GRPO's full utilization of group reward information, we customize the PPO
framework for ride-sharing platforms and show that, under a homogeneous fleet,
the optimal policy can be trained using only one-step rewards - a method we
term One-Step Policy Optimization (OSPO). Experiments on a real-world Manhattan
ride-hailing dataset demonstrate that both GRPO and OSPO achieve superior
performance across most scenarios, efficiently optimizing pickup times and the
number of served orders using simple MLP networks.

</details>


### [188] [RAD: Retrieval High-quality Demonstrations to Enhance Decision-making](https://arxiv.org/abs/2507.15356)
*Lu Guo,Yixiang Shan,Zhengbang Zhu,Qifan Liang,Lichang Song,Ting Long,Weinan Zhang,Yi Chang*

Main category: cs.AI

TL;DR: RAD方法通过结合非参数检索和扩散生成模型，解决了离线强化学习中数据集稀疏和轨迹规划问题，提升了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习因数据集稀疏和轨迹重叠不足，导致长时规划困难，现有方法泛化能力有限。

Method: RAD结合非参数检索和扩散生成模型，动态检索高回报状态作为目标，并利用条件扩散模型规划路径。

Result: 实验表明RAD在多种基准测试中表现优于基线方法。

Conclusion: RAD有效解决了离线强化学习中的泛化和规划问题。

Abstract: Offline reinforcement learning (RL) enables agents to learn policies from
fixed datasets, avoiding costly or unsafe environment interactions. However,
its effectiveness is often limited by dataset sparsity and the lack of
transition overlap between suboptimal and expert trajectories, which makes
long-horizon planning particularly challenging. Prior solutions based on
synthetic data augmentation or trajectory stitching often fail to generalize to
novel states and rely on heuristic stitching points. To address these
challenges, we propose Retrieval High-quAlity Demonstrations (RAD) for
decision-making, which combines non-parametric retrieval with diffusion-based
generative modeling. RAD dynamically retrieves high-return states from the
offline dataset as target states based on state similarity and return
estimation, and plans toward them using a condition-guided diffusion model.
Such retrieval-guided generation enables flexible trajectory stitching and
improves generalization when encountered with underrepresented or
out-of-distribution states. Extensive experiments confirm that RAD achieves
competitive or superior performance compared to baselines across diverse
benchmarks, validating its effectiveness.

</details>


### [189] [Predictive Process Monitoring Using Object-centric Graph Embeddings](https://arxiv.org/abs/2507.15411)
*Wissam Gherissi,Mehdi Acheli,Joyce El Haddad,Daniela Grigori*

Main category: cs.AI

TL;DR: 提出了一种基于图注意力网络和LSTM的端到端模型，用于预测未来流程行为，包括下一活动和下一事件时间。


<details>
  <summary>Details</summary>
Motivation: 利用对象中心事件日志提升流程预测的准确性和效率。

Method: 结合图注意力网络编码活动及其关系，LSTM处理时间依赖。

Result: 在真实和合成事件日志上表现优于现有方法。

Conclusion: 模型在预测流程行为方面具有竞争力。

Abstract: Object-centric predictive process monitoring explores and utilizes
object-centric event logs to enhance process predictions. The main challenge
lies in extracting relevant information and building effective models. In this
paper, we propose an end-to-end model that predicts future process behavior,
focusing on two tasks: next activity prediction and next event time. The
proposed model employs a graph attention network to encode activities and their
relationships, combined with an LSTM network to handle temporal dependencies.
Evaluated on one reallife and three synthetic event logs, the model
demonstrates competitive performance compared to state-of-the-art methods.

</details>


### [190] [Optimization of Activity Batching Policies in Business Processes](https://arxiv.org/abs/2507.15457)
*Orlenys López-Pintado,Jannis Rosenbaum,Marlon Dumas*

Main category: cs.AI

TL;DR: 本文提出了一种基于帕累托优化的方法，通过干预启发式发现业务过程中活动批处理的最优策略，权衡等待时间、处理成本与资源利用率。


<details>
  <summary>Details</summary>
Motivation: 业务过程中，批处理策略需要在降低成本与减少等待时间之间找到平衡，现有方法缺乏系统性优化。

Method: 采用帕累托优化框架，结合干预启发式（如调整批处理策略）和模拟评估，嵌入三种元启发式算法（爬山法、模拟退火、强化学习）进行优化。

Result: 实验表明，基于干预启发式的方法在收敛性、多样性和周期时间增益方面优于非启发式基线。

Conclusion: 该方法能有效发现最优批处理策略，为业务过程优化提供实用工具。

Abstract: In business processes, activity batching refers to packing multiple activity
instances for joint execution. Batching allows managers to trade off cost and
processing effort against waiting time. Larger and less frequent batches may
lower costs by reducing processing effort and amortizing fixed costs, but they
create longer waiting times. In contrast, smaller and more frequent batches
reduce waiting times but increase fixed costs and processing effort. A batching
policy defines how activity instances are grouped into batches and when each
batch is activated. This paper addresses the problem of discovering batching
policies that strike optimal trade-offs between waiting time, processing
effort, and cost. The paper proposes a Pareto optimization approach that starts
from a given set (possibly empty) of activity batching policies and generates
alternative policies for each batched activity via intervention heuristics.
Each heuristic identifies an opportunity to improve an activity's batching
policy with respect to a metric (waiting time, processing time, cost, or
resource utilization) and an associated adjustment to the activity's batching
policy (the intervention). The impact of each intervention is evaluated via
simulation. The intervention heuristics are embedded in an optimization
meta-heuristic that triggers interventions to iteratively update the Pareto
front of the interventions identified so far. The paper considers three
meta-heuristics: hill-climbing, simulated annealing, and reinforcement
learning. An experimental evaluation compares the proposed approach based on
intervention heuristics against the same (non-heuristic guided) meta-heuristics
baseline regarding convergence, diversity, and cycle time gain of
Pareto-optimal policies.

</details>


### [191] [Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner](https://arxiv.org/abs/2507.15509)
*Lei Chen,Xuanle Zhao,Zhixiong Zeng,Jing Huang,Yufeng Zhong,Lin Ma*

Main category: cs.AI

TL;DR: Chart-R1是一种基于强化学习微调的图表领域视觉语言模型，通过程序化数据合成和两阶段训练策略（Chart-COT和Chart-RFT）实现复杂图表推理，实验表明其优于现有图表领域方法，甚至媲美GPT-4o等大型模型。


<details>
  <summary>Details</summary>
Motivation: 验证R1-Style方法在通用多模态数据（如图表）上的优势，解决图表领域缺乏高质量推理数据的问题。

Method: 提出程序化数据合成技术生成高质量图表推理数据，并采用两阶段训练策略：Chart-COT（逐步监督）和Chart-RFT（数值敏感的强化微调）。

Result: Chart-R1在开源基准和自建数据集（ChartRQA）上表现优异，超越图表领域方法，接近GPT-4o等大型模型。

Conclusion: Chart-R1通过创新的数据合成和训练策略，显著提升了图表推理能力，展示了R1-Style方法在多模态任务中的潜力。

Abstract: Recently, inspired by OpenAI-o1/o3 and Deepseek-R1, the R1-Style method based
on reinforcement learning fine-tuning has received widespread attention from
the community. Previous R1-Style methods mainly focus on mathematical reasoning
and code intelligence. It is of great research significance to verify their
advantages on more general multimodal data. Chart is an important multimodal
data type with rich information, which brings important research challenges in
complex reasoning. In this work, we introduce Chart-R1, a chart-domain
vision-language model with reinforcement learning fine-tuning to enable complex
chart reasoning. To support Chart-R1, we first propose a novel programmatic
data synthesis technology to generate high-quality step-by-step chart reasoning
data covering single- and multi-subcharts, which makes up for the lack of
reasoning data in the chart domain. Then we develop a two-stage training
strategy: Chart-COT with step-by-step chain-of-thought supervision, and
Chart-RFT with numerically sensitive reinforcement fine-tuning. Chart-COT aims
to decompose complex chart reasoning tasks into fine-grained, understandable
subtasks through step-by-step supervision, which lays a good foundation for
improving the reasoning level of reinforcement learning. Chart-RFT utilize the
typical group relative policy optimization strategy, in which a relatively soft
reward is adopted for numerical response to emphasize the numerical sensitivity
in the chart domain. We conduct extensive experiments on open-source benchmarks
and self-built chart reasoning dataset (\emph{i.e., ChartRQA}). Experimental
results show that Chart-R1 has significant advantages compared to chart-domain
methods, even comparable to open/closed source large-scale models (\emph{e.g.,
GPT-4o, Claude-3.5}).

</details>


### [192] [HAMLET: Hyperadaptive Agent-based Modeling for Live Embodied Theatrics](https://arxiv.org/abs/2507.15518)
*Sizhou Chen,Shufan Jiang,Chi Zhang,Xiao-Lei Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: HAMLET是一个基于多智能体框架的戏剧创作与在线表演系统，通过自主决策和物理环境交互提升沉浸感。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的戏剧生成方法缺乏主动性和物理交互，需详细用户输入，限制了实时表演的互动性和沉浸感。

Method: 提出HAMLET框架，生成叙事蓝图并赋予演员自主决策能力，支持通过动作改变场景状态。

Result: 实验表明HAMLET能创造表达性强且连贯的戏剧体验。

Conclusion: HAMLET通过多智能体自主决策和物理交互，显著提升了戏剧表演的互动性和沉浸感。

Abstract: Creating an immersive and interactive theatrical experience is a long-term
goal in the field of interactive narrative. The emergence of large language
model (LLM) is providing a new path to achieve this goal. However, existing
LLM-based drama generation methods often result in AI agents that lack
initiative and cannot interact with the physical environment. Furthermore,
these methods typically require detailed user input to drive the drama. These
limitations reduce the interactivity and immersion of online real-time
performance. To address the above challenges, we propose HAMLET, a multi-agent
framework focused on drama creation and online performance. Given a simple
topic, the framework generates a narrative blueprint, guiding the subsequent
improvisational performance. During the online performance, each actor is given
an autonomous mind. This means that actors can make independent decisions based
on their own background, goals, and emotional state. In addition to
conversations with other actors, their decisions can also change the state of
scene props through actions such as opening a letter or picking up a weapon.
The change is then broadcast to other related actors, updating what they know
and care about, which in turn influences their next action. To evaluate the
quality of drama performance, we designed an evaluation method to assess three
primary aspects, including character performance, narrative quality, and
interaction experience. The experimental evaluation shows that HAMLET can
create expressive and coherent theatrical experiences. Our code, dataset and
models are available at https://github.com/HAMLET-2025/HAMLET.

</details>


### [193] [LLM world models are mental: Output layer evidence of brittle world model use in LLM mechanical reasoning](https://arxiv.org/abs/2507.15521)
*Cole Robertson,Philip Wolff*

Main category: cs.AI

TL;DR: 论文探讨大型语言模型（LLM）是否构建内部世界模型或仅依赖统计关联。通过滑轮系统实验，发现LLM能利用统计关联（如滑轮数量）估计机械优势（MA），但缺乏对复杂结构连接的推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究LLM是否具备内部世界模型构建能力，而非仅依赖统计关联。

Method: 采用认知科学方法，通过三个实验（滑轮系统问题）测试LLM的MA估计能力、系统功能识别能力及结构连接推理能力。

Result: LLM能基于统计关联估计MA（Study 1），识别功能系统（Study 2），但在复杂结构推理中表现随机（Study 3）。

Conclusion: LLM可能具备初步世界模型能力，但缺乏复杂推理。认知科学方法有助于评估AI的世界建模能力。

Abstract: Do large language models (LLMs) construct and manipulate internal world
models, or do they rely solely on statistical associations represented as
output layer token probabilities? We adapt cognitive science methodologies from
human mental models research to test LLMs on pulley system problems using
TikZ-rendered stimuli. Study 1 examines whether LLMs can estimate mechanical
advantage (MA). State-of-the-art models performed marginally but significantly
above chance, and their estimates correlated significantly with ground-truth
MA. Significant correlations between number of pulleys and model estimates
suggest that models employed a pulley counting heuristic, without necessarily
simulating pulley systems to derive precise values. Study 2 tested this by
probing whether LLMs represent global features crucial to MA estimation. Models
evaluated a functionally connected pulley system against a fake system with
randomly placed components. Without explicit cues, models identified the
functional system as having greater MA with F1=0.8, suggesting LLMs could
represent systems well enough to differentiate jumbled from functional systems.
Study 3 built on this by asking LLMs to compare functional systems with matched
systems which were connected up but which transferred no force to the weight;
LLMs identified the functional system with F1=0.46, suggesting random guessing.
Insofar as they may generalize, these findings are compatible with the notion
that LLMs manipulate internal world models, sufficient to exploit statistical
associations between pulley count and MA (Study 1), and to approximately
represent system components' spatial relations (Study 2). However, they may
lack the facility to reason over nuanced structural connectivity (Study 3). We
conclude by advocating the utility of cognitive scientific methods to evaluate
the world-modeling capacities of artificial intelligence systems.

</details>


### [194] [Data-Efficient Safe Policy Improvement Using Parametric Structure](https://arxiv.org/abs/2507.15532)
*Kasper Engelen,Guillermo A. Pérez,Marnix Suilen*

Main category: cs.AI

TL;DR: 论文提出了一种利用参数依赖关系提升安全策略改进（SPI）数据效率的方法，包括参数化SPI算法和两种预处理技术。


<details>
  <summary>Details</summary>
Motivation: 在离线强化学习中，如何利用已知的参数依赖关系提高数据效率，同时确保新策略可靠优于行为策略。

Method: 1. 参数化SPI算法；2. 基于博弈抽象的动作剪枝预处理；3. 基于SMT求解的进阶预处理。

Result: 实验表明，这些技术将SPI的数据效率提升多个数量级，同时保持可靠性。

Conclusion: 通过利用参数依赖关系和预处理技术，显著提升了SPI的数据效率。

Abstract: Safe policy improvement (SPI) is an offline reinforcement learning problem in
which a new policy that reliably outperforms the behavior policy with high
confidence needs to be computed using only a dataset and the behavior policy.
Markov decision processes (MDPs) are the standard formalism for modeling
environments in SPI. In many applications, additional information in the form
of parametric dependencies between distributions in the transition dynamics is
available. We make SPI more data-efficient by leveraging these dependencies
through three contributions: (1) a parametric SPI algorithm that exploits known
correlations between distributions to more accurately estimate the transition
dynamics using the same amount of data; (2) a preprocessing technique that
prunes redundant actions from the environment through a game-based abstraction;
and (3) a more advanced preprocessing technique, based on satisfiability modulo
theory (SMT) solving, that can identify more actions to prune. Empirical
results and an ablation study show that our techniques increase the data
efficiency of SPI by multiple orders of magnitude while maintaining the same
reliability guarantees.

</details>


### [195] [Metric assessment protocol in the context of answer fluctuation on MCQ tasks](https://arxiv.org/abs/2507.15581)
*Ekaterina Goliakova,Xavier Renard,Marie-Jeanne Lesot,Thibault Laugel,Christophe Marsala,Marcin Detyniecki*

Main category: cs.AI

TL;DR: 论文提出了一种评估多选问题（MCQ）指标的新协议，分析指标与答案波动率的关系，发现现有指标与答案变化有强关联，并提出新指标“最差准确率”表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有研究未全面评估MCQ指标，且MCQ评估存在答案波动问题，需要一种更可靠的评估方法。

Method: 提出一种指标评估协议，通过分析指标与答案波动率及原始性能的关系来评估方法。

Result: 现有指标与答案变化有强关联，新指标“最差准确率”在协议中表现最佳。

Conclusion: 新协议和“最差准确率”指标为MCQ评估提供了更可靠的方法。

Abstract: Using multiple-choice questions (MCQs) has become a standard for assessing
LLM capabilities efficiently. A variety of metrics can be employed for this
task. However, previous research has not conducted a thorough assessment of
them. At the same time, MCQ evaluation suffers from answer fluctuation: models
produce different results given slight changes in prompts. We suggest a metric
assessment protocol in which evaluation methodologies are analyzed through
their connection with fluctuation rates, as well as original performance. Our
results show that there is a strong link between existing metrics and the
answer changing, even when computed without any additional prompt variants. A
novel metric, worst accuracy, demonstrates the highest association on the
protocol.

</details>


### [196] [TacticCraft: Natural Language-Driven Tactical Adaptation for StarCraft II](https://arxiv.org/abs/2507.15618)
*Weiyu Ma,Jiwen Jiang,Haobo Fu,Haifeng Zhang*

Main category: cs.AI

TL;DR: 提出一种基于适配器的方法，用于《星际争霸II》AI代理的战术条件调节，通过轻量级适配器模块实现战术变化，同时保持核心能力。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理虽强大，但缺乏基于高层战术指令的策略适应能力。

Method: 冻结预训练策略网络（DI-Star），为每个动作头附加轻量级适配器模块，并通过KL散度约束训练适配器。

Result: 实验表明，该方法能成功调节代理行为（如侵略性、扩张模式和技术偏好），同时保持竞争力。

Conclusion: 该方法以最小计算开销实现灵活战术控制，适用于复杂即时战略游戏的策略定制。

Abstract: We present an adapter-based approach for tactical conditioning of StarCraft
II AI agents. Current agents, while powerful, lack the ability to adapt their
strategies based on high-level tactical directives. Our method freezes a
pre-trained policy network (DI-Star) and attaches lightweight adapter modules
to each action head, conditioned on a tactical tensor that encodes strategic
preferences. By training these adapters with KL divergence constraints, we
ensure the policy maintains core competencies while exhibiting tactical
variations. Experimental results show our approach successfully modulates agent
behavior across tactical dimensions including aggression, expansion patterns,
and technology preferences, while maintaining competitive performance. Our
method enables flexible tactical control with minimal computational overhead,
offering practical strategy customization for complex real-time strategy games.

</details>


### [197] [Agentic AI for autonomous anomaly management in complex systems](https://arxiv.org/abs/2507.15676)
*Reza Vatankhah Barenji,Sina Khoshgoftar*

Main category: cs.AI

TL;DR: 探讨智能代理AI在复杂系统中自主检测和响应异常的潜力。


<details>
  <summary>Details</summary>
Motivation: 旨在改变传统依赖人工的异常管理方法。

Method: 利用智能代理AI的自主能力。

Result: 展示了智能代理AI在异常管理中的潜力。

Conclusion: 智能代理AI有望革新异常管理方法。

Abstract: This paper explores the potential of agentic AI in autonomously detecting and
responding to anomalies within complex systems, emphasizing its ability to
transform traditional, human-dependent anomaly management methods.

</details>


### [198] [Towards physician-centered oversight of conversational diagnostic AI](https://arxiv.org/abs/2507.15743)
*Elahe Vedadi,David Barrett,Natalie Harris,Ellery Wulczyn,Shashir Reddy,Roma Ruparel,Mike Schaekermann,Tim Strother,Ryutaro Tanno,Yash Sharma,Jihyeon Lee,Cían Hughes,Dylan Slack,Anil Palepu,Jan Freyberg,Khaled Saab,Valentin Liévin,Wei-Hung Weng,Tao Tu,Yun Liu,Nenad Tomasev,Kavita Kulkarni,S. Sara Mahdavi,Kelvin Guu,Joëlle Barral,Dale R. Webster,James Manyika,Avinatan Hassidim,Katherine Chou,Yossi Matias,Pushmeet Kohli,Adam Rodman,Vivek Natarajan,Alan Karthikesalingam,David Stutz*

Main category: cs.AI

TL;DR: 论文提出了一种名为g-AMIE的多智能体系统框架，用于在医疗诊断对话中实现异步监督，确保AI系统在安全范围内运行，并由医生最终负责临床决策。


<details>
  <summary>Details</summary>
Motivation: 当前医疗AI系统在提供诊断和治疗建议时需要专业医生的监督，但传统监督方式效率较低。本文旨在探索一种异步监督框架，以提高效率和安全性。

Method: 提出g-AMIE系统，通过多智能体协作完成病史采集，并在安全范围内运行，避免提供个性化医疗建议。系统将评估结果通过临床驾驶舱界面提交给主治医生进行异步监督。

Result: 在虚拟OSCE测试中，g-AMIE在病史采集、病例总结及诊断建议方面优于护士和医生助理组，且监督效率高于传统医生单独会诊。

Conclusion: 异步监督框架为医疗AI系统在专家监督下运行提供了可行方案，有望提升现实世界中的医疗服务质量。

Abstract: Recent work has demonstrated the promise of conversational AI systems for
diagnostic dialogue. However, real-world assurance of patient safety means that
providing individual diagnoses and treatment plans is considered a regulated
activity by licensed professionals. Furthermore, physicians commonly oversee
other team members in such activities, including nurse practitioners (NPs) or
physician assistants/associates (PAs). Inspired by this, we propose a framework
for effective, asynchronous oversight of the Articulate Medical Intelligence
Explorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent
system that performs history taking within guardrails, abstaining from
individualized medical advice. Afterwards, g-AMIE conveys assessments to an
overseeing primary care physician (PCP) in a clinician cockpit interface. The
PCP provides oversight and retains accountability of the clinical decision.
This effectively decouples oversight from intake and can thus happen
asynchronously. In a randomized, blinded virtual Objective Structured Clinical
Examination (OSCE) of text consultations with asynchronous oversight, we
compared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across
60 scenarios, g-AMIE outperformed both groups in performing high-quality
intake, summarizing cases, and proposing diagnoses and management plans for the
overseeing PCP to review. This resulted in higher quality composite decisions.
PCP oversight of g-AMIE was also more time-efficient than standalone PCP
consultations in prior work. While our study does not replicate existing
clinical practices and likely underestimates clinicians' capabilities, our
results demonstrate the promise of asynchronous oversight as a feasible
paradigm for diagnostic AI systems to operate under expert human oversight for
enhancing real-world care.

</details>


### [199] [LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization](https://arxiv.org/abs/2507.15758)
*Xingyu Wu,Yuchen Yan,Shangke Lyu,Linjuan Wu,Yiwen Qiu,Yongliang Shen,Weiming Lu,Jian Shao,Jun Xiao,Yueting Zhuang*

Main category: cs.AI

TL;DR: LAPO是一种新框架，通过强化学习让模型内化推理长度控制，减少40.9%的token使用并提高2.3%的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在长链推理中表现优异，但会生成过多token，LAPO旨在将推理长度控制内化为模型能力。

Method: 采用两阶段强化学习：第一阶段学习成功解的长度分布，第二阶段将其作为元认知指导嵌入推理上下文。

Result: 在数学推理基准测试中，LAPO减少40.9%的token使用，同时提高2.3%的准确性。

Conclusion: LAPO使模型能根据问题复杂度分配计算资源，实现高效推理且不牺牲质量。

Abstract: Large reasoning models have achieved remarkable performance through extended
chain-of-thought sequences, yet this computational freedom leads to excessive
token generation even for simple problems. We present Length-Adaptive Policy
Optimization (LAPO), a novel framework that transforms reasoning length control
from an external constraint into an intrinsic model capability. Unlike existing
approaches that impose rigid limits or rely on post-hoc interventions, LAPO
enables models to internalize an understanding of appropriate reasoning depth
through a two-stage reinforcement learning process. In the first stage, models
learn natural reasoning patterns by discovering the statistical distribution of
successful solution lengths. The second stage leverages these patterns as
meta-cognitive guidance, embedding them directly within the model's reasoning
context to ensure inference-time flexibility. Experiments on mathematical
reasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9\%
while improving accuracy by 2.3\%. Our analysis reveals that models trained
with LAPO develop emergent abilities to allocate computational resources based
on problem complexity, achieving efficient reasoning without sacrificing
quality.

</details>


### [200] [GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts](https://arxiv.org/abs/2507.15761)
*Jingyi Zheng,Zifan Peng,Yule Liu,Junfeng Wang,Yifan Liao,Wenhan Dong,Xinlei He*

Main category: cs.AI

TL;DR: GasAgent是一个多代理系统，用于智能合约Gas优化，结合现有模式的兼容性和自动化发现/验证新模式，实现端到端优化。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案依赖手动发现Gas浪费模式，效率低且难以扩展。LLMs虽能探索新模式，但兼容性差且需手动验证。

Method: GasAgent由四个专业代理（Seeker、Innovator、Executor、Manager）协作，闭环识别、验证和应用Gas节省改进。

Result: 实验表明，GasAgent优化了82%的合约，平均节省9.97%部署Gas，且兼容现有工具。

Conclusion: GasAgent可作为LLM辅助智能合约开发的优化层，具有广泛适用性。

Abstract: Smart contracts are trustworthy, immutable, and automatically executed
programs on the blockchain. Their execution requires the Gas mechanism to
ensure efficiency and fairness. However, due to non-optimal coding practices,
many contracts contain Gas waste patterns that need to be optimized. Existing
solutions mostly rely on manual discovery, which is inefficient, costly to
maintain, and difficult to scale. Recent research uses large language models
(LLMs) to explore new Gas waste patterns. However, it struggles to remain
compatible with existing patterns, often produces redundant patterns, and
requires manual validation/rewriting. To address this gap, we present GasAgent,
the first multi-agent system for smart contract Gas optimization that combines
compatibility with existing patterns and automated discovery/validation of new
patterns, enabling end-to-end optimization. GasAgent consists of four
specialized agents, Seeker, Innovator, Executor, and Manager, that collaborate
in a closed loop to identify, validate, and apply Gas-saving improvements.
Experiments on 100 verified real-world contracts demonstrate that GasAgent
successfully optimizes 82 contracts, achieving an average deployment Gas
savings of 9.97%. In addition, our evaluation confirms its compatibility with
existing tools and validates the effectiveness of each module through ablation
studies. To assess broader usability, we further evaluate 500 contracts
generated by five representative LLMs across 10 categories and find that
GasAgent optimizes 79.8% of them, with deployment Gas savings ranging from
4.79% to 13.93%, showing its usability as the optimization layer for
LLM-assisted smart contract development.

</details>


### [201] [A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining](https://arxiv.org/abs/2507.15770)
*Yifan Shen,Zihan Zhao,Xiao Xue,Yuwei Guo,Qun Ma,Deyu Zhou,Ming Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种基于多智能体意图的动态可解释涌现分析框架EAMI，通过双视角思维追踪和k-means聚类揭示群体意图的相变点，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着服务计算、云计算和物联网的发展，服务生态系统变得复杂，传统因果方法难以分析智能体间的异常涌现现象。

Method: EAMI框架采用双视角思维追踪机制（Inspector Agent和Analysis Agent）提取意图，结合k-means聚类和意图时序涌现图进行动态分析。

Result: 实验在复杂O2O服务系统和Stanford AI Town中验证了EAMI的有效性、通用性和高效性。

Conclusion: EAMI为服务生态系统中的异常涌现和因果分析提供了新范式。

Abstract: With the rise of service computing, cloud computing, and IoT, service
ecosystems are becoming increasingly complex. The intricate interactions among
intelligent agents make abnormal emergence analysis challenging, as traditional
causal methods focus on individual trajectories. Large language models offer
new possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT)
reasoning to reveal agent intentions. However, existing approaches remain
limited to microscopic and static analysis. This paper introduces a framework:
Emergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic
and interpretable emergence analysis. EAMI first employs a dual-perspective
thought track mechanism, where an Inspector Agent and an Analysis Agent extract
agent intentions under bounded and perfect rationality. Then, k-means
clustering identifies phase transition points in group intentions, followed by
a Intention Temporal Emergence diagram for dynamic analysis. The experiments
validate EAMI in complex online-to-offline (O2O) service system and the
Stanford AI Town experiment, with ablation studies confirming its
effectiveness, generalizability, and efficiency. This framework provides a
novel paradigm for abnormal emergence and causal analysis in service
ecosystems. The code is available at
https://anonymous.4open.science/r/EAMI-B085.

</details>


### [202] [Challenges of Trustworthy Federated Learning: What's Done, Current Trends and Remaining Work](https://arxiv.org/abs/2507.15796)
*Nuria Rodríguez-Barroso,Mario García-Márquez,M. Victoria Luzón,Francisco Herrera*

Main category: cs.AI

TL;DR: 该论文探讨了如何将联邦学习（FL）与可信人工智能（TAI）的要求对齐，分析了FL在满足TAI时面临的挑战，并总结了当前进展和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着可信人工智能（TAI）在敏感和高风险领域的重要性日益凸显，联邦学习（FL）作为一种隐私保护技术，如何满足TAI的综合要求成为关键问题。

Method: 作者以TAI的要求为框架，系统分析了FL在适应TAI时的主要挑战，并对现有研究、趋势和未解决问题进行了分类和探讨。

Result: 论文识别了FL在满足TAI要求时的主要障碍，并总结了当前的研究进展和未来需要解决的问题。

Conclusion: 通过系统分析，论文为FL与TAI的对齐提供了清晰的挑战分类和研究方向，为未来研究奠定了基础。

Abstract: In recent years, the development of Trustworthy Artificial Intelligence (TAI)
has emerged as a critical objective in the deployment of AI systems across
sensitive and high-risk domains. TAI frameworks articulate a comprehensive set
of ethical, legal, and technical requirements to ensure that AI technologies
are aligned with human values, rights, and societal expectations. Among the
various AI paradigms, Federated Learning (FL) presents a promising solution to
pressing privacy concerns. However, aligning FL with the rest of the
requirements of TAI presents a series of challenges, most of which arise from
its inherently distributed nature. In this work, we adopt the requirements TAI
as a guiding structure to systematically analyze the challenges of adapting FL
to TAI. Specifically, we classify and examine the key obstacles to aligning FL
with TAI, providing a detailed exploration of what has been done, the trends,
and the remaining work within each of the identified challenges.

</details>


### [203] [Identifying Conditional Causal Effects in MPDAGs](https://arxiv.org/abs/2507.15842)
*Sara LaPlante,Emilija Perković*

Main category: cs.AI

TL;DR: 论文研究了在已知最大定向部分有向无环图（MPDAG）的情况下，如何识别条件因果效应。提出了三个结果：不受治疗影响的条件下识别公式、MPDAG设置下的do calculus推广，以及识别这些条件效应的完整算法。


<details>
  <summary>Details</summary>
Motivation: 背景知识限制了因果图的等价类，且所有变量均为观测变量。研究目标是解决在MPDAG设置下条件因果效应的识别问题。

Method: 提出了三个关键结果：1）不受治疗影响的条件下识别公式；2）将do calculus推广到MPDAG设置；3）开发了一个完整的识别算法。

Result: 提供了在MPDAG设置下识别条件因果效应的理论框架和实用工具。

Conclusion: 论文为MPDAG设置下的条件因果效应识别提供了全面的解决方案，扩展了现有因果推断方法的应用范围。

Abstract: We consider identifying a conditional causal effect when a graph is known up
to a maximally oriented partially directed acyclic graph (MPDAG). An MPDAG
represents an equivalence class of graphs that is restricted by background
knowledge and where all variables in the causal model are observed. We provide
three results that address identification in this setting: an identification
formula when the conditioning set is unaffected by treatment, a generalization
of the well-known do calculus to the MPDAG setting, and an algorithm that is
complete for identifying these conditional effects.

</details>


### [204] [Hierarchical Budget Policy Optimization for Adaptive Reasoning](https://arxiv.org/abs/2507.15844)
*Shangke Lyu,Linjuan Wu,Yuchen Yan,Xingyu Wu,Hao Li,Yongliang Shen,Peisheng Jiang,Weiming Lu,Jun Xiao,Yueting Zhuang*

Main category: cs.AI

TL;DR: HBPO是一种强化学习框架，通过分层预算探索和差异化奖励机制，优化推理模型的效率和能力，减少60.6%的token使用并提升3.14%的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决大型推理模型在统一推理策略下计算效率低下的问题，同时避免因效率优化导致的推理能力下降。

Method: 采用分层预算探索，将样本分组并分配不同token预算，结合差异化奖励机制，使模型根据问题复杂度自适应调整推理深度。

Result: 在四个推理基准测试中，平均token使用减少60.6%，准确率提升3.14%。

Conclusion: 推理效率和能力并非固有冲突，通过分层训练可同时优化，模型能自适应调整推理深度。

Abstract: Large reasoning models achieve remarkable performance through extensive
chain-of-thought generation, yet exhibit significant computational inefficiency
by applying uniform reasoning strategies regardless of problem complexity. We
present Hierarchical Budget Policy Optimization (HBPO), a reinforcement
learning framework that enables models to learn problem-specific reasoning
depths without sacrificing capability. HBPO addresses the fundamental challenge
of exploration space collapse in efficiency-oriented training, where penalties
on long output length systematically bias models away from necessary long
reasoning paths. Through hierarchical budget exploration, our approach
partitions rollout samples into multiple subgroups with distinct token budgets,
aiming to enable efficient resource allocation while preventing degradation of
capability. We introduce differentiated reward mechanisms that create
budget-aware incentives aligned with the complexity of the problem, allowing
models to discover natural correspondences between task requirements and
computational effort. Extensive experiments demonstrate that HBPO reduces
average token usage by up to 60.6% while improving accuracy by 3.14% across
four reasoning benchmarks. Unlike existing methods that impose external
constraints or rely on discrete mode selection, HBPO exhibits emergent adaptive
behavior where models automatically adjust reasoning depth based on problem
complexity. Our results suggest that reasoning efficiency and capability are
not inherently conflicting, and can be simultaneously optimized through
appropriately structured hierarchical training that preserves exploration
diversity.

</details>


### [205] [The Other Mind: How Language Models Exhibit Human Temporal Cognition](https://arxiv.org/abs/2507.15851)
*Lingyu Li,Yang Yao,Yixu Wang,Chubo Li,Yan Teng,Yingchun Wang*

Main category: cs.AI

TL;DR: 研究发现大型语言模型（LLMs）在时间认知上表现出类似人类的自发行为，如建立主观时间参考点并遵循韦伯-费希纳定律。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在未明确训练的情况下如何表现出类似人类的时间认知模式。

Method: 通过相似性判断任务和多层次分析（神经元、表征和信息层面）揭示LLMs的时间认知机制。

Result: 发现LLMs中存在时间偏好神经元，表征呈现层次构建过程，且训练语料具有非线性时间结构。

Conclusion: 提出体验主义视角理解LLMs的认知，强调AI对齐需关注内部表征构建。

Abstract: As Large Language Models (LLMs) continue to advance, they exhibit certain
cognitive patterns similar to those of humans that are not directly specified
in training data. This study investigates this phenomenon by focusing on
temporal cognition in LLMs. Leveraging the similarity judgment task, we find
that larger models spontaneously establish a subjective temporal reference
point and adhere to the Weber-Fechner law, whereby the perceived distance
logarithmically compresses as years recede from this reference point. To
uncover the mechanisms behind this behavior, we conducted multiple analyses
across neuronal, representational, and informational levels. We first identify
a set of temporal-preferential neurons and find that this group exhibits
minimal activation at the subjective reference point and implements a
logarithmic coding scheme convergently found in biological systems. Probing
representations of years reveals a hierarchical construction process, where
years evolve from basic numerical values in shallow layers to abstract temporal
orientation in deep layers. Finally, using pre-trained embedding models, we
found that the training corpus itself possesses an inherent, non-linear
temporal structure, which provides the raw material for the model's internal
construction. In discussion, we propose an experientialist perspective for
understanding these findings, where the LLMs' cognition is viewed as a
subjective construction of the external world by its internal representational
system. This nuanced perspective implies the potential emergence of alien
cognitive frameworks that humans cannot intuitively predict, pointing toward a
direction for AI alignment that focuses on guiding internal constructions. Our
code is available at https://TheOtherMind.github.io.

</details>


### [206] [Gemini 2.5 Pro Capable of Winning Gold at IMO 2025](https://arxiv.org/abs/2507.15855)
*Yichen Huang,Lin F. Yang*

Main category: cs.AI

TL;DR: Gemini 2.5 Pro成功解决了IMO 2025的5道难题，展示了优化使用大型语言模型的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（如Gemini 2.5 Pro）在解决国际数学奥林匹克（IMO）等高难度数学问题上的表现，填补现有模型在奥数任务上的不足。

Method: 通过管道设计和提示工程优化Gemini 2.5 Pro的使用，避免数据污染，测试其在IMO 2025问题上的表现。

Result: Gemini 2.5 Pro成功解决了6道问题中的5道，显示出其在奥数任务上的潜力。

Conclusion: 优化模型使用方法对解决高难度数学问题至关重要，Gemini 2.5 Pro在IMO任务中表现出色。

Abstract: The International Mathematical Olympiad (IMO) poses uniquely challenging
problems requiring deep insight, creativity, and formal reasoning. While Large
Language Models (LLMs) perform well on mathematical benchmarks like AIME, they
struggle with Olympiad-level tasks. We use Google's Gemini 2.5 Pro on the newly
released IMO 2025 problems, avoiding data contamination. With pipeline design
and prompt engineering, 5 (out of 6) problems are solved correctly (up to a
caveat discussed below), highlighting the importance of finding the optimal way
of using powerful models.

</details>
