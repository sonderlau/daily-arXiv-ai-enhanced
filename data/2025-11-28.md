<div id=toc></div>

# Table of Contents

- [physics.ao-ph](#physics.ao-ph) [Total: 4]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.CV](#cs.CV) [Total: 16]
- [cs.AI](#cs.AI) [Total: 18]


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [1] [Sunlight, the Bond Albedo, CO2, and Earth's Temperature](https://arxiv.org/abs/2511.20803)
*R. Louw,W. A. van Wijngaarden,W. Happer*

Main category: physics.ao-ph

TL;DR: 该研究分析了影响地球表面温度的主要因素，发现太阳常数最重要，反照率次之，CO2浓度影响最小。


<details>
  <summary>Details</summary>
Motivation: 确定影响地球绝对表面温度的关键因素及其相对重要性。

Method: 假设有效发射率由大气CO2浓度决定，分析太阳常数、反照率和CO2浓度对温度的影响。

Result: 太阳常数对温度影响最大，反照率第二重要，CO2浓度影响相对较小。

Conclusion: 在影响地球表面温度的因素中，太阳常数是最主要的决定因素，其次是反照率，CO2浓度的影响相对较弱。

Abstract: The main determinants of Earth's absolute surface Temperature, T, are the solar constant, S, the Bond albedo, A, and the effective emissivity for thermal radiation, e. In this note we assume that the value of the effective emissivity, e = e(C), is determined by the atmospheric concentration C of CO2. We show that the solar constant is most important, the albedo is second, and the CO2 concentration is a distant third.

</details>


### [2] [The early history of Marine Cloud Brightening (MCB); the legacy of John Latham and Stephen Salter](https://arxiv.org/abs/2511.20897)
*Alan Gadian*

Main category: physics.ao-ph

TL;DR: 本文回顾了海洋云增亮(MCB)概念从1990年作为云微物理过程的理论构想，到2015年发展成熟的过程，重点关注创始人John Latham和Stephen Salter的贡献，以及该技术作为缓解全球变暖的潜在方法的最新发展。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够缓解地球快速变暖的地球工程技术，海洋云增亮被认为是通过增加云层反射率来降低地球表面温度的潜在方法。

Method: 通过云微物理过程的理论研究，从最初的概念构想到完整技术方案的开发，包括英国ARIA项目中的进一步研究。

Result: 成功建立了海洋云增亮作为地球工程技术的理论基础，并展示了其作为缓解全球变暖的可行性。

Conclusion: 海洋云增亮技术从理论概念发展为有前景的地球工程方法，为应对气候变化提供了新的技术路径。

Abstract: This paper discusses the initial development of Marine Cloud Brightening (MCB) as a theoretical idea, from its inception as a cloud microphysics process in circe 1990 to the full-blown concept by 2015. It primarily focuses on the work of founders John Latham and Stephen Salter and their contributions. Recently the concept has been developed further, e.g. in the UK ARIA project, as a prospective method to ameliorate the Earths rapid warming.

</details>


### [3] [Extratropical Atmospheric Circulation Response to ENSO in Deep Learning Pacific Pacemaker Experiments](https://arxiv.org/abs/2511.20899)
*Zhanxiang Hua,Christina Karamperidou,Zilu Meng*

Main category: physics.ao-ph

TL;DR: 使用耦合深度学习气候模拟器进行太平洋定速实验，发现虽然能真实捕捉大气内部变率，但对ENSO强迫的遥相关响应显著放大，导致极端事件模拟偏差。


<details>
  <summary>Details</summary>
Motivation: 耦合大气-海洋深度学习气候模拟器存在ENSO变率弱的问题，需要验证其模拟遥相关的能力。

Method: 使用耦合深度学习模拟器(DLESyM)进行太平洋定速(PACE)实验，隔离观测ENSO强迫下的大气响应。

Result: 模拟器能真实捕捉大气内部变率，但对ENSO强迫的遥相关响应显著放大，导致大气阻塞频率和持续时间被高估，峰值强度被低估。

Conclusion: 耦合深度学习气候模型需要像传统数值模型一样进行深入且物理基础扎实的验证，以建立其在物理气候分析中使用的可信度。

Abstract: Coupled atmosphere-ocean deep learning (DL) climate emulators are a new frontier but are known to exhibit weak ENSO variability, raising questions about their ability to simulate teleconnections. Here, we present the first Pacific pacemaker (PACE) experiments using a coupled DL emulator (DLESyM) to bypass this weak variability and isolate the atmospheric response to observed ENSO forcing. We find that while the emulator realistically captures internal atmospheric variability, it produces a significantly amplified forced teleconnection response to ENSO. This amplified response leads to biases in simulating extremes, notably an overestimation of atmospheric blocking frequency and duration with the underestimation of peak intensity. Our findings underscore that coupled DL climate models require in-depth and physically-grounded validation, analogous to traditional numerical models, to build confidence in their use for physical climate analysis.

</details>


### [4] [Crowdsourcing the Frontier: Advancing Hybrid Physics-ML Climate Simulation via $50,000 Kaggle Competition](https://arxiv.org/abs/2511.20963)
*Jerry Lin,Zeyuan Hu,Tom Beucler,Katherine Frields,Hannah Christensen,Walter Hannah,Helge Heuer,Peter Ukkonnen,Laura A. Mansfield,Tian Zheng,Liran Peng,Ritwik Gupta,Pierre Gentine,Yusef Al-Naher,Mingjiang Duan,Kyo Hattori,Weiliang Ji,Chunhan Li,Kippei Matsuda,Naoki Murakami,Shlomo Ron,Marec Serlin,Hongjian Song,Yuma Tanabe,Daisuke Yamamoto,Jianyao Zhou,Mike Pritchard*

Main category: physics.ao-ph

TL;DR: 该论文研究了将Kaggle竞赛获胜团队的机器学习架构集成到气候模型中，证明了在低分辨率真实地理环境下在线稳定性的可重现性，多个架构在特定指标上达到了最先进水平。


<details>
  <summary>Details</summary>
Motivation: 解决亚网格机器学习参数化在长期气候预测中存在的在线不稳定性和性能不一致问题，推动混合物理-AI气候模拟的发展。

Method: 将Kaggle竞赛获胜团队的机器学习架构耦合到包含完整云微物理的交互式气候模型中，系统评估其在线性能。

Result: 所有测试架构都表现出相似的离线和在线偏差，但不同架构对设计选择的响应差异显著。多个Kaggle启发架构在特定指标上达到了最先进水平。

Conclusion: 众包离线问题的本质是改善混合物理-AI气候模拟在线性能的一条可行路径，在线稳定性在低分辨率真实地理环境下是可重现的关键里程碑。

Abstract: Subgrid machine-learning (ML) parameterizations have the potential to introduce a new generation of climate models that incorporate the effects of higher-resolution physics without incurring the prohibitive computational cost associated with more explicit physics-based simulations. However, important issues, ranging from online instability to inconsistent online performance, have limited their operational use for long-term climate projections. To more rapidly drive progress in solving these issues, domain scientists and machine learning researchers opened up the offline aspect of this problem to the broader machine learning and data science community with the release of ClimSim, a NeurIPS Datasets and Benchmarks publication, and an associated Kaggle competition. This paper reports on the downstream results of the Kaggle competition by coupling emulators inspired by the winning teams' architectures to an interactive climate model (including full cloud microphysics, a regime historically prone to online instability) and systematically evaluating their online performance. Our results demonstrate that online stability in the low-resolution, real-geography setting is reproducible across multiple diverse architectures, which we consider a key milestone. All tested architectures exhibit strikingly similar offline and online biases, though their responses to architecture-agnostic design choices (e.g., expanding the list of input variables) can differ significantly. Multiple Kaggle-inspired architectures achieve state-of-the-art (SOTA) results on certain metrics such as zonal mean bias patterns and global RMSE, indicating that crowdsourcing the essence of the offline problem is one path to improving online performance in hybrid physics-AI climate simulation.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [5] [Event-driven eligibility propagation in large sparse networks: efficiency shaped by biological realism](https://arxiv.org/abs/2511.21674)
*Agnes Korcsak-Gorzo,Jesús A. Espinoza Valverde,Jonas Stapmanns,Hans Ekkehard Plesser,David Dahmen,Matthias Bolten,Sacha J. van Albada,Markus Diesmann*

Main category: cs.NE

TL;DR: 提出了一个基于生物启发的扩展资格传播学习规则，用于脉冲神经网络，将时间驱动更新转换为事件驱动，并整合到大规模脉冲神经网络模拟平台中。


<details>
  <summary>Details</summary>
Motivation: 尽管技术进步显著，AI系统仍可从生物原理中受益，如循环连接和能量高效机制。受大脑启发，开发更生物合理的算法。

Method: 扩展e-prop学习规则，将其从时间驱动转换为事件驱动更新，集成到大规模脉冲神经网络模拟平台，并加入连续动态、严格局部性、稀疏连接等生物特征。

Result: 在神经形态MNIST等任务上验证了方法的适用性，能够扩展到数百万神经元而不影响学习性能。

Conclusion: 生物基础约束可以为计算高效的AI算法设计提供信息，这项工作连接了机器学习和计算神经科学，为可持续的生物启发AI系统铺平道路。

Abstract: Despite remarkable technological advances, AI systems may still benefit from biological principles, such as recurrent connectivity and energy-efficient mechanisms. Drawing inspiration from the brain, we present a biologically plausible extension of the eligibility propagation (e-prop) learning rule for recurrent spiking networks. By translating the time-driven update scheme into an event-driven one, we integrate the learning rule into a simulation platform for large-scale spiking neural networks and demonstrate its applicability to tasks such as neuromorphic MNIST. We extend the model with prominent biological features such as continuous dynamics and weight updates, strict locality, and sparse connectivity. Our results show that biologically grounded constraints can inform the design of computationally efficient AI algorithms, offering scalability to millions of neurons without compromising learning performance. This work bridges machine learning and computational neuroscience, paving the way for sustainable, biologically inspired AI systems while advancing our understanding of brain-like learning.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [6] [Foundry: Distilling 3D Foundation Models for the Edge](https://arxiv.org/abs/2511.20721)
*Guillaume Letellier,Siddharth Srivastava,Frédéric Jurie,Gaurav Sharma*

Main category: cs.CV

TL;DR: 提出Foundation Model Distillation (FMD)新范式，通过压缩大型SSL模型创建紧凑高效的代理模型，保留通用表征能力。实现Foundry系统用于3D点云，训练学生学习压缩的SuperTokens来重建教师模型的表征。


<details>
  <summary>Details</summary>
Motivation: 基础模型虽然强大但计算成本高，难以在边缘设备部署。现有压缩技术会牺牲模型的通用性，需要一种能保持通用表征能力的压缩方法。

Method: 使用Foundation Model Distillation (FMD)范式，训练学生模型学习压缩的SuperTokens来重建教师模型的token级表征，捕捉潜在空间的紧凑基向量。

Result: 单个蒸馏模型在分类、部分分割和少样本场景等多样化下游任务中保持强迁移性，接近完整基础模型性能，同时显著减少token数量和FLOPs。

Conclusion: FMD能够创建紧凑高效的代理模型，保留基础模型的通用表征能力，使其更适合在资源受限的硬件上部署。

Abstract: Foundation models pre-trained with self-supervised learning (SSL) on large-scale datasets have become powerful general-purpose feature extractors. However, their immense size and computational cost make them prohibitive for deployment on edge devices such as robots and AR/VR headsets. Existing compression techniques like standard knowledge distillation create efficient 'specialist' models but sacrifice the crucial, downstream-agnostic generality that makes foundation models so valuable.  In this paper, we introduce Foundation Model Distillation (FMD), a new paradigm for compressing large SSL models into compact, efficient, and faithful proxies that retain their general-purpose representational power. We present Foundry, the first implementation of FMD for 3D point clouds. Our approach, Foundry, trains a student to learn a compressed set of SuperTokens that reconstruct the teacher's token-level representations, capturing a compact basis of its latent space. A single distilled model maintains strong transferability across diverse downstream tasks-classification, part segmentation, and few-shot scenarios-approaching full foundation-model performance while using significantly fewer tokens and FLOPs, making such models more practical for deployment on resourceconstrained hardware.

</details>


### [7] [Are Neuro-Inspired Multi-Modal Vision-Language Models Resilient to Membership Inference Privacy Leakage?](https://arxiv.org/abs/2511.20710)
*David Amebley,Sayanton Dibbo*

Main category: cs.CV

TL;DR: 本文提出了一种神经科学启发的拓扑正则化框架，用于增强多模态视觉语言模型对成员推断攻击的隐私保护能力，在保持模型效用的同时显著降低攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 随着多模态模型的广泛应用，其训练数据隐私泄露风险日益突出。现有研究主要关注单模态系统的隐私攻击，而多模态模型的隐私脆弱性及其与神经科学启发的模型结构之间的关系尚未被充分探索。

Method: 引入系统性的神经科学启发的拓扑正则化框架(tau)，在三种视觉语言模型(BLIP、PaliGemma 2、ViT-GPT2)上应用该正则化，并在三个基准数据集(COCO、CC3M、NoCaps)上评估其对成员推断攻击的防御能力。

Result: 实验结果显示，在BLIP模型上，神经启发的VLM变体使MIA攻击成功率平均ROC-AUC下降24%，同时保持相似的模型效用(MPNet和ROUGE-2指标)。在其他模型和数据集上的广泛评估进一步验证了发现的稳定性。

Conclusion: 神经启发的多模态视觉语言模型在保持模型效用的同时，对隐私攻击具有更强的抵御能力，为理解多模态模型的隐私风险提供了重要证据。

Abstract: In the age of agentic AI, the growing deployment of multi-modal models (MMs) has introduced new attack vectors that can leak sensitive training data in MMs, causing privacy leakage. This paper investigates a black-box privacy attack, i.e., membership inference attack (MIA) on multi-modal vision-language models (VLMs). State-of-the-art research analyzes privacy attacks primarily to unimodal AI-ML systems, while recent studies indicate MMs can also be vulnerable to privacy attacks. While researchers have demonstrated that biologically inspired neural network representations can improve unimodal model resilience against adversarial attacks, it remains unexplored whether neuro-inspired MMs are resilient against privacy attacks. In this work, we introduce a systematic neuroscience-inspired topological regularization (tau) framework to analyze MM VLMs resilience against image-text-based inference privacy attacks. We examine this phenomenon using three VLMs: BLIP, PaliGemma 2, and ViT-GPT2, across three benchmark datasets: COCO, CC3M, and NoCaps. Our experiments compare the resilience of baseline and neuro VLMs (with topological regularization), where the tau > 0 configuration defines the NEURO variant of VLM. Our results on the BLIP model using the COCO dataset illustrate that MIA attack success in NEURO VLMs drops by 24% mean ROC-AUC, while achieving similar model utility (similarities between generated and reference captions) in terms of MPNet and ROUGE-2 metrics. This shows neuro VLMs are comparatively more resilient against privacy attacks, while not significantly compromising model utility. Our extensive evaluation with PaliGemma 2 and ViT-GPT2 models, on two additional datasets: CC3M and NoCaps, further validates the consistency of the findings. This work contributes to the growing understanding of privacy risks in MMs and provides evidence on neuro VLMs privacy threat resilience.

</details>


### [8] [Inferix: A Block-Diffusion based Next-Generation Inference Engine for World Simulation](https://arxiv.org/abs/2511.20714)
*Inferix Team,Tianyu Feng,Yizeng Han,Jiahao He,Yuanyu He,Xi Lin,Teng Liu,Hanfeng Lu,Jiasheng Tang,Wei Wang,Zhiyuan Wang,Jichao Wu,Mingyang Yang,Yinghao Yu,Zeyu Zhang,Bohan Zhuang*

Main category: cs.CV

TL;DR: Inferix是一个专为世界模型设计的下一代推理引擎，通过优化的半自回归解码实现沉浸式世界合成，支持交互式视频流和精细评估。


<details>
  <summary>Details</summary>
Motivation: 世界模型是智能体AI、具身AI和游戏领域的核心模拟器，能够生成高质量的长视频。扩展这些模型可以解锁视觉感知、理解和推理的新兴能力，超越当前以LLM为中心的视觉基础模型。

Method: 采用半自回归（块扩散）解码范式，结合扩散和自回归方法的优势，在每个块内应用扩散生成视频令牌，同时以前一个块为条件，实现更连贯稳定的视频序列。通过重新引入LLM风格的KV缓存管理，克服标准视频扩散的限制。

Result: Inferix专门设计用于世界模拟，与高并发系统（如vLLM）和经典视频扩散模型（如xDiTs）不同，支持高效、可变长度和高质量生成。

Conclusion: Inferix通过优化的半自回归解码、交互式视频流和LV-Bench集成，为世界模型探索提供了专门的推理引擎，希望社区共同推进这一方向。

Abstract: World models serve as core simulators for fields such as agentic AI, embodied AI, and gaming, capable of generating long, physically realistic, and interactive high-quality videos. Moreover, scaling these models could unlock emergent capabilities in visual perception, understanding, and reasoning, paving the way for a new paradigm that moves beyond current LLM-centric vision foundation models. A key breakthrough empowering them is the semi-autoregressive (block-diffusion) decoding paradigm, which merges the strengths of diffusion and autoregressive methods by generating video tokens in block-applying diffusion within each block while conditioning on previous ones, resulting in more coherent and stable video sequences. Crucially, it overcomes limitations of standard video diffusion by reintroducing LLM-style KV Cache management, enabling efficient, variable-length, and high-quality generation.
  Therefore, Inferix is specifically designed as a next-generation inference engine to enable immersive world synthesis through optimized semi-autoregressive decoding processes. This dedicated focus on world simulation distinctly sets it apart from systems engineered for high-concurrency scenarios (like vLLM or SGLang) and from classic video diffusion models (such as xDiTs). Inferix further enhances its offering with interactive video streaming and profiling, enabling real-time interaction and realistic simulation to accurately model world dynamics. Additionally, it supports efficient benchmarking through seamless integration of LV-Bench, a new fine-grained evaluation benchmark tailored for minute-long video generation scenarios. We hope the community will work together to advance Inferix and foster world model exploration.

</details>


### [9] [Video Object Recognition in Mobile Edge Networks: Local Tracking or Edge Detection?](https://arxiv.org/abs/2511.20716)
*Kun Guo,Yun Shen,Xijun Wang,Chaoqun You,Yun Rui,Tony Q. S. Quek*

Main category: cs.CV

TL;DR: 提出LTED-Ada算法，在移动边缘计算环境中自适应选择本地跟踪或边缘检测，通过深度强化学习优化视频对象识别的准确性和延迟要求。


<details>
  <summary>Details</summary>
Motivation: 资源受限设备（如交通摄像头）进行视频对象识别时面临挑战，需要平衡边缘检测的高精度和本地跟踪的低延迟。

Method: 基于深度强化学习，在单设备场景提出LTED-Ada算法，在多设备场景结合联邦学习进行协作策略训练。

Result: 通过硬件在环实验验证了LTED-Ada的优越性，能够适应不同的帧率和性能要求。

Conclusion: LTED-Ada算法有效解决了移动边缘网络中视频对象识别的自适应决策问题，在单设备和多设备场景下均表现出色。

Abstract: Fast and accurate video object recognition, which relies on frame-by-frame video analytics, remains a challenge for resource-constrained devices such as traffic cameras. Recent advances in mobile edge computing have made it possible to offload computation-intensive object detection to edge servers equipped with high-accuracy neural networks, while lightweight and fast object tracking algorithms run locally on devices. This hybrid approach offers a promising solution but introduces a new challenge: deciding when to perform edge detection versus local tracking. To address this, we formulate two long-term optimization problems for both single-device and multi-device scenarios, taking into account the temporal correlation of consecutive frames and the dynamic conditions of mobile edge networks. Based on the formulation, we propose the LTED-Ada in single-device setting, a deep reinforcement learning-based algorithm that adaptively selects between local tracking and edge detection, according to the frame rate as well as recognition accuracy and delay requirement. In multi-device setting, we further enhance LTED-Ada using federated learning to enable collaborative policy training across devices, thereby improving its generalization to unseen frame rates and performance requirements. Finally, we conduct extensive hardware-in-the-loop experiments using multiple Raspberry Pi 4B devices and a personal computer as the edge server, demonstrating the superiority of LTED-Ada.

</details>


### [10] [DeeAD: Dynamic Early Exit of Vision-Language Action for Efficient Autonomous Driving](https://arxiv.org/abs/2511.20720)
*Haibo HU,Lianming Huang,Nan Guan,Chun Jason Xue*

Main category: cs.CV

TL;DR: DeeAD是一个无需训练的早期退出框架，通过评估中间轨迹的物理可行性来加速视觉语言动作模型的推理，在保持规划质量的同时实现高达28%的层稀疏度和29%的延迟降低。


<details>
  <summary>Details</summary>
Motivation: 视觉语言动作模型在自动驾驶中统一了感知、推理和轨迹生成，但由于深度transformer堆栈导致推理延迟显著。

Method: 提出基于动作引导的早期退出框架，当预测轨迹与轻量级规划先验（如导航或低精度规划）在可容忍偏差内对齐时终止推理，并引入多跳控制器自适应跳过冗余层。

Result: 在Bench2Drive基准测试中实现了28%的transformer层稀疏度和29%的延迟降低，同时保持了规划质量和安全性。

Conclusion: DeeAD框架无需重新训练即可集成到现有VLA模型中，有效加速推理过程，为自动驾驶规划提供了高效的解决方案。

Abstract: Vision-Language Action (VLA) models unify perception, reasoning, and trajectory generation for autonomous driving, but suffer from significant inference latency due to deep transformer stacks. We present DeeAD, a training-free, action-guided early-exit framework that accelerates VLA planning by evaluating the physical feasibility of intermediate trajectories. Instead of relying on confidence scores, DeeAD terminates inference when predicted trajectories align with lightweight planning priors (e.g., Navigation or Low-precision Planning) within a tolerable deviation (<2m). To improve efficiency, we introduce a multi-hop controller that adaptively skips redundant layers based on the change rate of scores. DeeAD integrates into existing VLA models, such as ORION, without requiring retraining. Experiments on the Bench2Drive benchmark demonstrate up to 28% transformer-layer sparsity and 29% latency reduction, while preserving planning quality and safety.

</details>


### [11] [DinoLizer: Learning from the Best for Generative Inpainting Localization](https://arxiv.org/abs/2511.20722)
*Minh Thong Doi,Jan Butora,Vincent Itier,Jérémie Boulanger,Patrick Bas*

Main category: cs.CV

TL;DR: DinoLizer是基于DINOv2的模型，用于定位生成式修复图像中的篡改区域。该方法在DINOv2模型上添加线性分类头，通过滑动窗口策略处理大图像，在多个修复数据集上超越现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 开发能够准确定位生成式修复图像中篡改区域的检测器，解决现有方法在语义篡改检测方面的不足。

Method: 在预训练的DINOv2模型上添加线性分类头，使用滑动窗口策略处理大尺寸图像，通过后处理优化二值篡改掩码。

Result: 在多个修复数据集上，DinoLizer比次优模型平均IoU提高12%，对常见后处理操作（如调整大小、噪声添加、JPEG压缩）保持鲁棒性。

Conclusion: DinoLizer证明了Vision Transformers在篡改定位任务中的强大表示能力，并通过与DINOv3的对比研究确认了其优越性。

Abstract: We introduce DinoLizer, a DINOv2-based model for localizing manipulated regions in generative inpainting. Our method builds on a DINOv2 model pretrained to detect synthetic images on the B-Free dataset. We add a linear classification head on top of the Vision Transformer's patch embeddings to predict manipulations at a $14\times 14$ patch resolution. The head is trained to focus on semantically altered regions, treating non-semantic edits as part of the original content. Because the ViT accepts only fixed-size inputs, we use a sliding-window strategy to aggregate predictions over larger images; the resulting heatmaps are post-processed to refine the estimated binary manipulation masks. Empirical results show that DinoLizer surpasses state-of-the-art local manipulation detectors on a range of inpainting datasets derived from different generative models. It remains robust to common post-processing operations such as resizing, noise addition, and JPEG (double) compression. On average, DinoLizer achieves a 12\% higher Intersection-over-Union (IoU) than the next best model, with even greater gains after post-processing. Our experiments with off-the-shelf DINOv2 demonstrate the strong representational power of Vision Transformers for this task. Finally, extensive ablation studies comparing DINOv2 and its successor, DINOv3, in deepfake localization confirm DinoLizer's superiority. The code will be publicly available upon acceptance of the paper.

</details>


### [12] [CANVAS: A Benchmark for Vision-Language Models on Tool-Based User Interface Design](https://arxiv.org/abs/2511.20737)
*Daeheon Jeong,Seoyeon Byun,Kihoon Son,Dae Hyun Kim,Juho Kim*

Main category: cs.CV

TL;DR: CANVAS是一个评估视觉语言模型在工具调用基础上进行用户界面设计的基准测试，包含598个设计任务，涵盖设计复制和设计修改两种任务类型。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏评估基于工具的设计性能的基准测试，而理解视觉语言模型在设计软件中迭代编辑UI设计的能力对于其与设计师协作的潜力至关重要。

Method: 构建包含598个工具设计任务的基准测试，任务基于3.3K移动UI设计，涵盖30个功能类别，包含设计复制和设计修改两种任务类型，模型通过上下文工具调用逐步更新设计。

Result: 领先模型展现出更具策略性的工具调用，提高了设计质量，同时识别了模型常见的错误模式。

Conclusion: CANVAS基准测试为评估和提升基于工具的设计能力提供了重要基础，指导未来在增强工具设计能力方面的工作。

Abstract: User interface (UI) design is an iterative process in which designers progressively refine their work with design software such as Figma or Sketch. Recent advances in vision language models (VLMs) with tool invocation suggest these models can operate design software to edit a UI design through iteration. Understanding and enhancing this capacity is important, as it highlights VLMs' potential to collaborate with designers within conventional software. However, as no existing benchmark evaluates tool-based design performance, the capacity remains unknown. To address this, we introduce CANVAS, a benchmark for VLMs on tool-based user interface design. Our benchmark contains 598 tool-based design tasks paired with ground-truth references sampled from 3.3K mobile UI designs across 30 function-based categories (e.g., onboarding, messaging). In each task, a VLM updates the design step-by-step through context-based tool invocations (e.g., create a rectangle as a button background), linked to design software. Specifically, CANVAS incorporates two task types: (i) design replication evaluates the ability to reproduce a whole UI screen; (ii) design modification evaluates the ability to modify a specific part of an existing screen. Results suggest that leading models exhibit more strategic tool invocations, improving design quality. Furthermore, we identify common error patterns models exhibit, guiding future work in enhancing tool-based design capabilities.

</details>


### [13] [Text-Guided Semantic Image Encoder](https://arxiv.org/abs/2511.20770)
*Raghuveer Thirukovalluru,Xiaochuang Han,Bhuwan Dhingra,Emily Dinan,Maha Elbayad*

Main category: cs.CV

TL;DR: 提出文本引导语义图像编码器(TIE)，使视觉语言模型中的图像编码器能够根据文本查询生成条件化的图像表示，显著提升多模态任务性能并提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 传统视觉语言模型中的图像编码器通常独立预训练，与语言模型对齐后仍以任务无关方式处理图像，无法根据具体下游任务或文本查询进行优化。

Method: 开发文本引导语义图像编码器(TIE)，通过文本条件化训练使图像编码器能够根据输入文本查询生成相应的图像表示。

Result: 在1B和3B规模下，TIE增强的视觉语言模型在9个图像到文本基准测试中平均提升1.5和1.3个百分点，在DocVQA和InfoVQA等任务上提升高达6个百分点，同时仅使用一半图像块即可达到更好性能。

Conclusion: 文本条件化训练有效优化编码器以捕捉关键视觉特征，TIE能够持续关注查询相关区域，增强可解释性和查询特定基础能力，且具有良好的泛化性能。

Abstract: Image encoders, a fundamental component of vision-language models (VLMs), are typically pretrained independently before being aligned with a language model. This standard paradigm results in encoders that process images agnostically, without regard to the specific downstream task or text query. To address this limitation, we propose the Text-Guided Semantic Image Encoder (TIE), which generates image representations conditioned on the input text query. VLMs equipped with TIE outperform their conventional counterparts by +1.5 and +1.3 points on average across nine image-to-text benchmarks at the 1B and 3B scales, respectively, with gains reaching up to 6 points on tasks such as DocVQA and InfoVQA. Moreover, TIE-based VLMs attain superior performance while utilizing only half as many image tiles (tokens), resulting in notably improved inference efficiency. TIE also generalizes well with generic queries, indicating that text-conditioned training effectively optimizes the encoder to capture key visual features. Qualitative analysis confirms that TIE consistently attends to query-relevant regions, enhancing both interpretability and query-specific grounding.

</details>


### [14] [One Patch is All You Need: Joint Surface Material Reconstruction and Classification from Minimal Visual Cues](https://arxiv.org/abs/2511.20784)
*Sindhuja Penchala,Gavin Money,Gabriel Marques,Samuel Wood,Jessica Kirschman,Travis Atkison,Shahram Rahimi,Noorbakhsh Amiri Golilarz*

Main category: cs.CV

TL;DR: SMARC是一个从最小视觉输入进行表面材料重建和分类的统一模型，仅需单个10%连续图像块即可识别和重建完整RGB表面并分类材料类别。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖密集或全场景观测，在受限或部分视角环境中效果有限，需要从稀疏视觉线索理解材料表面的解决方案。

Method: 结合部分卷积U-Net和分类头的架构，在极端观测稀疏条件下实现空间修复和语义理解，使用Touch and Go真实世界表面纹理数据集。

Result: 在五个模型比较中达到最先进性能：PSNR 17.55 dB，材料分类准确率85.10%。

Conclusion: 部分卷积在缺失数据空间推理中具有优势，为最小视觉表面理解奠定了坚实基础。

Abstract: Understanding material surfaces from sparse visual cues is critical for applications in robotics, simulation, and material perception. However, most existing methods rely on dense or full-scene observations, limiting their effectiveness in constrained or partial view environment. To address this challenge, we introduce SMARC, a unified model for Surface MAterial Reconstruction and Classification from minimal visual input. By giving only a single 10% contiguous patch of the image, SMARC recognizes and reconstructs the full RGB surface while simultaneously classifying the material category. Our architecture combines a Partial Convolutional U-Net with a classification head, enabling both spatial inpainting and semantic understanding under extreme observation sparsity. We compared SMARC against five models including convolutional autoencoders [17], Vision Transformer (ViT) [13], Masked Autoencoder (MAE) [5], Swin Transformer [9], and DETR [2] using Touch and Go dataset [16] of real-world surface textures. SMARC achieves state-of-the-art results with a PSNR of 17.55 dB and a material classification accuracy of 85.10%. Our findings highlight the advantages of partial convolution in spatial reasoning under missing data and establish a strong foundation for minimal-vision surface understanding.

</details>


### [15] [LongVT: Incentivizing "Thinking with Long Videos" via Native Tool Calling](https://arxiv.org/abs/2511.20785)
*Zuhao Yang,Sudong Wang,Kaichen Zhang,Keming Wu,Sicong Leng,Yifan Zhang,Chengwei Qin,Shijian Lu,Xingxuan Li,Lidong Bing*

Main category: cs.CV

TL;DR: LongVT是一个端到端的智能体框架，通过多模态工具链思维实现长视频推理，利用LMMs的时序定位能力作为原生视频裁剪工具，采用全局到局部的推理循环来减少幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型在处理长视频时容易产生幻觉，因为证据稀疏且时间分散。受人类理解长视频的方式启发（先全局浏览再检查相关片段），需要开发能够进行精细推理的框架。

Method: 利用LMMs的时序定位能力作为视频裁剪工具，通过全局到局部的推理循环逐步细化视频帧采样。采用三阶段训练策略：工具集成的冷启动监督微调、智能体强化学习和智能体强化微调。

Result: 在四个具有挑战性的长视频理解和推理基准测试中，LongVT始终优于现有强基线模型。

Conclusion: LongVT框架通过多模态工具链思维和全局到局部的推理循环，有效解决了长视频推理中的幻觉问题，为长视频理解任务提供了有效的解决方案。

Abstract: Large multimodal models (LMMs) have shown great potential for video reasoning with textual Chain-of-Thought. However, they remain vulnerable to hallucinations, especially when processing long-form videos where evidence is sparse and temporally dispersed. Inspired by how humans comprehend long videos - by first skimming globally and then examining relevant clips for details - we introduce LongVT, an end-to-end agentic framework that enables "Thinking with Long Videos" via interleaved Multimodal Chain-of-Tool-Thought. Specifically, we exploit LMMs' inherent temporal grounding ability as a native video cropping tool to zoom in on a specific video clip and resample finer-grained video frames. This global-to-local reasoning loop continues until answers are grounded in retrieved visual evidence. Given the scarcity of fine-grained question-answering (QA) data for the long video reasoning task, we curate and will release a data suite named VideoSIAH to facilitate both training and evaluation. Specifically, our training dataset consists of 247.9K samples for tool-integrated cold-start supervised fine-tuning, 1.6K samples for agentic reinforcement learning, and 15.4K samples for agentic reinforcement fine-tuning, respectively. Our evaluation benchmark consists of 1,280 QA pairs that are carefully curated through a semi-automatic data pipeline with human-in-the-loop validation. With a meticulously designed three-stage training strategy and extensive empirical validation, LongVT consistently outperforms existing strong baselines across four challenging long-video understanding and reasoning benchmarks. Our codes, data, and model checkpoints are publicly available at https://github.com/EvolvingLMMs-Lab/LongVT .

</details>


### [16] [Revisiting KRISP: A Lightweight Reproduction and Analysis of Knowledge-Enhanced Vision-Language Models](https://arxiv.org/abs/2511.20795)
*Souradeep Dutta,Keshav Bulia,Neena S Nair*

Main category: cs.CV

TL;DR: 本文重新审视了KRISP知识增强视觉问答模型，提出了一个参数更少的轻量级复现版本，虽然性能约为原版的75%，但揭示了原模型的设计缺陷和实际问题，并在资源受限条件下验证了知识增强VQA架构的可扩展性和有效性。


<details>
  <summary>Details</summary>
Motivation: 原版KRISP模型虽然有效，但需要工业级训练规模、计算需求大且与大型骨干网络紧密耦合。本文旨在开发一个轻量级版本，使其能在边缘设备上运行，并揭示原模型未充分讨论的设计问题。

Method: 通过系统消融研究，包括在合成VQA数据上的概念验证和在DAQUAR数据集上的评估，重新设计了一个参数较少的轻量级KRISP模型，并约束在外部知识图谱领域内以防止AI幻觉。

Result: 复现的轻量级模型性能约为原版的75%，但能够揭示原模型的设计缺陷和实际问题。模型在资源受限条件下仍能有效工作，可在智能手机和AR-VR等边缘设备上离线运行。

Conclusion: 轻量级知识增强VQA架构在资源受限条件下具有可行性，能够防止AI幻觉并生成限定领域内的输出，为边缘设备上的视觉推理应用提供了实用解决方案。

Abstract: Facebook AI Research introduced KRISP [4], which integrates structured external knowledge into pipelines for vision-language reasoning. Despite its effectiveness, the original model has been developed for industrial-scale training, is computationally demanding, and is tightly connected to a large backbone. In this work, we reexamine KRISP from a different angle and offer a lightweight reproduction with significantly fewer parameters. Even though our replicated model performs about 75 % of the original, the replication process uncovers a number of design flaws, real-world pitfalls, and implicit problems that were not fully covered in the original paper. We offer insights into the scalability and efficacy of knowledge-enhanced VQA architectures under resource constraints through systematic ablation studies, which include a proof-of-concept on synthetic VQA data and evaluation on the DAQUAR dataset. Our model, configured with a low parameter setup and constrained by the external Knowledge graph domain, prevents AI hallucinations and generates outputs solely within that domain. Minimal parameters allow us to function on edge devices like smartphones and AR-VR, further improving offline visual reasoning.

</details>


### [17] [Intriguing Properties of Dynamic Sampling Networks](https://arxiv.org/abs/2511.20800)
*Dario Morle,Reid Zaffino*

Main category: cs.CV

TL;DR: 本文提出了一种名为"warping"的新型算子，统一分析了深度学习中各种动态采样机制，揭示了前向传播与反向传播之间的不对称性，并提供了确保动态采样网络稳定训练的条件。


<details>
  <summary>Details</summary>
Motivation: 深度学习架构中的动态采样机制在计算机视觉模型中已证明有效，但这些结构的理论分析尚未统一。本文旨在通过开发可分析的新型算子来连接各种动态采样方法。

Method: 提出了"warping"算子作为动态采样的最小实现，能够重构现有架构如可变形卷积、主动卷积单元和空间变换网络。通过将输入建模为IID变量和齐次随机场进行统计分析，并引入基于梯度更新信息的损失景观可视化方法。

Result: 发现动态采样机制代表了一类与传统平移不变卷积算子完全不同的正交算子类别。揭示了前向传播与反向传播之间的独特不对称性，并确定了确保动态采样网络稳定训练的必要条件。

Conclusion: warping算子为动态采样方法提供了统一的理论框架，通过理论分析和实证研究揭示了这些机制的本质特性，为理解动态采样网络的学习行为提供了新视角。

Abstract: Dynamic sampling mechanisms in deep learning architectures have demonstrated utility across many computer vision models, though the theoretical analysis of these structures has not yet been unified. In this paper we connect the various dynamic sampling methods by developing and analyzing a novel operator which generalizes existing methods, which we term "warping". Warping provides a minimal implementation of dynamic sampling which is amenable to analysis, and can be used to reconstruct existing architectures including deformable convolutions, active convolutional units, and spatial transformer networks. Using our formalism, we provide statistical analysis of the operator by modeling the inputs as both IID variables and homogeneous random fields. Extending this analysis, we discover a unique asymmetry between the forward and backward pass of the model training. We demonstrate that these mechanisms represent an entirely different class of orthogonal operators to the traditional translationally invariant operators defined by convolutions. With a combination of theoretical analysis and empirical investigation, we find the conditions necessary to ensure stable training of dynamic sampling networks. In addition, statistical analysis of discretization effects are studied. Finally, we introduce a novel loss landscape visualization which utilizes gradient update information directly, to better understand learning behavior.

</details>


### [18] [$Δ$-NeRF: Incremental Refinement of Neural Radiance Fields through Residual Control and Knowledge Transfer](https://arxiv.org/abs/2511.20804)
*Kriti Ghosh,Devjyoti Chakraborty,Lakshmish Ramaswamy,Suchendra M. Bhandarkar,In Kee Kim,Nancy O'Hare,Deepak Mishra*

Main category: cs.CV

TL;DR: Δ-NeRF提出了一种模块化残差框架，用于神经辐射场的增量优化，解决了现有方法需要完整重训练和灾难性遗忘的问题，特别适用于卫星地形分析等数据顺序到达的场景。


<details>
  <summary>Details</summary>
Motivation: 现有NeRF框架在引入新视图时需要完整重训练，限制了在数据顺序到达场景（如卫星地形分析）中的应用。增量优化方法存在灾难性遗忘问题，且过去数据不可用时难以有效优化。

Method: 提出Δ-NeRF框架，包含：残差控制器向冻结的基础NeRF注入逐层修正；不确定性感知门控机制自适应结合基础和优化预测；视图选择策略减少47%训练数据；知识蒸馏将增强模型压缩至原大小20%。

Result: 在卫星图像上，Δ-NeRF性能与联合训练相当，训练时间减少30-42%。相比朴素微调PSNR提升43.5%，在某些指标上超越联合训练。

Conclusion: Δ-NeRF为NeRF的增量优化提供了有效解决方案，在保持性能的同时显著提升效率，特别适用于卫星地形分析等顺序数据场景。

Abstract: Neural Radiance Fields (NeRFs) have demonstrated remarkable capabilities in 3D reconstruction and novel view synthesis. However, most existing NeRF frameworks require complete retraining when new views are introduced incrementally, limiting their applicability in domains where data arrives sequentially. This limitation is particularly problematic in satellite-based terrain analysis, where regions are repeatedly observed over time. Incremental refinement of NeRFs remains underexplored, and naive approaches suffer from catastrophic forgetting when past data is unavailable. We propose $Δ$-NeRF, a unique modular residual framework for incremental NeRF refinement. $Δ$-NeRF introduces several novel techniques including: (1) a residual controller that injects per-layer corrections into a frozen base NeRF, enabling refinement without access to past data; (2) an uncertainty-aware gating mechanism that prevents overcorrection by adaptively combining base and refined predictions; and (3) a view selection strategy that reduces training data by up to 47\% while maintaining performance. Additionally, we employ knowledge distillation to compress the enhanced model into a compact student network (20\% of original size). Experiments on satellite imagery demonstrate that $Δ$-NeRF achieves performance comparable to joint training while reducing training time by 30-42\%. $Δ$-NeRF consistently outperforms existing baselines, achieving an improvement of up to 43.5\% in PSNR over naive fine-tuning and surpassing joint training on some metrics.

</details>


### [19] [Layer-Aware Video Composition via Split-then-Merge](https://arxiv.org/abs/2511.20809)
*Ozgur Kara,Yujia Chen,Ming-Hsuan Yang,James M. Rehg,Wen-Sheng Chu,Du Tran*

Main category: cs.CV

TL;DR: 提出Split-then-Merge (StM)框架，通过将未标注视频分割为前景和背景层并进行自组合学习，解决生成视频合成的控制问题和数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖标注数据集或手工规则，难以学习动态主体与多样化场景的复杂交互关系，且面临数据稀缺问题。

Method: 将未标注视频分割为动态前景和背景层，通过自组合学习主体与场景的交互；采用变换感知训练管道，结合多层融合增强和身份保持损失，实现感知能力感知的合成。

Result: 在定量基准测试和人类/VLLM定性评估中均优于现有最优方法。

Conclusion: StM框架有效解决了生成视频合成的控制挑战，通过学习前景背景的交互关系实现了更真实的视频生成。

Abstract: We present Split-then-Merge (StM), a novel framework designed to enhance control in generative video composition and address its data scarcity problem. Unlike conventional methods relying on annotated datasets or handcrafted rules, StM splits a large corpus of unlabeled videos into dynamic foreground and background layers, then self-composes them to learn how dynamic subjects interact with diverse scenes. This process enables the model to learn the complex compositional dynamics required for realistic video generation. StM introduces a novel transformation-aware training pipeline that utilizes a multi-layer fusion and augmentation to achieve affordance-aware composition, alongside an identity-preservation loss that maintains foreground fidelity during blending. Experiments show StM outperforms SoTA methods in both quantitative benchmarks and in humans/VLLM-based qualitative evaluations. More details are available at our project page: https://split-then-merge.github.io

</details>


### [20] [SPHINX: A Synthetic Environment for Visual Perception and Reasoning](https://arxiv.org/abs/2511.20814)
*Md Tanvirul Alam,Saksham Aggarwal,Justin Yang Chae,Nidhi Rastogi*

Main category: cs.CV

TL;DR: Sphinx是一个针对视觉感知和推理核心认知原语的合成环境，通过程序化生成包含图案、图块、图表、图标和几何原语的谜题，并配有可验证的真实解，支持精确评估和大规模数据集构建。


<details>
  <summary>Details</summary>
Motivation: 当前视觉推理任务缺乏能够精确评估核心认知能力的基准测试，需要构建一个能够系统评估视觉感知和推理能力的合成环境。

Method: 使用程序化生成方法创建包含25种任务类型的谜题，涵盖对称检测、几何变换、空间推理、图表解释和序列预测等认知原语，每个谜题都配有可验证的真实解。

Result: 评估显示即使是当前最先进的GPT-5模型在Sphinx基准上仅达到51.1%准确率，远低于人类表现。使用可验证奖励的强化学习（RLVR）能显著提升模型在这些任务上的准确性。

Conclusion: Sphinx基准有效揭示了当前视觉语言模型在核心认知能力上的局限性，而RLVR方法展示了提升多模态推理能力的潜力。

Abstract: We present Sphinx, a synthetic environment for visual perception and reasoning that targets core cognitive primitives. Sphinx procedurally generates puzzles using motifs, tiles, charts, icons, and geometric primitives, each paired with verifiable ground-truth solutions, enabling both precise evaluation and large-scale dataset construction. The benchmark covers 25 task types spanning symmetry detection, geometric transformations, spatial reasoning, chart interpretation, and sequence prediction. Evaluating recent large vision-language models (LVLMs) shows that even state-of-the-art GPT-5 attains only 51.1% accuracy, well below human performance. Finally, we demonstrate that reinforcement learning with verifiable rewards (RLVR) substantially improves model accuracy on these tasks and yields gains on external visual reasoning benchmarks, highlighting its promise for advancing multimodal reasoning.

</details>


### [21] [Training-Free Diffusion Priors for Text-to-Image Generation via Optimization-based Visual Inversion](https://arxiv.org/abs/2511.20821)
*Samuele Dell'Erba,Andrew D. Bagdanov*

Main category: cs.CV

TL;DR: 提出了一种基于优化的视觉反转(OVI)方法，无需训练即可替代传统扩散先验网络，通过优化潜在视觉表示来匹配文本嵌入，并引入两种约束提升图像质量。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型依赖计算昂贵的先验网络，需要大量训练数据。本研究挑战这种必要性，寻求无需训练和数据的替代方案。

Method: 使用优化视觉反转(OVI)方法，从随机伪标记初始化潜在表示，通过迭代优化最大化与文本嵌入的余弦相似度。提出马氏距离和最近邻损失两种约束来正则化优化过程。

Result: 在Kandinsky 2.2上的实验表明OVI可替代传统先验。分析发现当前评估基准存在缺陷，文本嵌入直接作为先验也能获得高分但感知质量较低。约束OVI方法提升了视觉保真度，最近邻方法表现最佳。

Conclusion: OVI作为传统先验的可行替代方案，特别是最近邻约束方法效果显著，表明这一思路值得进一步研究。

Abstract: Diffusion models have established the state-of-the-art in text-to-image generation, but their performance often relies on a diffusion prior network to translate text embeddings into the visual manifold for easier decoding. These priors are computationally expensive and require extensive training on massive datasets. In this work, we challenge the necessity of a trained prior at all by employing Optimization-based Visual Inversion (OVI), a training-free and data-free alternative, to replace the need for a prior. OVI initializes a latent visual representation from random pseudo-tokens and iteratively optimizes it to maximize the cosine similarity with input textual prompt embedding. We further propose two novel constraints, a Mahalanobis-based and a Nearest-Neighbor loss, to regularize the OVI optimization process toward the distribution of realistic images. Our experiments, conducted on Kandinsky 2.2, show that OVI can serve as an alternative to traditional priors. More importantly, our analysis reveals a critical flaw in current evaluation benchmarks like T2I-CompBench++, where simply using the text embedding as a prior achieves surprisingly high scores, despite lower perceptual quality. Our constrained OVI methods improve visual fidelity over this baseline, with the Nearest-Neighbor approach proving particularly effective, achieving quantitative scores comparable to or higher than the state-of-the-art data-efficient prior, indicating that the idea merits further investigation. The code will be publicly available upon acceptance.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [22] [Minimizing Hyperbolic Embedding Distortion with LLM-Guided Hierarchy Restructuring](https://arxiv.org/abs/2511.20679)
*Melika Ayoughi,Pascal Mettes,Paul Groth*

Main category: cs.AI

TL;DR: 本文研究使用大型语言模型自动重构层次结构以优化双曲嵌入质量，实验表明LLM重构的层次结构能显著提升嵌入质量并提供可解释的重组理由。


<details>
  <summary>Details</summary>
Motivation: 双曲嵌入的质量与输入层次结构紧密相关，而现有层次结构往往不符合双曲嵌入的最佳条件（高分支因子和单继承）。本文旨在探索LLM能否自动重构层次结构以满足这些标准。

Method: 提出基于提示的方法，使用LLM在已知双曲嵌入期望标准的指导下转换现有层次结构。在16个不同层次结构上进行实验验证。

Result: 实验显示LLM重构的层次结构在多个标准嵌入质量指标上一致产生更高质量的双曲嵌入，并能提供可解释的重组理由。

Conclusion: LLM能够有效自动重构层次结构以优化双曲嵌入质量，同时为知识工程师提供可解释的重组过程。

Abstract: Hyperbolic geometry is an effective geometry for embedding hierarchical data structures. Hyperbolic learning has therefore become increasingly prominent in machine learning applications where data is hierarchically organized or governed by hierarchical semantics, ranging from recommendation systems to computer vision. The quality of hyperbolic embeddings is tightly coupled to the structure of the input hierarchy, which is often derived from knowledge graphs or ontologies. Recent work has uncovered that for an optimal hyperbolic embedding, a high branching factor and single inheritance are key, while embedding algorithms are robust to imbalance and hierarchy size. To assist knowledge engineers in reorganizing hierarchical knowledge, this paper investigates whether Large Language Models (LLMs) have the ability to automatically restructure hierarchies to meet these criteria. We propose a prompt-based approach to transform existing hierarchies using LLMs, guided by known desiderata for hyperbolic embeddings. Experiments on 16 diverse hierarchies show that LLM-restructured hierarchies consistently yield higher-quality hyperbolic embeddings across several standard embedding quality metrics. Moreover, we show how LLM-guided hierarchy restructuring enables explainable reorganizations, providing justifications to knowledge engineers.

</details>


### [23] [AssurAI: Experience with Constructing Korean Socio-cultural Datasets to Discover Potential Risks of Generative AI](https://arxiv.org/abs/2511.20686)
*Chae-Gyun Lim,Seung-Ho Han,EunYoung Byun,Jeongyun Han,Soohyun Cho,Eojin Joo,Heehyeon Kim,Sieun Kim,Juhoon Lee,Hyunsoo Lee,Dongkun Lee,Jonghwan Hyeon,Yechan Hwang,Young-Jun Lee,Kyeongryul Lee,Minhyeong An,Hyunjun Ahn,Jeongwoo Son,Junho Park,Donggyu Yoon,Taehyung Kim,Jeemin Kim,Dasom Choi,Kwangyoung Lee,Hyunseung Lim,Yeohyun Jung,Jongok Hong,Sooyohn Nam,Joonyoung Park,Sungmin Na,Yubin Choi,Jeanne Choi,Yoojin Hong,Sueun Jang,Youngseok Seo,Somin Park,Seoungung Jo,Wonhye Chae,Yeeun Jo,Eunyoung Kim,Joyce Jiyoung Whang,HwaJung Hong,Joseph Seering,Uichin Lee,Juho Kim,Sunna Choi,Seokyeon Ko,Taeho Kim,Kyunghoon Kim,Myungsik Ha,So Jung Lee,Jemin Hwang,JoonHo Kwak,Ho-Jin Choi*

Main category: cs.AI

TL;DR: AssurAI是一个针对韩语多模态生成AI安全评估的质量控制数据集，包含11,480个文本、图像、视频和音频实例，涵盖35种AI风险因素，专门针对韩国社会文化背景设计。


<details>
  <summary>Details</summary>
Motivation: 当前的安全数据集主要是英语中心，无法捕捉非英语社会文化背景（如韩语）中的特定风险，且通常仅限于文本模态，需要填补这一空白。

Method: 定义35种AI风险因素的分类法，通过多学科专家组适应现有框架；采用两阶段构建（专家引导播种和众包扩展）、三重独立标注和迭代专家红队循环的质量控制流程。

Result: 构建并发布了AssurAI数据集，包含11,480个多模态实例；试点研究验证了其在评估最新LLM安全性方面的有效性。

Conclusion: AssurAI有助于为韩国社区开发更安全可靠的生成AI系统，该数据集已向公众发布。

Abstract: The rapid evolution of generative AI necessitates robust safety evaluations. However, current safety datasets are predominantly English-centric, failing to capture specific risks in non-English, socio-cultural contexts such as Korean, and are often limited to the text modality. To address this gap, we introduce AssurAI, a new quality-controlled Korean multimodal dataset for evaluating the safety of generative AI. First, we define a taxonomy of 35 distinct AI risk factors, adapted from established frameworks by a multidisciplinary expert group to cover both universal harms and relevance to the Korean socio-cultural context. Second, leveraging this taxonomy, we construct and release AssurAI, a large-scale Korean multimodal dataset comprising 11,480 instances across text, image, video, and audio. Third, we apply the rigorous quality control process used to ensure data integrity, featuring a two-phase construction (i.e., expert-led seeding and crowdsourced scaling), triple independent annotation, and an iterative expert red-teaming loop. Our pilot study validates AssurAI's effectiveness in assessing the safety of recent LLMs. We release AssurAI to the public to facilitate the development of safer and more reliable generative AI systems for the Korean community.

</details>


### [24] [$A^2Flow:$ Automating Agentic Workflow Generation via Self-Adaptive Abstraction Operators](https://arxiv.org/abs/2511.20693)
*Mingming Zhao,Xiaokang Wei,Yuanqi Shao,Kaiwen Zhou,Lin Yang,Siwei Rao,Junhui Zhan,Zhitang Chen*

Main category: cs.AI

TL;DR: A²Flow是一个基于自适应抽象算子的全自动智能体工作流生成框架，通过三阶段算子提取过程自动生成可重用的执行算子，无需手动预定义，在性能和资源效率上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法严重依赖手动预定义算子，限制了智能体工作流的泛化性和可扩展性，需要开发完全自动化的框架来解决这一问题。

Method: 采用三阶段算子提取：1)基于案例的初始算子生成；2)算子聚类和初步抽象；3)深度提取抽象执行算子。同时引入算子记忆机制增强工作流搜索。

Result: 在通用和具身基准测试中，A²Flow平均性能提升2.4%和19.3%，资源使用减少37%，优于现有最先进基线方法。

Conclusion: A²Flow通过完全自动化的算子提取和工作流生成，显著提升了智能体工作流设计的效率和性能，为自动化智能体工作流设计提供了有效解决方案。

Abstract: Large language models (LLMs) have shown strong potential in automating the design of agentic workflows. However, existing methods still rely heavily on manually predefined operators, limiting generalization and scalability. To address this issue, we propose $A^2Flow$, a fully automated framework for agentic workflow generation based on self-adaptive abstraction operators. $A^2Flow$ employs a three-stage operator extraction process: 1) Case-based Initial Operator Generation: leveraging expert demonstrations and LLM reasoning to generate case-specific operators; 2) Operator Clustering and Preliminary Abstraction: grouping similar operators across tasks to form preliminary abstractions; and 3) Deep Extraction for Abstract Execution Operators: applying long chain-of-thought prompting and multi-path reasoning to derive compact and generalizable execution operators. These operators serve as reusable building blocks for workflow construction without manual predefinition. Furthermore, we enhance node-level workflow search with an operator memory mechanism, which retains historical outputs to enrich context and improve decision-making. Experiments on general and embodied benchmarks show that $A^2Flow$ achieves a 2.4\% and 19.3\% average performance improvement and reduces resource usage by 37\% over state-of-the-art baselines. Homepage:https://github.com/pandawei-ele/A2FLOW

</details>


### [25] [Reasoning With a Star: A Heliophysics Dataset and Benchmark for Agentic Scientific Reasoning](https://arxiv.org/abs/2511.20694)
*Kevin Lee,Russell Spiewak,James Walsh*

Main category: cs.AI

TL;DR: 提出了一个名为"Reasoning With a Star"的日球物理学推理数据集和基准测试方法，通过多智能体模式在需要演绎推理的问题上优于直接提示。


<details>
  <summary>Details</summary>
Motivation: 解决日球物理学中科学推理的挑战，包括整合物理假设、保持单位一致性、提供清晰科学格式等需求。

Method: 构建来自NASA和UCAR Living With a Star暑期学校问题集的数据集，采用程序化评分器检查预测结果，并测试单次提示基线和四种多智能体模式。

Result: 通过系统工程原则分解工作流程的多智能体模式在需要演绎推理的问题上表现优于直接提示。

Conclusion: 多智能体推理方法在复杂科学推理任务中具有优势，特别是在需要演绎推理而非纯归纳回忆的问题上。

Abstract: Scientific reasoning through Large Language Models in heliophysics involves more than just recalling facts: it requires incorporating physical assumptions, maintaining consistent units, and providing clear scientific formats through coordinated approaches. To address these challenges, we present Reasoning With a Star, a newly contributed heliophysics dataset applicable to reasoning; we also provide an initial benchmarking approach. Our data are constructed from National Aeronautics and Space Administration & University Corporation for Atmospheric Research Living With a Star summer school problem sets and compiled into a readily consumable question-and-answer structure with question contexts, reasoning steps, expected answer type, ground-truth targets, format hints, and metadata. A programmatic grader checks the predictions using unit-aware numerical tolerance, symbolic equivalence, and schema validation. We benchmark a single-shot baseline and four multi-agent patterns, finding that decomposing workflows through systems engineering principles outperforms direct prompting on problems requiring deductive reasoning rather than pure inductive recall.

</details>


### [26] [EWE: An Agentic Framework for Extreme Weather Analysis](https://arxiv.org/abs/2511.21444)
*Zhe Jiang,Jiong Wang,Xiaoyu Yue,Zijie Guo,Wenlong Zhang,Fenghua Ling,Wanli Ouyang,Lei Bai*

Main category: cs.AI

TL;DR: EWE是首个用于极端天气自动诊断推理的智能代理框架，通过模拟专家工作流程，从原始气象数据自主生成和解释多模态可视化，实现全面诊断分析。


<details>
  <summary>Details</summary>
Motivation: 极端天气事件对全球社会构成日益严重的风险，但传统专家驱动的人工诊断范式存在分析瓶颈，阻碍科学进展。虽然AI在地球科学预测方面取得进展，但自动诊断推理这一同等重要的挑战尚未被充分探索。

Method: EWE通过知识引导规划、闭环推理和领域定制的气象工具包模拟专家工作流程，能够从原始气象数据自主生成和解释多模态可视化。

Result: 开发了该领域首个基准测试，包含103个高影响事件的精选数据集和新的逐步评估指标。EWE展示了自动化科学发现的潜力。

Conclusion: EWE标志着向自动化科学发现迈出的一步，有望民主化专业知识和智力资源，特别是对易受极端天气影响的发展中国家。

Abstract: Extreme weather events pose escalating risks to global society, underscoring the urgent need to unravel their underlying physical mechanisms. Yet the prevailing expert-driven, labor-intensive diagnostic paradigm has created a critical analytical bottleneck, stalling scientific progress. While AI for Earth Science has achieved notable advances in prediction, the equally essential challenge of automated diagnostic reasoning remains largely unexplored. We present the Extreme Weather Expert (EWE), the first intelligent agent framework dedicated to this task. EWE emulates expert workflows through knowledge-guided planning, closed-loop reasoning, and a domain-tailored meteorological toolkit. It autonomously produces and interprets multimodal visualizations from raw meteorological data, enabling comprehensive diagnostic analyses. To catalyze progress, we introduce the first benchmark for this emerging field, comprising a curated dataset of 103 high-impact events and a novel step-wise evaluation metric. EWE marks a step toward automated scientific discovery and offers the potential to democratize expertise and intellectual resources, particularly for developing nations vulnerable to extreme weather.

</details>


### [27] [A Brief History of Digital Twin Technology](https://arxiv.org/abs/2511.20695)
*Yunqi Zhang,Kuangyu Shi,Biao Li*

Main category: cs.AI

TL;DR: 数字孪生技术从NASA航天器模拟发展而来，现正推动医疗健康转型，通过创建患者特异性虚拟模型支持诊断、治疗规划和药物开发，但仍面临互操作性、数据隐私等挑战。


<details>
  <summary>Details</summary>
Motivation: 将数字孪生技术从工业领域引入医疗健康，旨在实现从被动治疗向预测性、预防性和个性化医疗的转变，提高医疗决策的精确性和效率。

Method: 整合医学影像、生物传感器和计算模型，构建动态数据驱动的患者虚拟副本，通过实时数据流持续更新，支持双向交互和模拟分析。

Result: 已开发出心脏数字孪生预测心律失常治疗效果、肿瘤数字孪生追踪肿瘤进展优化放疗、药理学数字孪生加速药物发现等代表性应用。

Conclusion: 数字孪生技术有望彻底改变医疗模式，但需要解决互操作性、数据隐私等挑战，并通过可解释AI、联邦学习等技术进一步发展多器官数字孪生和基因组整合。

Abstract: Emerging from NASA's spacecraft simulations in the 1960s, digital twin technology has advanced through industrial adoption to spark a healthcare transformation. A digital twin is a dynamic, data-driven virtual counterpart of a physical system, continuously updated through real-time data streams and capable of bidirectional interaction. In medicine, digital twin integrates imaging, biosensors, and computational models to generate patient-specific simulations that support diagnosis, treatment planning, and drug development. Representative applications include cardiac digital twin for predicting arrhythmia treatment outcomes, oncology digital twin for tracking tumor progression and optimizing radiotherapy, and pharmacological digital twin for accelerating drug discovery. Despite rapid progress, major challenges, including interoperability, data privacy, and model fidelity, continue to limit widespread clinical integration. Emerging solutions such as explainable AI, federated learning, and harmonized regulatory frameworks offer promising pathways forward. Looking ahead, advances in multi-organ digital twin, genomics integration, and ethical governance will be essential to ensure that digital twin shifts healthcare from reactive treatment to predictive, preventive, and truly personalized medicine.

</details>


### [28] [Paraconsistent-Lib: an intuitive PAL2v algorithm Python Library](https://arxiv.org/abs/2511.20700)
*Arnaldo de Carvalho Junior,Diego Oliveira da Cruz,Bruno da Silva Alves,Fernando da Silva Paulo Junior,João Inacio da Silva Filho*

Main category: cs.AI

TL;DR: Paraconsistent-Lib是一个开源的Python库，用于构建PAL2v算法，支持12种经典格区域分析、分析节点输出和决策输出，可简化复杂算法的实现。


<details>
  <summary>Details</summary>
Motivation: 为推理和决策系统提供一个易于使用的PAL2v算法构建工具，减少代码复杂性和错误。

Method: 开发通用PAL2v标准计算库，支持独立或网络形式的算法实现，包括Para-analyzer、ParaExtrCTX等经典算法。

Result: 成功创建了稳定状态的Paraconsistent-Lib库，能够有效简化PAL2v算法的开发过程。

Conclusion: Paraconsistent-Lib是一个活跃开发的项目，能够响应用户需求，为PAL2v算法提供高效实现平台。

Abstract: This paper introduces Paraconsistent-Lib, an open-source, easy-to-use Python library for building PAL2v algorithms in reasoning and decision-making systems. Paraconsistent-Lib is designed as a general-purpose library of PAL2v standard calculations, presenting three types of results: paraconsistent analysis in one of the 12 classical lattice PAL2v regions, paraconsistent analysis node (PAN) outputs, and a decision output. With Paraconsistent-Lib, well-known PAL2v algorithms such as Para-analyzer, ParaExtrCTX, PAL2v Filter, paraconsistent analysis network (PANnet), and paraconsistent neural network (PNN) can be written in stand-alone or network form, reducing complexity, code size, and bugs, as two examples presented in this paper. Given its stable state, Paraconsistent-Lib is an active development to respond to user-required features and enhancements received on GitHub.

</details>


### [29] [Cross Domain Evaluation of Multimodal Chain-of-Thought Reasoning of different datasets into the Amazon CoT Framework](https://arxiv.org/abs/2511.20701)
*Nitya Tiwari,Parv Maheshwari,Vidisha Agarwal*

Main category: cs.AI

TL;DR: 本文对多模态思维链推理进行了综合分析，发现在科学问答之外的领域，其有效性因问题类型而异，常识推理尤其具有挑战性。


<details>
  <summary>Details</summary>
Motivation: 探索多模态思维链方法在不同领域的泛化能力，特别是在需要广泛常识和世界知识的任务中。

Method: 采用Zhang等人的两阶段框架，将理由生成与答案推理分离，通过门控融合机制整合视觉特征与基于T5的语言模型。

Result: 视觉特征整合显著减少了理由生成中的幻觉，但思维链推理的有效性在不同问题类型间差异很大，常识推理表现最差。

Conclusion: 为多模态推理系统的实现提供了实用见解，并确定了跨领域泛化的关键改进方向。

Abstract: While recent work has extended CoT to multimodal settings, achieving state-of-the-art results on science question answering benchmarks like ScienceQA, the generalizability of these approaches across diverse domains remains underexplored. This work presents a comprehensive analysis of Multimodal Chain-of-Thought (Multimodal-CoT) reasoning, evaluating its effectiveness on the A-OKVQA, OKVQA and ChartQA datasets, which requires broad commonsense and world knowledge beyond scientific reasoning. We implement the two-stage framework proposed by Zhang et al. [3], which separates rationale generation from answer inference and integrates vision features through a gated fusion mechanism with T5-based language models. Through systematic ablation studies, we analyze the contributions of vision features, rationale quality, and architectural choices. Our findings reveal that while vision integration significantly reduces hallucination in rationale generation, the effectiveness of CoT reasoning varies substantially across question types, with commonsense reasoning presenting particular challenges. This work provides practical insights for researchers implementing multimodal reasoning systems and identifies key areas for future improvement in cross-domain generalization.

</details>


### [30] [Learning Multi-Access Point Coordination in Agentic AI Wi-Fi with Large Language Models](https://arxiv.org/abs/2511.20719)
*Yifan Fan,Le Liang,Peng Liu,Xiao Li,Ziyang Guo,Qiao Lan,Shi Jin,Wen Tong*

Main category: cs.AI

TL;DR: 提出了一种基于大型语言模型代理的智能Wi-Fi框架，其中每个接入点作为自主代理，通过自然语言对话实时协商自适应协调策略，显著提升了密集重叠基本服务集中的吞吐量性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多接入点协调协议依赖静态的协议定义规则，无法适应动态网络条件（如变化的干扰水平和拓扑结构），限制了在密集Wi-Fi环境中的性能提升。

Method: 将每个接入点建模为自主的大型语言模型代理，通过认知工作流程进行自然语言对话，利用集成记忆、反思和工具使用功能，基于历史经验和环境反馈制定决策。

Result: 综合仿真结果表明，该代理框架成功适应了多样化和动态的网络环境，显著优于最先进的空分复用基线方法。

Conclusion: 该代理式AI Wi-Fi框架验证了其作为未来无线网络稳健智能解决方案的潜力，能够实现实时自适应协调策略。

Abstract: Multi-access point coordination (MAPC) is a key technology for enhancing throughput in next-generation Wi-Fi within dense overlapping basic service sets. However, existing MAPC protocols rely on static, protocol-defined rules, which limits their ability to adapt to dynamic network conditions such as varying interference levels and topologies. To address this limitation, we propose a novel Agentic AI Wi-Fi framework where each access point, modeled as an autonomous large language model agent, collaboratively reasons about the network state and negotiates adaptive coordination strategies in real time. This dynamic collaboration is achieved through a cognitive workflow that enables the agents to engage in natural language dialogue, leveraging integrated memory, reflection, and tool use to ground their decisions in past experience and environmental feedback. Comprehensive simulation results demonstrate that our agentic framework successfully learns to adapt to diverse and dynamic network environments, significantly outperforming the state-of-the-art spatial reuse baseline and validating its potential as a robust and intelligent solution for future wireless networks.

</details>


### [31] [OpenApps: Simulating Environment Variations to Measure UI-Agent Reliability](https://arxiv.org/abs/2511.20766)
*Karen Ullrich,Jingtong Su,Claudia Shi,Arjun Subramonian,Amir Bar,Ivan Evtimov,Nikolaos Tsilivis,Randall Balestriero,Julia Kempe,Mark Ibrahim*

Main category: cs.AI

TL;DR: OpenApps是一个轻量级开源生态系统，包含6个可配置应用，用于评估多模态UI代理在不同应用变体中的可靠性。研究发现代理在固定应用中的可靠性相对稳定，但在不同应用变体间差异巨大，任务成功率波动可达50%以上。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法依赖固定环境，无法衡量代理在不同应用设计和内容变化中的可靠性。OpenApps旨在解决这一盲点，评估代理在真实部署中可能遇到的应用变体中的表现。

Method: 开发OpenApps生态系统，包含6个可配置应用（消息、日历、地图等），仅需单个CPU即可运行数千个应用版本。进行了超过10,000次独立评估，研究7个领先多模态代理在不同应用变体中的可靠性。

Result: 代理在固定应用中的可靠性相对稳定，但在不同应用变体间差异巨大。例如Kimi-VL-3B的平均成功率在不同应用版本中从63%降至4%。代理行为（如循环或幻觉操作）也随环境配置显著变化。

Conclusion: 应用变体是衡量代理可靠性的重要新维度。OpenApps为评估代理在不同应用环境中的鲁棒性提供了有效工具，强调了在多样化应用配置中测试代理的重要性。

Abstract: Reliability is key to realizing the promise of autonomous UI-Agents, multimodal agents that directly interact with apps in the same manner as humans, as users must be able to trust an agent to complete a given task. Current evaluations rely on fixed environments, often clones of existing apps, which are limited in that they can only shed light on whether or how often an agent can complete a task within a specific environment. When deployed however, agents are likely to encounter variations in app design and content that can affect an agent's ability to complete a task. To address this blind spot of measuring agent reliability across app variations, we develop OpenApps, a light-weight open-source ecosystem with six apps (messenger, calendar, maps, etc.) that are configurable in appearance and content. OpenApps requires just a single CPU to run, enabling easy generation and deployment of thousands of versions of each app. Specifically, we run more than 10,000 independent evaluations to study reliability across seven leading multimodal agents. We find that while standard reliability within a fixed app is relatively stable, reliability can vary drastically when measured across app variations. Task success rates for many agents can fluctuate by more than $50\%$ across app variations. For example, Kimi-VL-3B's average success across all tasks fluctuates from $63\%$ to just $4\%$ across app versions. We also find agent behaviors such as looping or hallucinating actions can differ drastically depending on the environment configuration. These initial findings highlight the importance of measuring reliability along this new dimension of app variations. OpenApps is available at https://facebookresearch.github.io/OpenApps/

</details>


### [32] [Representation Interventions Enable Lifelong Unstructured Knowledge Control](https://arxiv.org/abs/2511.20892)
*Xuyuan Liu,Zhengzhang Chen,Xinshuai Dong,Yanchi Liu,Xujiang Zhao,Shengyu Chen,Haoyu Wang,Yujun Yan,Haifeng Chen*

Main category: cs.AI

TL;DR: RILKE是一种在表示空间进行干预的知识控制方法，能够在保持基础权重不变的情况下，对复杂非结构化知识进行细粒度控制，支持大规模知识编辑。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型产生错误或过时内容的问题，在不进行昂贵重新训练的情况下高效准确地更新模型知识，特别是在终身学习设置中处理多编辑共存且不相互干扰的挑战。

Method: 在模型表示空间进行干预，学习抗释义和编辑局部化的模块，将每个更新限制在低维子空间以减少交叉编辑干扰；推理时使用查询自适应路由选择适当模块指导生成。

Result: 在LLaMA和Qwen模型的知识编辑基准测试中，RILKE可扩展到大规模数据集，表现出高编辑成功率、强释义泛化能力，并以适度的内存开销保持通用效用。

Conclusion: RILKE是大语言模型中终身知识控制的有效且可扩展解决方案。

Abstract: Large language models (LLMs) often produce incorrect or outdated content. Updating their knowledge efficiently and accurately without costly retraining is a major challenge. This problem is especially hard for complex, unstructured knowledge in a lifelong setting, where many edits must coexist without interference. We introduce RILKE (Representation Intervention for Lifelong KnowledgE Control), a robust and scalable method that treats knowledge control as interventions within the model's representation space. Leveraging representation-space expressiveness, we identify two properties enabling RILKE to deliver fine-grained control over complex, unstructured knowledge while maintaining general utility with frozen base weights. During training, RILKE learns paraphrase-robust and edit-localized modules that limit each update to a low-dimensional subspace to minimize cross-edit interference. In inference, a query-adaptive router selects the appropriate module to guide the model's generation. In evaluation on knowledge editing benchmarks with LLaMA and Qwen models, RILKE is scalable to large-scale datasets, demonstrating high edit success, strong paraphrase generalization, and preserving general utility with modest memory overhead. These results show RILKE is an effective and scalable solution for lifelong knowledge control in LLMs.

</details>


### [33] [Guaranteed Optimal Compositional Explanations for Neurons](https://arxiv.org/abs/2511.20934)
*Biagio La Rosa,Leilani H. Gilpin*

Main category: cs.AI

TL;DR: 提出了首个计算保证最优组合解释的框架，通过分解空间对齐因素、设计启发式估计和高效算法，发现在CNN中10-40%的beam search解释是次优的。


<details>
  <summary>Details</summary>
Motivation: 现有组合解释方法使用beam search计算神经元激活与概念的空间对齐，但无法提供最优性保证，不清楚当前解释与真正最优解的接近程度。

Method: 提出三部分框架：(i)识别影响空间对齐因素的分解方法；(ii)在搜索任何阶段估计对齐的启发式；(iii)首个能在可行时间内计算最优组合解释的算法。

Result: 在计算机视觉和CNN中最常用设置下分析，发现当涉及重叠概念时，10-40%通过beam search获得的解释是次优的。

Conclusion: 基于所提分解和启发式的beam search变体在运行时间上匹配或优于先前方法，同时在超参数和计算资源方面提供更大灵活性。

Abstract: While neurons are the basic units of deep neural networks, it is still unclear what they learn and if their knowledge is aligned with that of humans. Compositional explanations aim to answer this question by describing the spatial alignment between neuron activations and concepts through logical rules. These logical descriptions are typically computed via a search over all possible concept combinations. Since computing the spatial alignment over the entire state space is computationally infeasible, the literature commonly adopts beam search to restrict the space. However, beam search cannot provide any theoretical guarantees of optimality, and it remains unclear how close current explanations are to the true optimum. In this theoretical paper, we address this gap by introducing the first framework for computing guaranteed optimal compositional explanations. Specifically, we propose: (i) a decomposition that identifies the factors influencing the spatial alignment, (ii) a heuristic to estimate the alignment at any stage of the search, and (iii) the first algorithm that can compute optimal compositional explanations within a feasible time. Using this framework, we analyze the differences between optimal and non-optimal explanations in the most popular settings for compositional explanations, the computer vision domain and Convolutional Neural Networks. In these settings, we demonstrate that 10-40 percent of explanations obtained with beam search are suboptimal when overlapping concepts are involved. Finally, we evaluate a beam-search variant guided by our proposed decomposition and heuristic, showing that it matches or improves runtime over prior methods while offering greater flexibility in hyperparameters and computational resources.

</details>


### [34] [ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction](https://arxiv.org/abs/2511.20937)
*Qineng Wang,Wenlong Huang,Yu Zhou,Hang Yin,Tianwei Bao,Jianwen Lyu,Weiyu Liu,Ruohan Zhang,Jiajun Wu,Li Fei-Fei,Manling Li*

Main category: cs.AI

TL;DR: ENACT是一个评估视觉语言模型是否展现具身认知的基准，通过视觉问答形式测试模型从自我中心交互中进行世界建模的能力，包含前向和逆向世界建模两个任务。


<details>
  <summary>Details</summary>
Motivation: 研究现代视觉语言模型是否在非具身训练后仍表现出具身认知的特征，即智能是否源于感觉运动交互而非被动观察。

Method: 将具身认知评估构建为部分可观察马尔可夫决策过程中的世界建模问题，设计两个序列重排序任务：给定动作重排观察序列（前向世界建模）和给定观察重排动作序列（逆向世界建模）。

Result: 前沿视觉语言模型与人类存在性能差距，且差距随交互时间跨度增大而扩大；模型在逆向任务上表现更好，并显示出人类中心偏见（如偏好右手动作）。

Conclusion: 现代视觉语言模型在具身认知能力上仍存在不足，特别是在长时程交互和偏离人类视觉特性的场景中表现较差。

Abstract: Embodied cognition argues that intelligence arises from sensorimotor interaction rather than passive observation. It raises an intriguing question: do modern vision-language models (VLMs), trained largely in a disembodied manner, exhibit signs of embodied cognition? We introduce ENACT, a benchmark that casts evaluation of embodied cognition as world modeling from egocentric interaction in a visual question answering (VQA) format. Framed as a partially observable Markov decision process (POMDP) whose actions are scene graph changes, ENACT comprises two complementary sequence reordering tasks: forward world modeling (reorder shuffled observations given actions) and inverse world modeling (reorder shuffled actions given observations). While conceptually simple, solving these tasks implicitly demands capabilities central to embodied cognition-affordance recognition, action-effect reasoning, embodied awareness, and interactive, long-horizon memory from partially observable egocentric input, while avoiding low-level image synthesis that could confound the evaluation. We provide a scalable pipeline that synthesizes QA pairs from robotics simulation (BEHAVIOR) and evaluates models on 8,972 QA pairs spanning long-horizon home-scale activities. Experiments reveal a performance gap between frontier VLMs and humans that widens with interaction horizon. Models consistently perform better on the inverse task than the forward one and exhibit anthropocentric biases, including a preference for right-handed actions and degradation when camera intrinsics or viewpoints deviate from human vision. Website at https://enact-embodied-cognition.github.io/.

</details>


### [35] [Improving Procedural Skill Explanations via Constrained Generation: A Symbolic-LLM Hybrid Architecture](https://arxiv.org/abs/2511.20942)
*Rahul Dass,Thomas Bowlin,Zebing Li,Xiao Jin,Ashok Goel*

Main category: cs.AI

TL;DR: Ivy是一个AI教练系统，通过结合符号化TMK模型与生成解释层，提供结构化、多步骤的解释，优于GPT和检索增强GPT基线。


<details>
  <summary>Details</summary>
Motivation: 在程序性技能学习中，教学解释需要传达步骤背后的因果、目标导向和组合逻辑，而大型语言模型通常产生流畅但浅层的回答，缺乏这种结构。

Method: Ivy系统结合符号化任务-方法-知识(TMK)模型与生成解释层，TMK编码因果转换、目标层次和问题分解，在明确的结构边界内指导LLM构建解释。

Result: 评估显示，符号约束持续提高了"如何"和"为什么"问题解释的结构质量，在三个推理维度上优于基线模型。

Conclusion: 这项研究展示了一种可扩展的AI教育方法，增强了AI生成解释在智能教练系统中的教学价值。

Abstract: In procedural skill learning, instructional explanations must convey not just steps, but the causal, goal-directed, and compositional logic behind them. Large language models (LLMs) often produce fluent yet shallow responses that miss this structure. We present Ivy, an AI coaching system that delivers structured, multi-step explanations by combining symbolic Task-Method-Knowledge (TMK) models with a generative interpretation layer-an LLM that constructs explanations while being constrained by TMK structure. TMK encodes causal transitions, goal hierarchies, and problem decompositions, and guides the LLM within explicit structural bounds. We evaluate Ivy against responses against GPT and retrieval-augmented GPT baselines using expert and independent annotations across three inferential dimensions. Results show that symbolic constraints consistently improve the structural quality of explanations for "how" and "why" questions. This study demonstrates a scalable AI for education approach that strengthens the pedagogical value of AI-generated explanations in intelligent coaching systems.

</details>


### [36] [ICPO: Intrinsic Confidence-Driven Group Relative Preference Optimization for Efficient Reinforcement Learning](https://arxiv.org/abs/2511.21005)
*Jinpeng Wang,Chao Li,Ting Ye,Mengyuan Zhang,Wei Liu,Jian Luan*

Main category: cs.AI

TL;DR: 提出了ICPO方法，通过利用LLM生成不同响应的概率来反映其推理过程的自我评估，结合偏好优势分数和可验证奖励来指导探索过程，解决现有RLVR方法中的粗粒度奖励、奖励噪声和低效探索问题。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法存在粗粒度奖励、奖励噪声和低效探索等问题，导致训练不稳定和熵崩溃，需要改进以增强LLM的推理能力。

Method: ICPO方法计算每个响应的偏好优势分数，通过比较同一输入提示下多个响应的相对生成概率，并将该分数与可验证奖励结合来指导探索过程。

Result: 在四个通用领域基准和三个数学基准上的综合实验表明，ICPO相比GRPO能稳定提升推理能力。

Conclusion: 偏好优势分数不仅能缓解粗粒度奖励和奖励噪声问题，还能有效抑制过度自信错误，增强被低估高质量响应的相对优势，防止模型过度拟合特定策略，促进更彻底的探索。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) demonstrates significant potential in enhancing the reasoning capabilities of Large Language Models (LLMs). However, existing RLVR methods are often constrained by issues such as coarse-grained rewards, reward noise, and inefficient exploration, which lead to unstable training and entropy collapse. To address this challenge, we propose the Intrinsic Confidence-Driven Group Relative Preference Optimization method (ICPO). The intuition behind it lies in the fact that the probabilities of an LLM generating different responses can inherently and directly reflect its self-assessment of the reasoning process. Inspired by the idea of preference modeling, ICPO calculates a preference advantage score for each response by comparing the relative generation probabilities of multiple responses under the same input prompt, and integrates this score with verifiable rewards to guide the exploration process. We have discovered that the preference advantage score not only alleviates the issues of coarse-grained rewards and reward noise but also effectively curbs overconfident errors, enhances the relative superiority of undervalued high-quality responses, and prevents the model from overfitting to specific strategies, thereby facilitating more thorough exploration. Comprehensive experiments across four general-domain benchmarks and three mathematical benchmarks demonstrate that ICPO steadily boosts reasoning compared to GRPO.

</details>


### [37] [Towards Trustworthy Legal AI through LLM Agents and Formal Reasoning](https://arxiv.org/abs/2511.21033)
*Linze Chen,Yufan Cai,Zhe Hou,Jinsong Dong*

Main category: cs.AI

TL;DR: L4M是一个结合对抗性LLM代理和SMT求解器的法律推理框架，将自然语言解释的灵活性与符号验证的严谨性相结合，在公开基准测试中超越了先进LLM和法律AI基线。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的系统擅长表面文本分析，但缺乏原则性法理学所需的保证。法律理性体现在实质理性（结果公平性）和形式理性（遵循明确规则）两方面，需要将自然语言的解释灵活性与符号验证的严谨性统一起来。

Method: 三阶段流程：1) 法规形式化：将法律条款转换为逻辑公式；2) 双重事实和法规提取：检察官和辩护方对齐的LLM独立从案例叙述中提取事实元组和法规；3) 求解器中心裁决：将双方论证编译为逻辑约束，通过不满足核心触发迭代自我批评，最终由法官LLM将可满足公式转化为透明判决。

Result: 在公开基准测试中，该系统超越了GPT-4-mini、DeepSeek-V3、Claude 4等先进LLM以及最先进的法律AI基线，同时提供严谨且可解释的符号化理由。

Conclusion: L4M框架成功地将自然语言处理的灵活性与符号验证的严谨性相结合，为法律推理提供了既具有解释灵活性又具备形式化保证的解决方案，显著提升了法律AI系统的性能和可解释性。

Abstract: The rationality of law manifests in two forms: substantive rationality, which concerns the fairness or moral desirability of outcomes, and formal rationality, which requires legal decisions to follow explicitly stated, general, and logically coherent rules. Existing LLM-based systems excel at surface-level text analysis but lack the guarantees required for principled jurisprudence. We introduce L4M, a novel framework that combines adversarial LLM agents with SMT-solver-backed proofs to unite the interpretive flexibility of natural language with the rigor of symbolic verification. The pipeline consists of three phases: (1) Statute Formalization, where domain-specific prompts convert legal provisions into logical formulae; (2) Dual Fact and Statute Extraction, in which prosecutor- and defense-aligned LLMs independently map case narratives to fact tuples and statutes, ensuring role isolation; and (3) Solver-Centric Adjudication, where an autoformalizer compiles both parties' arguments into logic constraints, and unsat cores trigger iterative self-critique until a satisfiable formula is achieved, which is then verbalized by a Judge-LLM into a transparent verdict and optimized sentence. Experimental results on public benchmarks show that our system surpasses advanced LLMs including GPT-o4-mini, DeepSeek-V3, and Claude 4 as well as state-of-the-art Legal AI baselines, while providing rigorous and explainable symbolic justifications.

</details>


### [38] [OVOD-Agent: A Markov-Bandit Framework for Proactive Visual Reasoning and Self-Evolving Detection](https://arxiv.org/abs/2511.21064)
*Chujie Wang,Jianyu Lu,Zhiyuan Luo,Xi Chen,Chu He*

Main category: cs.AI

TL;DR: OVOD-Agent将开放词汇目标检测从被动的类别匹配转变为主动的视觉推理和自我进化检测，通过视觉思维链和弱马尔可夫决策过程提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有OVOD方法虽然在多模态数据上预训练，但推理仍局限于固定类别名称，导致多模态训练与单模态推理之间存在差距。文本空间的潜力尚未充分挖掘。

Method: 提出OVOD-Agent框架，采用视觉思维链进行可解释推理，将视觉上下文建模为弱马尔可夫决策过程，包含Bandit模块生成探索信号，并通过自监督奖励模型优化形成闭环。

Result: 在COCO和LVIS数据集上的实验表明，OVOD-Agent在各种OVOD骨干网络上均能提供一致改进，特别是在稀有类别上表现突出。

Conclusion: OVOD-Agent框架通过主动视觉推理和自我进化检测机制，有效提升了开放词汇目标检测的性能，证明了所提方法的有效性。

Abstract: Open-Vocabulary Object Detection (OVOD) aims to enable detectors to generalize across categories by leveraging semantic information. Although existing methods are pretrained on large vision-language datasets, their inference is still limited to fixed category names, creating a gap between multimodal training and unimodal inference. Previous work has shown that improving textual representation can significantly enhance OVOD performance, indicating that the textual space is still underexplored. To this end, we propose OVOD-Agent, which transforms passive category matching into proactive visual reasoning and self-evolving detection. Inspired by the Chain-of-Thought (CoT) paradigm, OVOD-Agent extends the textual optimization process into an interpretable Visual-CoT with explicit actions. OVOD's lightweight nature makes LLM-based management unsuitable; instead, we model visual context transitions as a Weakly Markovian Decision Process (w-MDP) over eight state spaces, which naturally represents the agent's state, memory, and interaction dynamics. A Bandit module generates exploration signals under limited supervision, helping the agent focus on uncertain regions and adapt its detection policy. We further integrate Markov transition matrices with Bandit trajectories for self-supervised Reward Model (RM) optimization, forming a closed loop from Bandit exploration to RM learning. Experiments on COCO and LVIS show that OVOD-Agent provides consistent improvements across OVOD backbones, particularly on rare categories, confirming the effectiveness of the proposed framework.

</details>


### [39] [Causality Without Causal Models](https://arxiv.org/abs/2511.21260)
*Joseph Y. Halpern,Rafael Pass*

Main category: cs.AI

TL;DR: 本文提出了Halpern-Pearl因果定义的抽象化版本，使其能应用于更广泛的模型，包括处理析取、否定、信念和嵌套反事实等复杂情况。


<details>
  <summary>Details</summary>
Motivation: Halpern-Pearl的因果定义局限于因果模型，无法处理复杂逻辑公式和更广泛的模型类型，需要抽象化以扩展应用范围。

Method: 通过提取Halpern-Pearl因果定义的关键特征，构建抽象化定义框架，使其适用于任何定义了反事实的模型。

Result: 成功开发出能应用于更广泛模型的因果定义，包括支持回溯的模型，并能处理析取、否定、信念和嵌套反事实等复杂逻辑公式。

Conclusion: 抽象化方法不仅扩展了因果定义的应用范围，还深化了对因果定义特征的理解，并能推广到解释概念的定义。

Abstract: Perhaps the most prominent current definition of (actual) causality is due to Halpern and Pearl.  It is defined using causal models (also known as structural equations models).  We abstract the definition, extracting its key features, so that it can be applied to any other model where counterfactuals are defined. By abstracting the definition, we gain a number of benefits. Not only can we apply the definition in a wider range of models, including ones that allow, for example, backtracking, but we can apply the definition to determine if A is a cause of B  even if A and B are formulas involving disjunctions, negations, beliefs, and nested counterfactuals (none of which can be handled by the Halpern-Pearl definition). Moreover, we can extend the ideas to getting an abstract definition of explanation that can be applied beyond causal models. Finally, we gain a deeper understanding of features of the definition  even in causal models.

</details>
