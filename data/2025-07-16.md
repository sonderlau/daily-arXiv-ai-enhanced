<div id=toc></div>

# Table of Contents

- [physics.ao-ph](#physics.ao-ph) [Total: 2]
- [cs.NE](#cs.NE) [Total: 6]
- [cs.CV](#cs.CV) [Total: 65]
- [cs.AI](#cs.AI) [Total: 36]
- [eess.IV](#eess.IV) [Total: 3]


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [1] [Seasonal Variability of Snow Cover and Impact on Albedo and Thermal Properties in the Antarctic Marginal Ice Zone](https://arxiv.org/abs/2507.10916)
*Ippolita Tersigni,Filippo Nelli,Emiliano Cimoli,Petra Heil,Luke Bennetts,Giulio Passerotti,Alessandro Toffoli*

Main category: physics.ao-ph

TL;DR: 研究南极海冰上积雪的季节性变化及其对表面反照率和能量通量的影响，强调积雪覆盖的非线性作用及其对气候模型的修正需求。


<details>
  <summary>Details</summary>
Motivation: 积雪在南极海冰热力学行为中起关键作用，但常被低估，需更精确地描述其对表面条件的影响。

Method: 利用2019-2024年五次船载考察的高分辨率可见/红外影像、实地观测和气象数据，分析积雪分布及其影响。

Result: 积雪显著增加表面反照率并抑制热传导，简化假设会引入偏差，需多组分表面方案。

Conclusion: 积雪覆盖的非线性响应要求修正当前模型参数化，以更准确反映南极海冰区的异质性。

Abstract: Snow cover plays a critical yet often underrepresented role in shaping the
thermodynamic behavior of Antarctic sea ice. In this study, we investigate the
seasonal variability of snow distribution and its impact on surface albedo and
energy fluxes across the marginal ice zone (MIZ), using a unique dataset from
five shipborne expeditions conducted between 2019 and 2024. High-resolution
visible and infrared imagery, combined with field observations and
meteorological data, reveal that even modest snow fractions substantially
increase surface reflectivity and suppress conductive heat transfer. Our
results demonstrate that simplified binary assumptions-such as assigning dry
snow in winter and bare ice in summer-systematically misrepresent surface
conditions, introducing significant biases in modelled radiative and turbulent
fluxes. By explicitly resolving fractional snow cover, we show that surface
albedo and energy exchange respond nonlinearly to snow-ice composition, with
implications for sea ice growth, melt, and climate feedbacks. These findings
advocate for a revision of current model parameterizations, emphasizing the
need for multi-component surface schemes that reflect the observed
heterogeneity of the Antarctic MIZ.

</details>


### [2] [Estado del clima en Jalisco: temporada de lluvias y comportamiento extremo de la temperatura en 2024](https://arxiv.org/abs/2507.11335)
*Mauricio López-Reyes,Julio Eduardo Zamora-Salvador,Alma Delia Ortíz-Bañuelos,Stephany Paulina Arellano-Ramírez,Carlos Román-Castañeda,Armando González-Figueroa,Hector Hugo Ulloa-Godínez,Mario E. García Guadalupe*

Main category: physics.ao-ph

TL;DR: 本文分析了2024年墨西哥哈利斯科州雨季和极端温度的特征，发现雨季开始晚、结束早，且温度异常升高，可能与人为气候变化和厄尔尼诺事件有关。


<details>
  <summary>Details</summary>
Motivation: 研究旨在了解哈利斯科州的气候变化特征及其对农业等关键领域的影响。

Method: 使用ERA5和CHIRPS再分析数据及13个气象站的观测数据，分析降水和温度异常模式。

Result: 2024年雨季异常，温度创纪录，平均异常达2.3°C，降水分布不均。

Conclusion: 研究强调了加强监测网络和实施适应策略的必要性，以减轻气候变化对农业和水资源的影响。

Abstract: This article analyzes the characteristics of the rainy season and extreme
temperatures recorded in the state of Jalisco, Mexico, during 2024. Using ERA5
and CHIRPS reanalysis data and observations from thirteen meteorological
stations, patterns of precipitation and temperature anomalies were identified.
The results show a late start and early end of the rainy season, with positive
anomalies in the central and southern regions, and significant deficits in the
coastal strip. Furthermore, 2024 stood out as the warmest year on record, with
an average anomaly of 2.3 C in May to October period, surpassing the record set
in 2023. This warming is likely attributed to the combination of anthropogenic
climate change and an El Nino event, altering local atmospheric patterns and
affecting rainfall distribution. The findings highlight Jalisco climate
vulnerability, especially in the agricultural sector, which depends on stable
weather patterns. This study underscores the need to strengthen monitoring
networks, implement predictive models, and design adaptation strategies to
mitigate impacts in key sectors such as agriculture and water resources.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [3] [Tangma: A Tanh-Guided Activation Function with Learnable Parameters](https://arxiv.org/abs/2507.10560)
*Shreel Golwala*

Main category: cs.NE

TL;DR: Tangma是一种新的激活函数，结合了双曲正切的平滑形状和两个可学习参数，在MNIST和CIFAR-10上表现优于ReLU、Swish和GELU。


<details>
  <summary>Details</summary>
Motivation: 改进深度神经网络的反向传播效率和表达能力。

Method: 提出Tangma激活函数，引入可学习参数α和γ，调整激活曲线并保留弱梯度。

Result: 在MNIST上验证准确率99.09%，CIFAR-10上78.15%，收敛更快且训练更稳定。

Conclusion: Tangma在标准视觉任务中表现优异，可学习设计为更大模型提供灵活性。

Abstract: Activation functions are key to effective backpropagation and expressiveness
in deep neural networks. This work introduces Tangma, a new activation function
that combines the smooth shape of the hyperbolic tangent with two learnable
parameters: $\alpha$, which shifts the curve's inflection point to adjust
neuron activation, and $\gamma$, which adds linearity to preserve weak
gradients and improve training stability. Tangma was evaluated on MNIST and
CIFAR-10 using custom networks composed of convolutional and linear layers, and
compared against ReLU, Swish, and GELU. On MNIST, Tangma achieved the highest
validation accuracy of 99.09% and the lowest validation loss, demonstrating
faster and more stable convergence than the baselines. On CIFAR-10, Tangma
reached a top validation accuracy of 78.15%, outperforming all other activation
functions while maintaining a competitive training loss. Tangma also showed
improved training efficiency, with lower average epoch runtimes compared to
Swish and GELU. These results suggest that Tangma performs well on standard
vision tasks and enables reliable, efficient training. Its learnable design
gives more control over activation behavior, which may benefit larger models in
tasks such as image recognition or language modeling.

</details>


### [4] [SFATTI: Spiking FPGA Accelerator for Temporal Task-driven Inference -- A Case Study on MNIST](https://arxiv.org/abs/2507.10561)
*Alessio Caviglia,Filippo Marostica,Alessio Carpegna,Alessandro Savino,Stefano Di Carlo*

Main category: cs.NE

TL;DR: 论文探讨了使用Spiker+框架生成优化的SNN加速器，用于MNIST手写数字识别，分析了边缘计算中的权衡。


<details>
  <summary>Details</summary>
Motivation: 硬件加速器对于边缘应用（如图像识别）的低延迟、高能效推理至关重要，而SNN因其事件驱动和稀疏特性适合低功耗FPGA部署。

Method: 使用开源的Spiker+框架，支持高级网络拓扑、神经元模型和量化规范，自动生成可部署的HDL。

Result: 评估了多种配置，分析了与边缘计算约束相关的权衡。

Conclusion: Spiker+框架为SNN在边缘计算中的优化部署提供了有效工具。

Abstract: Hardware accelerators are essential for achieving low-latency,
energy-efficient inference in edge applications like image recognition. Spiking
Neural Networks (SNNs) are particularly promising due to their event-driven and
temporally sparse nature, making them well-suited for low-power Field
Programmable Gate Array (FPGA)-based deployment. This paper explores using the
open-source Spiker+ framework to generate optimized SNNs accelerators for
handwritten digit recognition on the MNIST dataset. Spiker+ enables high-level
specification of network topologies, neuron models, and quantization,
automatically generating deployable HDL. We evaluate multiple configurations
and analyze trade-offs relevant to edge computing constraints.

</details>


### [5] [A Biomimetic Way for Coral-Reef-Inspired Swarm Intelligence for Carbon-Neutral Wastewater Treatment](https://arxiv.org/abs/2507.10563)
*Antonis Messinis*

Main category: cs.NE

TL;DR: 提出一种基于珊瑚礁启发的群体交互网络，用于碳中性废水处理，具有高效率和低能耗。


<details>
  <summary>Details</summary>
Motivation: 随着废水处理需求增加，实现能源中性净化具有挑战性，需要创新解决方案。

Method: 结合形态发生抽象和多任务碳意识，采用线性令牌复杂性实现可扩展性。

Result: 在七种基准测试中，实现96.7%去除效率、0.31 kWh/m³能耗和14.2 g/m³ CO₂排放，并在传感器漂移下表现稳健。

Conclusion: 方法在多种场景中潜力显著，但数据科学人员配备和治理限制是未来需解决的问题。

Abstract: With increasing wastewater rates, achieving energy-neutral purification is
challenging. We introduce a coral-reef-inspired Swarm Interaction Network for
carbon-neutral wastewater treatment, combining morphogenetic abstraction with
multi-task carbon awareness. Scalability stems from linear token complexity,
mitigating the energy-removal problem. Compared with seven baselines, our
approach achieves 96.7\% removal efficiency, 0.31~kWh~m$^{-3}$ energy
consumption, and 14.2~g~m$^{-3}$ CO$_2$ emissions. Variance analysis
demonstrates robustness under sensor drift. Field scenarios--insular lagoons,
brewery spikes, and desert greenhouses--show potential diesel savings of up to
22\%. However, data-science staffing remains an impediment. Future work will
integrate AutoML wrappers within the project scope, although governance
restrictions pose interpretability challenges that require further visual
analytics.

</details>


### [6] [An Exact Gradient Framework for Training Spiking Neural Networks](https://arxiv.org/abs/2507.10568)
*Arman Ferdowsi,Atakan Aral*

Main category: cs.NE

TL;DR: 提出了一种基于事件驱动的学习框架，用于精确计算SNN中突触权重、传输延迟和自适应神经元放电阈值的梯度，显著提升了准确性和时序精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖离散时间模拟或代理梯度近似，限制了训练精度和效率，且对硬件实现提出了挑战。

Method: 开发了一种分析性事件驱动学习框架，能够精确计算损失梯度，包括突触权重、传输延迟和自适应放电阈值。

Result: 在多个基准测试中，准确率提升高达7%，时序精度和鲁棒性也显著优于现有方法。

Conclusion: 该方法克服了现有技术的限制，为SNN的高效训练和硬件实现提供了新途径。

Abstract: Spiking neural networks inherently rely on the precise timing of discrete
spike events for information processing. Incorporating additional bio-inspired
degrees of freedom, such as trainable synaptic transmission delays and adaptive
firing thresholds, is essential for fully leveraging the temporal dynamics of
SNNs. Although recent methods have demonstrated the benefits of training
synaptic weights and delays, both in terms of accuracy and temporal
representation, these techniques typically rely on discrete-time simulations,
surrogate gradient approximations, or full access to internal state variables
such as membrane potentials. Such requirements limit training precision and
efficiency and pose challenges for neuromorphic hardware implementation due to
increased memory and I/O bandwidth demands. To overcome these challenges, we
propose an analytical event-driven learning framework that computes exact loss
gradients not only with respect to synaptic weights and transmission delays but
also to adaptive neuronal firing thresholds. Experiments on multiple benchmarks
demonstrate significant gains in accuracy (up to 7%), timing precision, and
robustness compared to existing methods.

</details>


### [7] [Grammatical Structure and Grammatical Variations in Non-Metric Iranian Classical Music](https://arxiv.org/abs/2507.10708)
*Maziar Kanani,Sean O Leary,James McDermott*

Main category: cs.NE

TL;DR: 研究介绍了非节拍伊朗古典音乐的符号数据集、结构解析算法及变奏生成方法，验证了算法在解析和生成变奏上的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解析非节拍伊朗古典音乐的结构并生成变奏，填补西方音乐分析方法的不足，同时为教育和民族音乐学提供工具。

Method: 使用MIDI文件和数据表构建数据集，应用解析算法将曲调转化为语法表示，通过语法变异生成新变奏，并由专家评估。

Result: 系统成功生成可接受的变奏，统计分析了不同表示设置对算法的影响。

Conclusion: 方法适用于伊朗古典音乐，并可扩展至阿拉伯或土耳其古典音乐。

Abstract: In this study we introduce a symbolic dataset composed of non-metric Iranian
classical music, and algorithms for structural parsing of this music, and
generation of variations. The corpus comprises MIDI files and data sheets of
Dastgah Shour from Radif Mirza Abdollah, the foundational repertoire of Iranian
classical music. Furthermore, we apply our previously-introduced algorithm for
parsing melodic structure (Kanani et al., 2023b)to the dataset. Unlike much
Western music, this type of non-metric music does not follow bar-centric
organisation. The non-metric organisation can be captured well by our parsing
algorithm. We parse each tune (Gusheh) into a grammar to identify motifs and
phrases. These grammar representations can be useful for educational and
ethnomusicological purposes. We also further develop a previously-introduced
method of creating melodic variations (Kanani et al., 2023b). After parsing an
existing tune to produce a grammar, by applying mutations to this grammar, we
generate a new grammar. Expanding this new version yields a variation of the
original tune. Variations are assessed by a domain-expert listener.
Additionally, we conduct a statistical analysis of mutation with different
representation setups for our parsing and generation algorithms. The
overarching conclusion is that the system successfully produces acceptable
variations post-mutation. While our case study focuses on Iranian classical
music, the methodology can be adapted for Arabic or Turkish classical music.

</details>


### [8] [Biological Processing Units: Leveraging an Insect Connectome to Pioneer Biofidelic Neural Architectures](https://arxiv.org/abs/2507.10951)
*Siyu Yu,Zihan Qin,Tingshan Liu,Beiya Xu,R. Jacob Vogelstein,Jason Brown,Joshua T. Vogelstein*

Main category: cs.NE

TL;DR: 果蝇幼虫大脑的全连接组被转化为生物处理单元（BPU），其固定循环网络在MNIST和CIFAR-10任务中表现优异，甚至超越传统MLP。通过扩展连接组和模态特异性消融实验，进一步验证了其潜力。在ChessBench任务中，轻量级GNN-BPU模型表现突出，CNN-BPU模型在参数匹配情况下优于Transformer。


<details>
  <summary>Details</summary>
Motivation: 研究生物演化出的神经回路是否能支持人工智能，探索生物启发的神经网络架构在复杂认知任务中的潜力。

Method: 将果蝇幼虫大脑的连接组转化为固定循环网络（BPU），并通过扩展连接组和模态特异性消融实验进行优化。在多个任务（MNIST、CIFAR-10、ChessBench）中测试其性能。

Result: BPU在MNIST上达到98%准确率，CIFAR-10上58%；轻量级GNN-BPU在ChessBench上达到60%移动准确率；CNN-BPU在参数匹配情况下优于Transformer，深度搜索下达到91.7%准确率。

Conclusion: 生物启发的神经网络架构在复杂任务中表现出潜力，未来可扩展至更大规模的连接组以进一步提升性能。

Abstract: The complete connectome of the Drosophila larva brain offers a unique
opportunity to investigate whether biologically evolved circuits can support
artificial intelligence. We convert this wiring diagram into a Biological
Processing Unit (BPU), a fixed recurrent network derived directly from synaptic
connectivity. Despite its modest size 3,000 neurons and 65,000 weights between
them), the unmodified BPU achieves 98% accuracy on MNIST and 58% on CIFAR-10,
surpassing size-matched MLPs. Scaling the BPU via structured connectome
expansions further improves CIFAR-10 performance, while modality-specific
ablations reveal the uneven contributions of different sensory subsystems. On
the ChessBench dataset, a lightweight GNN-BPU model trained on only 10,000
games achieves 60% move accuracy, nearly 10x better than any size transformer.
Moreover, CNN-BPU models with ~2M parameters outperform parameter-matched
Transformers, and with a depth-6 minimax search at inference, reach 91.7%
accuracy, exceeding even a 9M-parameter Transformer baseline. These results
demonstrate the potential of biofidelic neural architectures to support complex
cognitive tasks and motivate scaling to larger and more intelligent connectomes
in future work.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [9] [Modernizing CNN-based Weather Forecast Model towards Higher Computational Efficiency](https://arxiv.org/abs/2507.10893)
*Minjong Cheon,Eunhan Goo,Su-Hyeon Shin,Muhammad Ahmed,Hyungjun Kim*

Main category: cs.CV

TL;DR: 本文介绍了一种基于CNN的轻量级全球天气预报模型KAI-a，其性能与现有Transformer模型相当，但计算需求显著降低。


<details>
  <summary>Details</summary>
Motivation: 尽管AI天气预报模型取得了显著进展，但Transformer架构的高复杂性和资源需求限制了其应用。本文旨在通过现代化CNN架构解决这一问题。

Method: KAI-a采用尺度不变架构和InceptionNeXt模块，结合地球系统数据特性设计，训练仅需12小时和7百万参数。

Result: KAI-a在中期天气预报中表现与最先进模型相当，且能有效捕捉极端事件（如2018年欧洲热浪和东亚夏季风）。

Conclusion: KAI-a展示了轻量级CNN模型在天气预报中的潜力，为资源高效的数据驱动预测提供了可行方案。

Abstract: Recently, AI-based weather forecast models have achieved impressive advances.
These models have reached accuracy levels comparable to traditional NWP
systems, marking a significant milestone in data-driven weather prediction.
However, they mostly leverage Transformer-based architectures, which often
leads to high training complexity and resource demands due to the massive
parameter sizes. In this study, we introduce a modernized CNN-based model for
global weather forecasting that delivers competitive accuracy while
significantly reducing computational requirements. To present a systematic
modernization roadmap, we highlight key architectural enhancements across
multiple design scales from an earlier CNN-based approach. KAI-a incorporates a
scale-invariant architecture and InceptionNeXt-based blocks within a
geophysically-aware design, tailored to the structure of Earth system data.
Trained on the ERA5 daily dataset with 67 atmospheric variables, the model
contains about 7 million parameters and completes training in just 12 hours on
a single NVIDIA L40s GPU. Our evaluation shows that KAI-a matches the
performance of state-of-the-art models in medium-range weather forecasting,
while offering a significantly lightweight design. Furthermore, case studies on
the 2018 European heatwave and the East Asian summer monsoon demonstrate
KAI-a's robust skill in capturing extreme events, reinforcing its practical
utility.

</details>


### [10] [CWNet: Causal Wavelet Network for Low-Light Image Enhancement](https://arxiv.org/abs/2507.10689)
*Tongshun Zhang,Pingping Liu,Yubing Lu,Mengen Cai,Zijian Zhang,Zhe Zhang,Qiuzhan Zhou*

Main category: cs.CV

TL;DR: CWNet是一种基于小波变换和因果推理的低光图像增强方法，通过全局和局部因果分析优化图像增强效果。


<details>
  <summary>Details</summary>
Motivation: 传统低光图像增强方法忽视实例级语义信息和特征特性，CWNet旨在通过因果推理解决这一问题。

Method: 结合因果推理和小波变换，采用全局度量学习和局部CLIP语义损失，设计小波变换主干网络。

Result: CWNet在多个数据集上显著优于现有方法，表现出强大的场景适应性。

Conclusion: CWNet通过因果推理和小波变换实现了更精确的低光图像增强，为未来研究提供了新思路。

Abstract: Traditional Low-Light Image Enhancement (LLIE) methods primarily focus on
uniform brightness adjustment, often neglecting instance-level semantic
information and the inherent characteristics of different features. To address
these limitations, we propose CWNet (Causal Wavelet Network), a novel
architecture that leverages wavelet transforms for causal reasoning.
Specifically, our approach comprises two key components: 1) Inspired by the
concept of intervention in causality, we adopt a causal reasoning perspective
to reveal the underlying causal relationships in low-light enhancement. From a
global perspective, we employ a metric learning strategy to ensure causal
embeddings adhere to causal principles, separating them from non-causal
confounding factors while focusing on the invariance of causal factors. At the
local level, we introduce an instance-level CLIP semantic loss to precisely
maintain causal factor consistency. 2) Based on our causal analysis, we present
a wavelet transform-based backbone network that effectively optimizes the
recovery of frequency information, ensuring precise enhancement tailored to the
specific attributes of wavelet transforms. Extensive experiments demonstrate
that CWNet significantly outperforms current state-of-the-art methods across
multiple datasets, showcasing its robust performance across diverse scenes.
Code is available at https://github.com/bywlzts/CWNet-Causal-Wavelet-Network.

</details>


### [11] [Integrating Biological Knowledge for Robust Microscopy Image Profiling on De Novo Cell Lines](https://arxiv.org/abs/2507.10737)
*Jiayuan Chen,Thai-Hoang Pham,Yuanlong Wang,Ping Zhang*

Main category: cs.CV

TL;DR: 提出一种新框架，整合外部生物知识到预训练策略中，增强显微镜图像分析模型对新型细胞系的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决新型细胞系因形态和生物学异质性导致的扰动筛选挑战。

Method: 利用蛋白质相互作用知识图谱和单细胞转录组特征，分离扰动特异性和细胞系特异性表征。

Result: 在RxRx数据库上验证，模型对新型细胞系的显微镜图像分析能力显著提升。

Conclusion: 该方法为基于表型的药物发现提供了有效工具。

Abstract: High-throughput screening techniques, such as microscopy imaging of cellular
responses to genetic and chemical perturbations, play a crucial role in drug
discovery and biomedical research. However, robust perturbation screening for
\textit{de novo} cell lines remains challenging due to the significant
morphological and biological heterogeneity across cell lines. To address this,
we propose a novel framework that integrates external biological knowledge into
existing pretraining strategies to enhance microscopy image profiling models.
Our approach explicitly disentangles perturbation-specific and cell
line-specific representations using external biological information.
Specifically, we construct a knowledge graph leveraging protein interaction
data from STRING and Hetionet databases to guide models toward
perturbation-specific features during pretraining. Additionally, we incorporate
transcriptomic features from single-cell foundation models to capture cell
line-specific representations. By learning these disentangled features, our
method improves the generalization of imaging models to \textit{de novo} cell
lines. We evaluate our framework on the RxRx database through one-shot
fine-tuning on an RxRx1 cell line and few-shot fine-tuning on cell lines from
the RxRx19a dataset. Experimental results demonstrate that our method enhances
microscopy image profiling for \textit{de novo} cell lines, highlighting its
effectiveness in real-world phenotype-based drug discovery applications.

</details>


### [12] [Auditing Facial Emotion Recognition Datasets for Posed Expressions and Racial Bias](https://arxiv.org/abs/2507.10755)
*Rina Khan,Catherine Stinson*

Main category: cs.CV

TL;DR: 该研究审计了两个先进的面部表情识别数据集，发现其中许多图像是摆拍而非自然表情，且模型对非白人或深色皮肤的人存在偏见。


<details>
  <summary>Details</summary>
Motivation: 解决面部表情识别算法在自然表情和不同种族/肤色上的性能下降和伦理问题。

Method: 随机抽样数据集图像，区分自然与摆拍表情，并测试模型对不同肤色人群的预测表现。

Result: 发现数据集包含大量摆拍图像，且模型对非白人或深色皮肤的人更易预测负面情绪。

Conclusion: 数据集和模型存在偏差，可能在实际应用中造成伤害，需改进数据收集和模型训练方法。

Abstract: Facial expression recognition (FER) algorithms classify facial expressions
into emotions such as happy, sad, or angry. An evaluative challenge facing FER
algorithms is the fall in performance when detecting spontaneous expressions
compared to posed expressions. An ethical (and evaluative) challenge facing FER
algorithms is that they tend to perform poorly for people of some races and
skin colors. These challenges are linked to the data collection practices
employed in the creation of FER datasets. In this study, we audit two
state-of-the-art FER datasets. We take random samples from each dataset and
examine whether images are spontaneous or posed. In doing so, we propose a
methodology for identifying spontaneous or posed images. We discover a
significant number of images that were posed in the datasets purporting to
consist of in-the-wild images. Since performance of FER models vary between
spontaneous and posed images, the performance of models trained on these
datasets will not represent the true performance if such models were to be
deployed in in-the-wild applications. We also observe the skin color of
individuals in the samples, and test three models trained on each of the
datasets to predict facial expressions of people from various races and skin
tones. We find that the FER models audited were more likely to predict people
labeled as not white or determined to have dark skin as showing a negative
emotion such as anger or sadness even when they were smiling. This bias makes
such models prone to perpetuate harm in real life applications.

</details>


### [13] [FPC-Net: Revisiting SuperPoint with Descriptor-Free Keypoint Detection via Feature Pyramids and Consistency-Based Implicit Matching](https://arxiv.org/abs/2507.10770)
*Ionuţ Grigore,Călin-Adrian Popa,Claudiu Leoveanu-Condrei*

Main category: cs.CV

TL;DR: 提出了一种无需描述符的兴趣点匹配方法，显著减少内存使用，尽管匹配精度略低。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要计算和匹配描述符，导致内存和计算开销大，新方法旨在消除这一需求。

Method: 在检测过程中直接关联兴趣点，省去描述符的计算、存储和匹配步骤。

Result: 匹配精度略低于传统方法，但内存使用大幅减少。

Conclusion: 该方法为定位系统提供了一种高效且内存友好的替代方案。

Abstract: The extraction and matching of interest points are fundamental to many
geometric computer vision tasks. Traditionally, matching is performed by
assigning descriptors to interest points and identifying correspondences based
on descriptor similarity. This work introduces a technique where interest
points are inherently associated during detection, eliminating the need for
computing, storing, transmitting, or matching descriptors. Although the
matching accuracy is marginally lower than that of conventional approaches, our
method completely eliminates the need for descriptors, leading to a drastic
reduction in memory usage for localization systems. We assess its effectiveness
by comparing it against both classical handcrafted methods and modern learned
approaches.

</details>


### [14] [A New Dataset and Performance Benchmark for Real-time Spacecraft Segmentation in Onboard Flight Computers](https://arxiv.org/abs/2507.10775)
*Jeffrey Joan Sam,Janhavi Sathe,Nikhil Chigali,Naman Gupta,Radhey Ruparel,Yicheng Jiang,Janmajay Singh,James W. Berck,Arko Barman*

Main category: cs.CV

TL;DR: 论文提出了一种新的航天器图像数据集，用于训练实时图像分割模型，以支持太空中的自主检测系统。


<details>
  <summary>Details</summary>
Motivation: 太空环境对航天器造成损害，人工或机器人维修成本高且风险大，需要可靠的自主检测系统。

Method: 创建了包含64k标注图像的数据集，结合真实与合成背景，并添加噪声和失真。微调YOLOv8和YOLOv11模型进行性能测试。

Result: 模型在模拟实时条件下，Dice分数0.92，Hausdorff距离0.69，推理时间约0.5秒。

Conclusion: 数据集和模型为太空实时图像分割提供了有效解决方案，支持自主检测系统的发展。

Abstract: Spacecraft deployed in outer space are routinely subjected to various forms
of damage due to exposure to hazardous environments. In addition, there are
significant risks to the subsequent process of in-space repairs through human
extravehicular activity or robotic manipulation, incurring substantial
operational costs. Recent developments in image segmentation could enable the
development of reliable and cost-effective autonomous inspection systems. While
these models often require large amounts of training data to achieve
satisfactory results, publicly available annotated spacecraft segmentation data
are very scarce. Here, we present a new dataset of nearly 64k annotated
spacecraft images that was created using real spacecraft models, superimposed
on a mixture of real and synthetic backgrounds generated using NASA's TTALOS
pipeline. To mimic camera distortions and noise in real-world image
acquisition, we also added different types of noise and distortion to the
images. Finally, we finetuned YOLOv8 and YOLOv11 segmentation models to
generate performance benchmarks for the dataset under well-defined hardware and
inference time constraints to mimic real-world image segmentation challenges
for real-time onboard applications in space on NASA's inspector spacecraft. The
resulting models, when tested under these constraints, achieved a Dice score of
0.92, Hausdorff distance of 0.69, and an inference time of about 0.5 second.
The dataset and models for performance benchmark are available at
https://github.com/RiceD2KLab/SWiM.

</details>


### [15] [Warehouse Spatial Question Answering with LLM Agent](https://arxiv.org/abs/2507.10778)
*Hsiang-Wei Huang,Jen-Hao Cheng,Kuang-Ming Chen,Cheng-Yen Yang,Bahaa Alattar,Yi-Ru Lin,Pyongkun Kim,Sangwon Kim,Kwangju Kim,Chung-I Huang,Jenq-Neng Hwang*

Main category: cs.CV

TL;DR: 提出了一种数据高效的方法，通过LLM代理系统增强空间理解能力，适用于复杂室内仓库场景的空间问答任务。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在空间理解任务上表现不足，需通过大规模微调提升能力，本文旨在提出更高效的方法。

Method: 构建了一个具备强大空间推理能力的LLM代理系统，集成多种工具进行空间推理和API交互。

Result: 在2025 AI City Challenge数据集上，系统在物体检索、计数和距离估计等任务中表现出高准确性和效率。

Conclusion: 该方法在复杂室内仓库场景中有效提升了空间问答任务的性能，代码已开源。

Abstract: Spatial understanding has been a challenging task for existing Multi-modal
Large Language Models~(MLLMs). Previous methods leverage large-scale MLLM
finetuning to enhance MLLM's spatial understanding ability. In this paper, we
present a data-efficient approach. We propose a LLM agent system with strong
and advanced spatial reasoning ability, which can be used to solve the
challenging spatial question answering task in complex indoor warehouse
scenarios. Our system integrates multiple tools that allow the LLM agent to
conduct spatial reasoning and API tools interaction to answer the given
complicated spatial question. Extensive evaluations on the 2025 AI City
Challenge Physical AI Spatial Intelligence Warehouse dataset demonstrate that
our system achieves high accuracy and efficiency in tasks such as object
retrieval, counting, and distance estimation. The code is available at:
https://github.com/hsiangwei0903/SpatialAgent

</details>


### [16] [ThinkingViT: Matryoshka Thinking Vision Transformer for Elastic Inference](https://arxiv.org/abs/2507.10800)
*Ali Hojjat,Janek Haberer,Soren Pirk,Olaf Landsiedel*

Main category: cs.CV

TL;DR: ThinkingViT是一种嵌套ViT架构，通过动态调整计算资源提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统嵌套Transformer对所有输入分配相同计算资源导致的效率问题。

Method: 采用渐进式思维阶段和Token Recycling机制，动态激活注意力头。

Result: 在相同计算量下，准确率提升2.0-2.9个百分点。

Conclusion: ThinkingViT高效且可作为插件升级现有ViT。

Abstract: Vision Transformers deliver state-of-the-art performance, yet their fixed
computational budget prevents scalable deployment across heterogeneous
hardware. Recent nested Transformer architectures mitigate this by embedding
nested subnetworks within a single model to enable scalable inference. However,
these models allocate the same amount of compute to all inputs, regardless of
their complexity, which leads to inefficiencies. To address this, we introduce
ThinkingViT, a nested ViT architecture that employs progressive thinking stages
to dynamically adjust inference computation based on input difficulty.
ThinkingViT initiates inference by activating a small subset of the most
important attention heads and terminates early if predictions reach sufficient
certainty. Otherwise, it activates additional attention heads and re-evaluates
the input. At the core of ThinkingViT is our Token Recycling mechanism, which
conditions each subsequent inference stage on the embeddings from the previous
stage, enabling progressive improvement. Due to its backbone-preserving design,
ThinkingViT also serves as a plugin upgrade for vanilla ViT. Experiments show
that ThinkingViT surpasses nested baselines by up to 2.0 percentage points
(p.p.) in accuracy at the same throughput and by up to 2.9 p.p. at equal GMACs
on ImageNet-1K. The source code is available at
https://github.com/ds-kiel/ThinkingViT.

</details>


### [17] [LLM-Guided Agentic Object Detection for Open-World Understanding](https://arxiv.org/abs/2507.10844)
*Furkan Mumcu,Michael J. Jones,Anoop Cherian,Yasin Yilmaz*

Main category: cs.CV

TL;DR: 提出了一种基于LLM的自主目标检测框架（LAOD），通过动态生成场景特定对象名称，实现无需标签的零样本检测。


<details>
  <summary>Details</summary>
Motivation: 传统目标检测依赖固定类别集，灵活性不足；现有开放世界/词汇检测方法存在语义标签缺失或依赖用户提示的问题。

Method: 利用LLM生成场景对象名称，结合开放词汇检测器进行定位，引入CAAP和SNAP评估指标。

Result: 在LVIS、COCO和COCO-OOD数据集上验证了方法的有效性，能检测并命名新对象。

Conclusion: LAOD框架提升了开放世界理解的自主性和适应性。

Abstract: Object detection traditionally relies on fixed category sets, requiring
costly re-training to handle novel objects. While Open-World and
Open-Vocabulary Object Detection (OWOD and OVOD) improve flexibility, OWOD
lacks semantic labels for unknowns, and OVOD depends on user prompts, limiting
autonomy. We propose an LLM-guided agentic object detection (LAOD) framework
that enables fully label-free, zero-shot detection by prompting a Large
Language Model (LLM) to generate scene-specific object names. These are passed
to an open-vocabulary detector for localization, allowing the system to adapt
its goals dynamically. We introduce two new metrics, Class-Agnostic Average
Precision (CAAP) and Semantic Naming Average Precision (SNAP), to separately
evaluate localization and naming. Experiments on LVIS, COCO, and COCO-OOD
validate our approach, showing strong performance in detecting and naming novel
objects. Our method offers enhanced autonomy and adaptability for open-world
understanding.

</details>


### [18] [Winsor-CAM: Human-Tunable Visual Explanations from Deep Networks via Layer-Wise Winsorization](https://arxiv.org/abs/2507.10846)
*Casey Wall,Longwei Wang,Rodrigue Rizk,KC Santosh*

Main category: cs.CV

TL;DR: Winsor-CAM是一种基于Grad-CAM的改进方法，通过聚合所有卷积层信息并应用Winsorization技术生成更鲁棒和连贯的显著性图。


<details>
  <summary>Details</summary>
Motivation: 解释CNN决策过程对高风险领域至关重要，但现有方法如Grad-CAM可能掩盖重要语义或放大噪声。

Method: 提出Winsor-CAM，通过Winsorization技术衰减异常值，并允许用户通过阈值调整语义层次。

Result: 在PASCAL VOC 2012数据集上，Winsor-CAM生成更可解释的热图，并在定位指标上优于Grad-CAM。

Conclusion: Winsor-CAM通过多层解释和用户控制，推动了可信AI的发展。

Abstract: Interpreting the decision-making process of Convolutional Neural Networks
(CNNs) is critical for deploying models in high-stakes domains.
Gradient-weighted Class Activation Mapping (Grad-CAM) is a widely used method
for visual explanations, yet it typically focuses on the final convolutional
layer or na\"ively averages across layers, strategies that can obscure
important semantic cues or amplify irrelevant noise. We propose Winsor-CAM, a
novel, human-tunable extension of Grad-CAM that generates robust and coherent
saliency maps by aggregating information across all convolutional layers. To
mitigate the influence of noisy or extreme attribution values, Winsor-CAM
applies Winsorization, a percentile-based outlier attenuation technique. A
user-controllable threshold allows for semantic-level tuning, enabling flexible
exploration of model behavior across representational hierarchies. Evaluations
on standard architectures (ResNet50, DenseNet121, VGG16, InceptionV3) using the
PASCAL VOC 2012 dataset demonstrate that Winsor-CAM produces more interpretable
heatmaps and achieves superior performance in localization metrics, including
intersection-over-union and center-of-mass alignment, when compared to Grad-CAM
and uniform layer-averaging baselines. Winsor-CAM advances the goal of
trustworthy AI by offering interpretable, multi-layer insights with
human-in-the-loop control.

</details>


### [19] [Sparse Fine-Tuning of Transformers for Generative Tasks](https://arxiv.org/abs/2507.10855)
*Wei Chen,Jingxi Yu,Zichen Miao,Qiang Qiu*

Main category: cs.CV

TL;DR: 该论文提出了一种基于稀疏编码的微调框架，通过稀疏组合特征字典原子来改进模型的可解释性和任务适应性。


<details>
  <summary>Details</summary>
Motivation: 现有微调方法难以解释模型参数更新的贡献，因此需要一种更透明的方法来理解模型如何适应新任务。

Method: 采用稀疏编码框架，将微调特征表示为特征字典原子的稀疏组合，稀疏系数用于指示原子重要性。

Result: 该方法在图像编辑和文本到图像概念定制任务中表现优异，提升了文本对齐和目标概念构建的效率。

Conclusion: 稀疏编码框架为模型微调提供了更高的可解释性和任务适应性，优于传统密集参数更新方法。

Abstract: Large pre-trained transformers have revolutionized artificial intelligence
across various domains, and fine-tuning remains the dominant approach for
adapting these models to downstream tasks due to the cost of training from
scratch. However, in existing fine-tuning methods, the updated representations
are formed as a dense combination of modified parameters, making it challenging
to interpret their contributions and understand how the model adapts to new
tasks. In this work, we introduce a fine-tuning framework inspired by sparse
coding, where fine-tuned features are represented as a sparse combination of
basic elements, i.e., feature dictionary atoms. The feature dictionary atoms
function as fundamental building blocks of the representation, and tuning atoms
allows for seamless adaptation to downstream tasks. Sparse coefficients then
serve as indicators of atom importance, identifying the contribution of each
atom to the updated representation. Leveraging the atom selection capability of
sparse coefficients, we first demonstrate that our method enhances image
editing performance by improving text alignment through the removal of
unimportant feature dictionary atoms. Additionally, we validate the
effectiveness of our approach in the text-to-image concept customization task,
where our method efficiently constructs the target concept using a sparse
combination of feature dictionary atoms, outperforming various baseline
fine-tuning methods.

</details>


### [20] [A Lightweight and Robust Framework for Real-Time Colorectal Polyp Detection Using LOF-Based Preprocessing and YOLO-v11n](https://arxiv.org/abs/2507.10864)
*Saadat Behzadi,Danial Sharifrazi,Bita Mesbahzadeh,Javad Hassannataj Joloudarid,Roohallah Alizadehsani*

Main category: cs.CV

TL;DR: 该研究提出了一种结合局部离群因子（LOF）和YOLO-v11n的轻量级框架，用于结直肠息肉检测，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 结直肠癌是全球主要死因之一，及时准确的息肉检测对诊断和预防至关重要。

Method: 使用LOF算法过滤噪声数据，结合YOLO-v11n模型，在五个公开数据集上测试，并通过5折交叉验证和增强策略优化模型。

Result: 精度95.83%，召回率91.85%，F1分数93.48%，mAP@0.5为96.48%，mAP@0.5:0.95为77.75%，性能优于现有方法。

Conclusion: 该方法适合临床实时结肠镜检查，强调了数据预处理和模型效率在医学影像AI系统中的重要性。

Abstract: Objectives: Timely and accurate detection of colorectal polyps plays a
crucial role in diagnosing and preventing colorectal cancer, a major cause of
mortality worldwide. This study introduces a new, lightweight, and efficient
framework for polyp detection that combines the Local Outlier Factor (LOF)
algorithm for filtering noisy data with the YOLO-v11n deep learning model.
  Study design: An experimental study leveraging deep learning and outlier
removal techniques across multiple public datasets.
  Methods: The proposed approach was tested on five diverse and publicly
available datasets: CVC-ColonDB, CVC-ClinicDB, Kvasir-SEG, ETIS, and EndoScene.
Since these datasets originally lacked bounding box annotations, we converted
their segmentation masks into suitable detection labels. To enhance the
robustness and generalizability of our model, we apply 5-fold cross-validation
and remove anomalous samples using the LOF method configured with 30 neighbors
and a contamination ratio of 5%. Cleaned data are then fed into YOLO-v11n, a
fast and resource-efficient object detection architecture optimized for
real-time applications. We train the model using a combination of modern
augmentation strategies to improve detection accuracy under diverse conditions.
  Results: Our approach significantly improves polyp localization performance,
achieving a precision of 95.83%, recall of 91.85%, F1-score of 93.48%, mAP@0.5
of 96.48%, and mAP@0.5:0.95 of 77.75%. Compared to previous YOLO-based methods,
our model demonstrates enhanced accuracy and efficiency.
  Conclusions: These results suggest that the proposed method is well-suited
for real-time colonoscopy support in clinical settings. Overall, the study
underscores how crucial data preprocessing and model efficiency are when
designing effective AI systems for medical imaging.

</details>


### [21] [Trexplorer Super: Topologically Correct Centerline Tree Tracking of Tubular Objects in CT Volumes](https://arxiv.org/abs/2507.10881)
*Roman Naeem,David Hagerman,Jennifer Alvén,Lennart Svensson,Fredrik Kahl*

Main category: cs.CV

TL;DR: Trexplorer Super是一种改进的3D医学图像中心线追踪模型，解决了重复分支和过早终止问题，并在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 准确追踪管状树结构（如血管和气道）对医学任务至关重要，但现有模型存在重复分支和过早终止的问题。

Method: 提出Trexplorer Super，通过新技术改进性能，并开发了三个数据集（一个合成，两个真实）用于评估。

Result: Trexplorer Super在所有数据集上优于现有方法，但合成数据的强表现不一定适用于真实数据。

Conclusion: Trexplorer Super显著提升了中心线追踪性能，数据集和代码已公开。

Abstract: Tubular tree structures, such as blood vessels and airways, are essential in
human anatomy and accurately tracking them while preserving their topology is
crucial for various downstream tasks. Trexplorer is a recurrent model designed
for centerline tracking in 3D medical images but it struggles with predicting
duplicate branches and terminating tracking prematurely. To address these
issues, we present Trexplorer Super, an enhanced version that notably improves
performance through novel advancements. However, evaluating centerline tracking
models is challenging due to the lack of public datasets. To enable thorough
evaluation, we develop three centerline datasets, one synthetic and two real,
each with increasing difficulty. Using these datasets, we conduct a
comprehensive evaluation of existing state-of-the-art (SOTA) models and compare
them with our approach. Trexplorer Super outperforms previous SOTA models on
every dataset. Our results also highlight that strong performance on synthetic
data does not necessarily translate to real datasets. The code and datasets are
available at https://github.com/RomStriker/Trexplorer-Super.

</details>


### [22] [Commuting Distance Regularization for Timescale-Dependent Label Inconsistency in EEG Emotion Recognition](https://arxiv.org/abs/2507.10895)
*Xiaocong Zeng,Craig Michoski,Yan Pang,Dongyang Kuang*

Main category: cs.CV

TL;DR: 论文提出两种正则化策略（LVL和LGCL）解决EEG情感识别中的时间尺度标签不一致问题，并通过实验验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决EEG情感识别中时间尺度标签不一致（TsDLI）问题，提升模型泛化性和可解释性。

Method: 提出Local Variation Loss (LVL)和Local-Global Consistency Loss (LGCL)两种正则化方法，结合数学原理和图论框架。

Result: 在DREAMER和DEAP数据集上，LVL和LGCL表现优于现有方法，LVL综合排名最佳。

Conclusion: 提出的方法有效解决了TsDLI问题，平衡了预测性能和可解释性。

Abstract: In this work, we address the often-overlooked issue of Timescale Dependent
Label Inconsistency (TsDLI) in training neural network models for EEG-based
human emotion recognition. To mitigate TsDLI and enhance model generalization
and explainability, we propose two novel regularization strategies: Local
Variation Loss (LVL) and Local-Global Consistency Loss (LGCL). Both methods
incorporate classical mathematical principles--specifically, functions of
bounded variation and commute-time distances--within a graph theoretic
framework. Complementing our regularizers, we introduce a suite of new
evaluation metrics that better capture the alignment between temporally local
predictions and their associated global emotion labels. We validate our
approach through comprehensive experiments on two widely used EEG emotion
datasets, DREAMER and DEAP, across a range of neural architectures including
LSTM and transformer-based models. Performance is assessed using five distinct
metrics encompassing both quantitative accuracy and qualitative consistency.
Results consistently show that our proposed methods outperform state-of-the-art
baselines, delivering superior aggregate performance and offering a principled
trade-off between interpretability and predictive power under label
inconsistency. Notably, LVL achieves the best aggregate rank across all
benchmarked backbones and metrics, while LGCL frequently ranks the second,
highlighting the effectiveness of our framework.

</details>


### [23] [GeoDistill: Geometry-Guided Self-Distillation for Weakly Supervised Cross-View Localization](https://arxiv.org/abs/2507.10935)
*Shaowen Tong,Zimin Xia,Alexandre Alahi,Xuming He,Yujiao Shi*

Main category: cs.CV

TL;DR: GeoDistill提出了一种几何引导的弱监督自蒸馏框架，通过教师-学生学习和基于视场的掩码增强局部特征学习，提升跨视图定位性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有跨视图定位方法依赖昂贵全监督标注的问题，提出一种更高效、可扩展的解决方案。

Method: 采用教师-学生学习框架，教师模型定位全景图像，学生模型通过基于视场的掩码学习局部特征，并通过预测对齐提升性能。

Result: 实验表明GeoDistill显著提升了定位性能，并引入了一种无需精确平面位置标注的方向估计网络。

Conclusion: GeoDistill为跨视图定位提供了一种高效且可扩展的解决方案，适用于实际应用场景。

Abstract: Cross-view localization, the task of estimating a camera's
3-degrees-of-freedom (3-DoF) pose by aligning ground-level images with
satellite images, is crucial for large-scale outdoor applications like
autonomous navigation and augmented reality. Existing methods often rely on
fully supervised learning, which requires costly ground-truth pose annotations.
In this work, we propose GeoDistill, a Geometry guided weakly supervised self
distillation framework that uses teacher-student learning with Field-of-View
(FoV)-based masking to enhance local feature learning for robust cross-view
localization. In GeoDistill, the teacher model localizes a panoramic image,
while the student model predicts locations from a limited FoV counterpart
created by FoV-based masking. By aligning the student's predictions with those
of the teacher, the student focuses on key features like lane lines and ignores
textureless regions, such as roads. This results in more accurate predictions
and reduced uncertainty, regardless of whether the query images are panoramas
or limited FoV images. Our experiments show that GeoDistill significantly
improves localization performance across different frameworks. Additionally, we
introduce a novel orientation estimation network that predicts relative
orientation without requiring precise planar position ground truth. GeoDistill
provides a scalable and efficient solution for real-world cross-view
localization challenges. Code and model can be found at
https://github.com/tongshw/GeoDistill.

</details>


### [24] [Graph Aggregation Prototype Learning for Semantic Change Detection in Remote Sensing](https://arxiv.org/abs/2507.10938)
*Zhengyi Xu,Haoran Wu,Wen Jiang,Jie Geng*

Main category: cs.CV

TL;DR: 论文提出了一种名为GAPL-SCD的图聚合原型学习方法，用于解决语义变化检测中的多任务优化问题，通过自适应权重分配和梯度旋转提升性能。


<details>
  <summary>Details</summary>
Motivation: 语义变化检测（SCD）需要同时优化多个任务，容易因任务间冲突导致负迁移，因此需要一种方法缓解这种冲突并提升多任务学习能力。

Method: 提出GAPL-SCD框架，结合语义分割和变化检测的主任务与图聚合原型学习的辅助任务，使用自适应权重分配和梯度旋转优化训练。

Result: 在SECOND和Landsat-SCD数据集上，该方法实现了最先进的性能，显著提升了SCD任务的准确性和鲁棒性。

Conclusion: GAPL-SCD通过多任务联合优化和特征交互模块，有效解决了语义变化检测中的任务冲突问题，提升了模型性能。

Abstract: Semantic change detection (SCD) extends the binary change detection task to
provide not only the change locations but also the detailed "from-to"
categories in multi-temporal remote sensing data. Such detailed semantic
insights into changes offer considerable advantages for a wide array of
applications. However, since SCD involves the simultaneous optimization of
multiple tasks, the model is prone to negative transfer due to task-specific
learning difficulties and conflicting gradient flows. To address this issue, we
propose Graph Aggregation Prototype Learning for Semantic Change Detection in
remote sensing(GAPL-SCD). In this framework, a multi-task joint optimization
method is designed to optimize the primary task of semantic segmentation and
change detection, along with the auxiliary task of graph aggregation prototype
learning. Adaptive weight allocation and gradient rotation methods are used to
alleviate the conflict between training tasks and improve multi-task learning
capabilities. Specifically, the graph aggregation prototype learning module
constructs an interaction graph using high-level features. Prototypes serve as
class proxies, enabling category-level domain alignment across time points and
reducing interference from irrelevant changes. Additionally, the proposed
self-query multi-level feature interaction and bi-temporal feature fusion
modules further enhance multi-scale feature representation, improving
performance in complex scenes. Experimental results on the SECOND and
Landsat-SCD datasets demonstrate that our method achieves state-of-the-art
performance, with significant improvements in accuracy and robustness for SCD
task.

</details>


### [25] [Robust ID-Specific Face Restoration via Alignment Learning](https://arxiv.org/abs/2507.10943)
*Yushun Fang,Lu Liu,Xiang Gao,Qiang Hu,Ning Cao,Jianghe Cui,Gang Chen,Xiaoyun Zhang*

Main category: cs.CV

TL;DR: RIDFR是一种基于扩散模型的ID特定人脸修复框架，通过内容注入和身份注入模块，结合对齐学习，显著提升了修复结果的视觉质量和身份保真度。


<details>
  <summary>Details</summary>
Motivation: 当前人脸修复方法在身份保真度方面存在不足，尤其是面对身份模糊输入和随机生成过程时。

Method: RIDFR利用预训练扩散模型，结合内容注入模块和身份注入模块，并通过对齐学习抑制ID无关语义干扰。

Result: 实验表明，RIDFR在视觉质量和身份保真度上优于现有方法，具有强鲁棒性。

Conclusion: RIDFR通过创新的模块设计和对齐学习，有效解决了身份保真度问题，为人脸修复提供了新思路。

Abstract: The latest developments in Face Restoration have yielded significant
advancements in visual quality through the utilization of diverse diffusion
priors. Nevertheless, the uncertainty of face identity introduced by
identity-obscure inputs and stochastic generative processes remains unresolved.
To address this challenge, we present Robust ID-Specific Face Restoration
(RIDFR), a novel ID-specific face restoration framework based on diffusion
models. Specifically, RIDFR leverages a pre-trained diffusion model in
conjunction with two parallel conditioning modules. The Content Injection
Module inputs the severely degraded image, while the Identity Injection Module
integrates the specific identity from a given image. Subsequently, RIDFR
incorporates Alignment Learning, which aligns the restoration results from
multiple references with the same identity in order to suppress the
interference of ID-irrelevant face semantics (e.g. pose, expression, make-up,
hair style). Experiments demonstrate that our framework outperforms the
state-of-the-art methods, reconstructing high-quality ID-specific results with
high identity fidelity and demonstrating strong robustness.

</details>


### [26] [Women Sport Actions Dataset for Visual Classification Using Small Scale Training Data](https://arxiv.org/abs/2507.10969)
*Palash Ray,Mahuya Sasmal,Asish Bera*

Main category: cs.CV

TL;DR: 提出新数据集WomenSports用于女性运动分类，并设计基于CNN和通道注意力的深度学习方法，取得89.15%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 现有女性运动动作数据集不足，缺乏多样性和变化，限制了相关研究。

Method: 提出WomenSports数据集，并设计CNN结合通道注意力机制进行特征提取和优化。

Result: 在WomenSports数据集上，ResNet-50达到89.15%的top-1分类准确率。

Conclusion: 新数据集和深度学习方法有效解决了女性运动分类问题，数据集已公开供研究使用。

Abstract: Sports action classification representing complex body postures and
player-object interactions is an emerging area in image-based sports analysis.
Some works have contributed to automated sports action recognition using
machine learning techniques over the past decades. However, sufficient image
datasets representing women sports actions with enough intra- and inter-class
variations are not available to the researchers. To overcome this limitation,
this work presents a new dataset named WomenSports for women sports
classification using small-scale training data. This dataset includes a variety
of sports activities, covering wide variations in movements, environments, and
interactions among players. In addition, this study proposes a convolutional
neural network (CNN) for deep feature extraction. A channel attention scheme
upon local contextual regions is applied to refine and enhance feature
representation. The experiments are carried out on three different sports
datasets and one dance dataset for generalizing the proposed algorithm, and the
performances on these datasets are noteworthy. The deep learning method
achieves 89.15% top-1 classification accuracy using ResNet-50 on the proposed
WomenSports dataset, which is publicly available for research at Mendeley Data.

</details>


### [27] [Conceptualizing Multi-scale Wavelet Attention and Ray-based Encoding for Human-Object Interaction Detection](https://arxiv.org/abs/2507.10977)
*Quan Bi Pay,Vishnu Monn Baskaran,Junn Yong Loo,KokSheik Wong,Simon See*

Main category: cs.CV

TL;DR: 提出了一种基于小波注意力机制和射线编码器的新型HOI检测架构，解决了现有方法效率低和资源消耗大的问题。


<details>
  <summary>Details</summary>
Motivation: 现有HOI检测器在效率和准确性上存在不足，需要资源密集型训练和低效架构。

Method: 设计小波注意力机制主干和射线编码器，聚合低阶和高阶交互特征，优化多尺度注意力。

Result: 在ImageNet和HICO-DET等基准数据集上验证了架构的有效性。

Conclusion: 提出的架构显著提升了HOI检测的效率和准确性，代码已开源。

Abstract: Human-object interaction (HOI) detection is essential for accurately
localizing and characterizing interactions between humans and objects,
providing a comprehensive understanding of complex visual scenes across various
domains. However, existing HOI detectors often struggle to deliver reliable
predictions efficiently, relying on resource-intensive training methods and
inefficient architectures. To address these challenges, we conceptualize a
wavelet attention-like backbone and a novel ray-based encoder architecture
tailored for HOI detection. Our wavelet backbone addresses the limitations of
expressing middle-order interactions by aggregating discriminative features
from the low- and high-order interactions extracted from diverse convolutional
filters. Concurrently, the ray-based encoder facilitates multi-scale attention
by optimizing the focus of the decoder on relevant regions of interest and
mitigating computational overhead. As a result of harnessing the attenuated
intensity of learnable ray origins, our decoder aligns query embeddings with
emphasized regions of interest for accurate predictions. Experimental results
on benchmark datasets, including ImageNet and HICO-DET, showcase the potential
of our proposed architecture. The code is publicly available at
[https://github.com/henry-pay/RayEncoder].

</details>


### [28] [Mind the Gap: Bridging Occlusion in Gait Recognition via Residual Gap Correction](https://arxiv.org/abs/2507.10978)
*Ayush Gupta,Siyuan Huang,Rama Chellappa*

Main category: cs.CV

TL;DR: RG-Gait是一种通过残差学习解决遮挡步态识别问题的方法，同时保持对完整步态的识别性能。


<details>
  <summary>Details</summary>
Motivation: 当前步态识别方法未解决遮挡问题，且现有方法需成对遮挡和完整序列，不实用。

Method: 将遮挡步态建模为完整步态表示的残差偏差，通过残差学习网络自适应整合残差。

Result: 在Gait3D、GREW和BRIAR数据集上验证，显著提升遮挡步态识别性能且不影响完整步态识别。

Conclusion: 残差学习是解决遮挡步态识别并保留完整步态性能的有效方法。

Abstract: Gait is becoming popular as a method of person re-identification because of
its ability to identify people at a distance. However, most current works in
gait recognition do not address the practical problem of occlusions. Among
those which do, some require paired tuples of occluded and holistic sequences,
which are impractical to collect in the real world. Further, these approaches
work on occlusions but fail to retain performance on holistic inputs. To
address these challenges, we propose RG-Gait, a method for residual correction
for occluded gait recognition with holistic retention. We model the problem as
a residual learning task, conceptualizing the occluded gait signature as a
residual deviation from the holistic gait representation. Our proposed network
adaptively integrates the learned residual, significantly improving performance
on occluded gait sequences without compromising the holistic recognition
accuracy. We evaluate our approach on the challenging Gait3D, GREW and BRIAR
datasets and show that learning the residual can be an effective technique to
tackle occluded gait recognition with holistic retention.

</details>


### [29] [SpaRTAN: Spatial Reinforcement Token-based Aggregation Network for Visual Recognition](https://arxiv.org/abs/2507.10999)
*Quan Bi Pay,Vishnu Monn Baskaran,Junn Yong Loo,KokSheik Wong,Simon See*

Main category: cs.CV

TL;DR: SpaRTAN是一种轻量级架构设计，通过多阶空间特征和通道聚合模块提升性能，参数效率高。


<details>
  <summary>Details</summary>
Motivation: 解决CNN和Transformer中简单特征偏好和信息冗余问题。

Method: 使用可变感受野的核和波式通道聚合模块。

Result: ImageNet-1k准确率77.7%，COCO AP 50.0%，参数效率显著。

Conclusion: SpaRTAN通过高效设计实现高性能，代码开源。

Abstract: The resurgence of convolutional neural networks (CNNs) in visual recognition
tasks, exemplified by ConvNeXt, has demonstrated their capability to rival
transformer-based architectures through advanced training methodologies and
ViT-inspired design principles. However, both CNNs and transformers exhibit a
simplicity bias, favoring straightforward features over complex structural
representations. Furthermore, modern CNNs often integrate MLP-like blocks akin
to those in transformers, but these blocks suffer from significant information
redundancies, necessitating high expansion ratios to sustain competitive
performance. To address these limitations, we propose SpaRTAN, a lightweight
architectural design that enhances spatial and channel-wise information
processing. SpaRTAN employs kernels with varying receptive fields, controlled
by kernel size and dilation factor, to capture discriminative multi-order
spatial features effectively. A wave-based channel aggregation module further
modulates and reinforces pixel interactions, mitigating channel-wise
redundancies. Combining the two modules, the proposed network can efficiently
gather and dynamically contextualize discriminative features. Experimental
results in ImageNet and COCO demonstrate that SpaRTAN achieves remarkable
parameter efficiency while maintaining competitive performance. In particular,
on the ImageNet-1k benchmark, SpaRTAN achieves 77. 7% accuracy with only 3.8M
parameters and approximately 1.0 GFLOPs, demonstrating its ability to deliver
strong performance through an efficient design. On the COCO benchmark, it
achieves 50.0% AP, surpassing the previous benchmark by 1.2% with only 21.5M
parameters. The code is publicly available at
[https://github.com/henry-pay/SpaRTAN].

</details>


### [30] [Bridge Feature Matching and Cross-Modal Alignment with Mutual-filtering for Zero-shot Anomaly Detection](https://arxiv.org/abs/2507.11003)
*Yuhu Bai,Jiangning Zhang,Yunkang Cao,Guangyuan Lu,Qingdong He,Xiangtai Li,Guanzhong Tian*

Main category: cs.CV

TL;DR: FiSeCLIP利用CLIP模型进行零样本异常检测，通过特征匹配和跨模态对齐，结合批次内图像作为参考，并利用文本信息过滤噪声，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 零样本异常检测（ZSAD）在实际应用中需求广泛，但现有方法在性能和适应性上存在不足，需要更高效的解决方案。

Method: 结合特征匹配和跨模态对齐，利用批次内图像作为参考，并通过文本信息过滤噪声，同时恢复CLIP的局部语义相关性以提升细粒度检测。

Result: 在MVTec-AD等基准测试中，FiSeCLIP在异常分类和分割任务上表现优异，AU-ROC和F1-max分别提升4.6%和5.7%。

Conclusion: FiSeCLIP为零样本异常检测提供了更强基线，展示了CLIP模型在ZSAD任务中的潜力。

Abstract: With the advent of vision-language models (e.g., CLIP) in zero- and few-shot
settings, CLIP has been widely applied to zero-shot anomaly detection (ZSAD) in
recent research, where the rare classes are essential and expected in many
applications. This study introduces \textbf{FiSeCLIP} for ZSAD with
training-free \textbf{CLIP}, combining the feature matching with the
cross-modal alignment. Testing with the entire dataset is impractical, while
batch-based testing better aligns with real industrial needs, and images within
a batch can serve as mutual reference points. Accordingly, FiSeCLIP utilizes
other images in the same batch as reference information for the current image.
However, the lack of labels for these references can introduce ambiguity, we
apply text information to \textbf{fi}lter out noisy features. In addition, we
further explore CLIP's inherent potential to restore its local
\textbf{se}mantic correlation, adapting it for fine-grained anomaly detection
tasks to enable a more accurate filtering process. Our approach exhibits
superior performance for both anomaly classification and segmentation on
anomaly detection benchmarks, building a stronger baseline for the direction,
e.g., on MVTec-AD, FiSeCLIP outperforms the SOTA AdaCLIP by
+4.6\%$\uparrow$/+5.7\%$\uparrow$ in segmentation metrics AU-ROC/$F_1$-max.

</details>


### [31] [Semantically Informed Salient Regions Guided Radiology Report Generation](https://arxiv.org/abs/2507.11015)
*Zeyi Hou,Zeqiang Wei,Ruixin Yan,Ning Lang,Xiuzhuang Zhou*

Main category: cs.CV

TL;DR: 提出了一种基于语义显著区域的放射学报告生成方法（SISRNet），通过关注医学关键区域，生成更准确的报告。


<details>
  <summary>Details</summary>
Motivation: 现有方法因数据偏差生成不准确的报告，限制了临床应用。

Method: 利用细粒度跨模态语义识别医学关键区域，并在图像建模和报告生成中聚焦这些区域。

Result: 在IU-Xray和MIMIC-CXR数据集上表现优于同类方法。

Conclusion: SISRNet通过关注医学关键区域，有效缓解数据偏差，生成更准确的临床报告。

Abstract: Recent advances in automated radiology report generation from chest X-rays
using deep learning algorithms have the potential to significantly reduce the
arduous workload of radiologists. However, due to the inherent massive data
bias in radiology images, where abnormalities are typically subtle and sparsely
distributed, existing methods often produce fluent yet medically inaccurate
reports, limiting their applicability in clinical practice. To address this
issue effectively, we propose a Semantically Informed Salient Regions-guided
(SISRNet) report generation method. Specifically, our approach explicitly
identifies salient regions with medically critical characteristics using
fine-grained cross-modal semantics. Then, SISRNet systematically focuses on
these high-information regions during both image modeling and report
generation, effectively capturing subtle abnormal findings, mitigating the
negative impact of data bias, and ultimately generating clinically accurate
reports. Compared to its peers, SISRNet demonstrates superior performance on
widely used IU-Xray and MIMIC-CXR datasets.

</details>


### [32] [Human-Guided Shade Artifact Suppression in CBCT-to-MDCT Translation via Schrödinger Bridge with Conditional Diffusion](https://arxiv.org/abs/2507.11025)
*Sung Ho Kang,Hyun-Cheol Park*

Main category: cs.CV

TL;DR: 提出了一种基于Schrodinger Bridge的CBCT-to-MDCT翻译框架，结合GAN先验和人类引导的条件扩散，通过边界一致性和人类反馈优化生成结果。


<details>
  <summary>Details</summary>
Motivation: 解决传统GAN或扩散模型在医学图像翻译中解剖保真度和感知可控性的不足，同时结合人类偏好优化临床结果。

Method: 采用Schrodinger Bridge框架，整合GAN先验和条件扩散，通过边界一致性和分类器自由引导（CFG）结合人类反馈，迭代优化生成过程。

Result: 在临床数据集上，该方法在RMSE、SSIM、LPIPS和Dice指标上表现优异，仅需10步采样，优于现有GAN和微调方法。

Conclusion: 该框架在实时医学图像翻译中表现出高效性和临床偏好对齐的潜力。

Abstract: We present a novel framework for CBCT-to-MDCT translation, grounded in the
Schrodinger Bridge (SB) formulation, which integrates GAN-derived priors with
human-guided conditional diffusion. Unlike conventional GANs or diffusion
models, our approach explicitly enforces boundary consistency between CBCT
inputs and pseudo targets, ensuring both anatomical fidelity and perceptual
controllability. Binary human feedback is incorporated via classifier-free
guidance (CFG), effectively steering the generative process toward clinically
preferred outcomes. Through iterative refinement and tournament-based
preference selection, the model internalizes human preferences without relying
on a reward model. Subtraction image visualizations reveal that the proposed
method selectively attenuates shade artifacts in key anatomical regions while
preserving fine structural detail. Quantitative evaluations further demonstrate
superior performance across RMSE, SSIM, LPIPS, and Dice metrics on clinical
datasets -- outperforming prior GAN- and fine-tuning-based feedback methods --
while requiring only 10 sampling steps. These findings underscore the
effectiveness and efficiency of our framework for real-time, preference-aligned
medical image translation.

</details>


### [33] [Personalized OVSS: Understanding Personal Concept in Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2507.11030)
*Sunghyun Park,Jungsoo Lee,Shubhankar Borse,Munawar Hayat,Sungha Choi,Kyuwoong Hwang,Fatih Porikli*

Main category: cs.CV

TL;DR: 论文提出了一种个性化开放词汇语义分割任务，通过文本提示调优和负掩模提案提升对用户特定兴趣区域的识别能力。


<details>
  <summary>Details</summary>
Motivation: 解决开放词汇语义分割无法理解个性化文本（如‘我的马克杯’）的问题，以识别用户特定兴趣区域。

Method: 采用文本提示调优和负掩模提案，减少误预测，并通过视觉嵌入增强文本提示表示。

Result: 在FSS$^\text{per}$、CUB$^\text{per}$和ADE$^\text{per}$等新基准上表现优越。

Conclusion: 该方法在提升个性化分割能力的同时，保持了原始开放词汇语义分割的性能。

Abstract: While open-vocabulary semantic segmentation (OVSS) can segment an image into
semantic regions based on arbitrarily given text descriptions even for classes
unseen during training, it fails to understand personal texts (e.g., `my mug
cup') for segmenting regions of specific interest to users. This paper
addresses challenges like recognizing `my mug cup' among `multiple mug cups'.
To overcome this challenge, we introduce a novel task termed
\textit{personalized open-vocabulary semantic segmentation} and propose a text
prompt tuning-based plug-in method designed to recognize personal visual
concepts using a few pairs of images and masks, while maintaining the
performance of the original OVSS. Based on the observation that reducing false
predictions is essential when applying text prompt tuning to this task, our
proposed method employs `negative mask proposal' that captures visual concepts
other than the personalized concept. We further improve the performance by
enriching the representation of text prompts by injecting visual embeddings of
the personal concept into them. This approach enhances personalized OVSS
without compromising the original OVSS performance. We demonstrate the
superiority of our method on our newly established benchmarks for this task,
including FSS$^\text{per}$, CUB$^\text{per}$, and ADE$^\text{per}$.

</details>


### [34] [Efficient Dual-domain Image Dehazing with Haze Prior Perception](https://arxiv.org/abs/2507.11035)
*Lirong Zheng,Yanshan Li,Rui Yu,Kaihao Zhang*

Main category: cs.CV

TL;DR: DGFDNet提出了一种双域去雾网络，结合空间和频率域特征，通过物理引导的退化对齐和自适应频率调制，显著提升了去雾性能和实时性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂雾霾条件下性能不足，且计算成本高，需要一种更高效、鲁棒的去雾方法。

Method: DGFDNet包含HAFM模块（自适应增强雾霾相关频率成分）和MGAM模块（多尺度特征融合），并通过PCGB分支迭代优化先验。

Result: 在四个基准数据集上，DGFDNet实现了最先进的性能，兼具鲁棒性和实时效率。

Conclusion: DGFDNet通过双域协同和物理引导，显著提升了去雾效果和实用性。

Abstract: Transformer-based models exhibit strong global modeling capabilities in
single-image dehazing, but their high computational cost limits real-time
applicability. Existing methods predominantly rely on spatial-domain features
to capture long-range dependencies, which are computationally expensive and
often inadequate under complex haze conditions. While some approaches introduce
frequency-domain cues, the weak coupling between spatial and frequency branches
limits the overall performance. To overcome these limitations, we propose the
Dark Channel Guided Frequency-aware Dehazing Network (DGFDNet), a novel
dual-domain framework that performs physically guided degradation alignment
across spatial and frequency domains. At its core, the DGFDBlock comprises two
key modules: 1) the Haze-Aware Frequency Modulator (HAFM), which generates a
pixel-level haze confidence map from dark channel priors to adaptively enhance
haze-relevant frequency components, thereby achieving global degradation-aware
spectral modulation; 2) the Multi-level Gating Aggregation Module (MGAM), which
fuses multi-scale features through diverse convolutional kernels and hybrid
gating mechanisms to recover fine structural details. Additionally, a Prior
Correction Guidance Branch (PCGB) incorporates a closed-loop feedback
mechanism, enabling iterative refinement of the prior by intermediate dehazed
features and significantly improving haze localization accuracy, especially in
challenging outdoor scenes. Extensive experiments on four benchmark haze
datasets demonstrate that DGFDNet achieves state-of-the-art performance with
superior robustness and real-time efficiency. Code is available at:
https://github.com/Dilizlr/DGFDNet.

</details>


### [35] [A Multi-View High-Resolution Foot-Ankle Complex Point Cloud Dataset During Gait for Occlusion-Robust 3D Completion](https://arxiv.org/abs/2507.11037)
*Jie-Wen Li,Zi-Han Ye,Qingyuan Zhou,Jiayi Song,Ying He,Ben Fei,Wen-Ming Chen*

Main category: cs.CV

TL;DR: FootGait3D是一个专注于足踝区域的高分辨率点云数据集，用于研究步态中的3D形状补全任务。


<details>
  <summary>Details</summary>
Motivation: 解决动态步态条件下足踝表面几何数据采集的挑战，如遮挡和视角限制。

Method: 使用五摄像头深度传感系统采集46名受试者的8,403帧点云数据，提供完整和部分视图的足踝重建。

Result: 数据集支持单模态和多模态3D点云补全方法的评估，适用于生物力学研究和临床应用。

Conclusion: FootGait3D为足踝运动建模提供了高精度数据，推动了生物力学、假肢设计和机器人应用的研究。

Abstract: The kinematics analysis of foot-ankle complex during gait is essential for
advancing biomechanical research and clinical assessment. Collecting accurate
surface geometry data from the foot and ankle during dynamic gait conditions is
inherently challenging due to swing foot occlusions and viewing limitations.
Thus, this paper introduces FootGait3D, a novel multi-view dataset of
high-resolution ankle-foot surface point clouds captured during natural gait.
Different from existing gait datasets that typically target whole-body or
lower-limb motion, FootGait3D focuses specifically on the detailed modeling of
the ankle-foot region, offering a finer granularity of motion data. To address
this, FootGait3D consists of 8,403 point cloud frames collected from 46
subjects using a custom five-camera depth sensing system. Each frame includes a
complete 5-view reconstruction of the foot and ankle (serving as ground truth)
along with partial point clouds obtained from only four, three, or two views.
This structured variation enables rigorous evaluation of 3D point cloud
completion methods under varying occlusion levels and viewpoints. Our dataset
is designed for shape completion tasks, facilitating the benchmarking of
state-of-the-art single-modal (e.g., PointTr, SnowflakeNet, Anchorformer) and
multi-modal (e.g., SVDFormer, PointSea, CSDN) completion networks on the
challenge of recovering the full foot geometry from occluded inputs. FootGait3D
has significant potential to advance research in biomechanics and multi-segment
foot modeling, offering a valuable testbed for clinical gait analysis,
prosthetic design, and robotics applications requiring detailed 3D models of
the foot during motion. The dataset is now available at
https://huggingface.co/datasets/ljw285/FootGait3D.

</details>


### [36] [Combining Transformers and CNNs for Efficient Object Detection in High-Resolution Satellite Imagery](https://arxiv.org/abs/2507.11040)
*Nicolas Drapier,Aladine Chetouani,Aurélien Chateigner*

Main category: cs.CV

TL;DR: GLOD是一种基于Transformer的架构，用于高分辨率卫星图像中的目标检测，通过Swin Transformer和新型模块实现高效特征提取和多尺度融合，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决高分辨率卫星图像中目标检测的挑战，提升检测性能并保持计算效率。

Method: 使用Swin Transformer替代CNN主干，结合UpConvMixer块和Fusion Blocks实现端到端特征提取和多尺度融合。

Result: 在xView数据集上达到32.95%的性能，优于现有方法11.46%。

Conclusion: GLOD通过创新设计和优化，显著提升了卫星图像目标检测的性能和效率。

Abstract: We present GLOD, a transformer-first architecture for object detection in
high-resolution satellite imagery. GLOD replaces CNN backbones with a Swin
Transformer for end-to-end feature extraction, combined with novel UpConvMixer
blocks for robust upsampling and Fusion Blocks for multi-scale feature
integration. Our approach achieves 32.95\% on xView, outperforming SOTA methods
by 11.46\%. Key innovations include asymmetric fusion with CBAM attention and a
multi-path head design capturing objects across scales. The architecture is
optimized for satellite imagery challenges, leveraging spatial priors while
maintaining computational efficiency.

</details>


### [37] [Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation](https://arxiv.org/abs/2507.11055)
*Shuchang Ye,Usman Naseem,Mingyuan Meng,Jinman Kim*

Main category: cs.CV

TL;DR: ProLearn框架通过原型驱动的学习方法，解决了医学语言引导分割中文本依赖的问题，提高了在文本数据有限时的分割性能。


<details>
  <summary>Details</summary>
Motivation: 医学语言引导分割依赖于成对的图像-文本输入，导致许多缺乏配对报告的医学分割数据集无法充分利用，且限制了其在临床场景中的应用。

Method: 提出ProLearn框架，引入原型驱动的语义近似（PSA）模块，通过从文本报告中提取语义信息初始化原型空间，支持无文本输入时的语义引导近似。

Result: 在QaTa-COV19、MosMedData+和Kvasir-SEG数据集上，ProLearn在文本有限的情况下优于现有语言引导方法。

Conclusion: ProLearn通过减少文本依赖，扩展了语言引导分割的适用性，为临床实践提供了更灵活的解决方案。

Abstract: Medical language-guided segmentation, integrating textual clinical reports as
auxiliary guidance to enhance image segmentation, has demonstrated significant
improvements over unimodal approaches. However, its inherent reliance on paired
image-text input, which we refer to as ``textual reliance", presents two
fundamental limitations: 1) many medical segmentation datasets lack paired
reports, leaving a substantial portion of image-only data underutilized for
training; and 2) inference is limited to retrospective analysis of cases with
paired reports, limiting its applicability in most clinical scenarios where
segmentation typically precedes reporting. To address these limitations, we
propose ProLearn, the first Prototype-driven Learning framework for
language-guided segmentation that fundamentally alleviates textual reliance. At
its core, in ProLearn, we introduce a novel Prototype-driven Semantic
Approximation (PSA) module to enable approximation of semantic guidance from
textual input. PSA initializes a discrete and compact prototype space by
distilling segmentation-relevant semantics from textual reports. Once
initialized, it supports a query-and-respond mechanism which approximates
semantic guidance for images without textual input, thereby alleviating textual
reliance. Extensive experiments on QaTa-COV19, MosMedData+ and Kvasir-SEG
demonstrate that ProLearn outperforms state-of-the-art language-guided methods
when limited text is available.

</details>


### [38] [Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with Regularized Score Distillation Sampling](https://arxiv.org/abs/2507.11061)
*Hayeon Kim,Ji Ha Jang,Se Young Chun*

Main category: cs.CV

TL;DR: RoMaP是一种新型局部3D高斯编辑框架，通过3D-GALP模块和正则化SDS损失实现精确的局部编辑。


<details>
  <summary>Details</summary>
Motivation: 当前3D神经表示和实例级编辑模型在实现精确局部3D编辑时面临挑战，尤其是高斯溅射技术因多视角2D分割不一致和SDS损失的模糊性而受限。

Method: 提出3D-GALP模块用于生成鲁棒的3D掩码，并结合正则化SDS损失（包括L1锚定损失和其他正则化器）实现局部编辑。

Result: 实验表明，RoMaP在重建和生成的高斯场景中实现了最先进的局部3D编辑效果。

Conclusion: RoMaP为3D高斯编辑提供了更鲁棒和灵活的局部编辑能力。

Abstract: Recent advances in 3D neural representations and instance-level editing
models have enabled the efficient creation of high-quality 3D content. However,
achieving precise local 3D edits remains challenging, especially for Gaussian
Splatting, due to inconsistent multi-view 2D part segmentations and inherently
ambiguous nature of Score Distillation Sampling (SDS) loss. To address these
limitations, we propose RoMaP, a novel local 3D Gaussian editing framework that
enables precise and drastic part-level modifications. First, we introduce a
robust 3D mask generation module with our 3D-Geometry Aware Label Prediction
(3D-GALP), which uses spherical harmonics (SH) coefficients to model
view-dependent label variations and soft-label property, yielding accurate and
consistent part segmentations across viewpoints. Second, we propose a
regularized SDS loss that combines the standard SDS loss with additional
regularizers. In particular, an L1 anchor loss is introduced via our Scheduled
Latent Mixing and Part (SLaMP) editing method, which generates high-quality
part-edited 2D images and confines modifications only to the target region
while preserving contextual coherence. Additional regularizers, such as
Gaussian prior removal, further improve flexibility by allowing changes beyond
the existing context, and robust 3D masking prevents unintended edits.
Experimental results demonstrate that our RoMaP achieves state-of-the-art local
3D editing on both reconstructed and generated Gaussian scenes and objects
qualitatively and quantitatively, making it possible for more robust and
flexible part-level 3D Gaussian editing.

</details>


### [39] [Joint angle model based learning to refine kinematic human pose estimation](https://arxiv.org/abs/2507.11075)
*Chang Peng,Yifei Zhou,Huifeng Xi,Shiqing Huang,Chuangye Chen,Jianming Yang,Bao Yang,Zhenyu Jiang*

Main category: cs.CV

TL;DR: 提出了一种基于关节角度建模的新方法，用于改进无标记人体姿态估计（HPE）中的关键点识别和轨迹平滑问题。


<details>
  <summary>Details</summary>
Motivation: 当前HPE在分析运动学人体姿态时存在关键点识别错误和轨迹随机波动的问题，且现有深度学习模型的性能受限于不准确的训练数据集。

Method: 通过关节角度建模和高阶傅里叶级数近似关节角度的时间变化，构建高质量数据集，并设计双向循环网络作为后处理模块。

Result: 实验表明，基于关节角度的改进方法（JAR）在花样滑冰和霹雳舞等挑战性案例中优于现有HPE改进网络。

Conclusion: 该方法显著提高了HPE的准确性和稳定性，尤其在复杂运动场景中表现优异。

Abstract: Marker-free human pose estimation (HPE) has found increasing applications in
various fields. Current HPE suffers from occasional errors in keypoint
recognition and random fluctuation in keypoint trajectories when analyzing
kinematic human poses. The performance of existing deep learning-based models
for HPE refinement is considerably limited by inaccurate training datasets in
which the keypoints are manually annotated. This paper proposed a novel method
to overcome the difficulty through joint angle-based modeling. The key
techniques include: (i) A joint angle-based model of human pose, which is
robust to describe kinematic human poses; (ii) Approximating temporal variation
of joint angles through high order Fourier series to get reliable "ground
truth"; (iii) A bidirectional recurrent network is designed as a
post-processing module to refine the estimation of well-established HRNet.
Trained with the high-quality dataset constructed using our method, the network
demonstrates outstanding performance to correct wrongly recognized joints and
smooth their spatiotemporal trajectories. Tests show that joint angle-based
refinement (JAR) outperforms the state-of-the-art HPE refinement network in
challenging cases like figure skating and breaking.

</details>


### [40] [GKNet: Graph-based Keypoints Network for Monocular Pose Estimation of Non-cooperative Spacecraft](https://arxiv.org/abs/2507.11077)
*Weizhao Ma,Dong Zhou,Yuhui Hu,Zipeng He*

Main category: cs.CV

TL;DR: 论文提出了一种基于图的关键点网络（GKNet），用于非合作航天器的单目姿态估计，解决了结构对称性和部分遮挡问题，并发布了SKD数据集。


<details>
  <summary>Details</summary>
Motivation: 非合作航天器的单目姿态估计对在轨服务任务（如卫星维护、空间碎片清除）至关重要，但现有关键点检测器对结构对称性和部分遮挡敏感。

Method: 提出GKNet，利用关键点图的几何约束；同时发布SKD数据集，包含3种航天器目标和9万张模拟图像。

Result: 实验表明GKNet在精度和有效性上优于现有方法。

Conclusion: GKNet在非合作航天器姿态估计中表现出色，SKD数据集为关键点检测提供了验证平台。

Abstract: Monocular pose estimation of non-cooperative spacecraft is significant for
on-orbit service (OOS) tasks, such as satellite maintenance, space debris
removal, and station assembly. Considering the high demands on pose estimation
accuracy, mainstream monocular pose estimation methods typically consist of
keypoint detectors and PnP solver. However, current keypoint detectors remain
vulnerable to structural symmetry and partial occlusion of non-cooperative
spacecraft. To this end, we propose a graph-based keypoints network for the
monocular pose estimation of non-cooperative spacecraft, GKNet, which leverages
the geometric constraint of keypoints graph. In order to better validate
keypoint detectors, we present a moderate-scale dataset for the spacecraft
keypoint detection, named SKD, which consists of 3 spacecraft targets, 90,000
simulated images, and corresponding high-precise keypoint annotations.
Extensive experiments and an ablation study have demonstrated the high accuracy
and effectiveness of our GKNet, compared to the state-of-the-art spacecraft
keypoint detectors. The code for GKNet and the SKD dataset is available at
https://github.com/Dongzhou-1996/GKNet.

</details>


### [41] [Automatic Road Subsurface Distress Recognition from Ground Penetrating Radar Images using Deep Learning-based Cross-verification](https://arxiv.org/abs/2507.11081)
*Chang Peng,Bao Yang,Meiqi Li,Ge Zhang,Hui Sun,Zhenyu Jiang*

Main category: cs.CV

TL;DR: 提出了一种基于交叉验证策略的深度学习模型，用于从GPR图像中自动识别道路地下病害（RSD），显著提高了识别准确率并减少了人工工作量。


<details>
  <summary>Details</summary>
Motivation: GPR图像中的RSD识别依赖人工且效率低，现有深度学习方法受限于数据集质量和网络能力。

Method: 构建了高质量的3D GPR数据集，并提出基于YOLO模型的交叉验证策略。

Result: 在实地测试中召回率超过98.6%，检测系统可减少约90%的人工工作量。

Conclusion: 该方法为RSD自动识别提供了高效解决方案，具有实际应用价值。

Abstract: Ground penetrating radar (GPR) has become a rapid and non-destructive
solution for road subsurface distress (RSD) detection. However, RSD recognition
from GPR images is labor-intensive and heavily relies on inspectors' expertise.
Deep learning offers the possibility for automatic RSD recognition, but its
current performance is limited by two factors: Scarcity of high-quality dataset
for network training and insufficient capability of network to distinguish RSD.
In this study, a rigorously validated 3D GPR dataset containing 2134 samples of
diverse types was constructed through field scanning. Based on the finding that
the YOLO model trained with one of the three scans of GPR images exhibits
varying sensitivity to specific type of RSD, we proposed a novel
cross-verification strategy with outstanding accuracy in RSD recognition,
achieving recall over 98.6% in field tests. The approach, integrated into an
online RSD detection system, can reduce the labor of inspection by around 90%.

</details>


### [42] [Atmos-Bench: 3D Atmospheric Structures for Climate Insight](https://arxiv.org/abs/2507.11085)
*Tianchi Xu*

Main category: cs.CV

TL;DR: 提出Atmos-Bench作为首个3D大气基准，并开发FourCastX网络，通过物理约束和高质量模拟数据改进大气结构恢复。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖辅助输入和简化物理模型，缺乏标准化3D基准，导致不确定性和对真实大气效应的捕捉不足。

Method: 结合WRF和增强的COSP模拟器生成高质量3D散射数据，设计FourCastX网络嵌入物理约束，提升恢复效果。

Result: 在Atmos-Bench数据集上，FourCastX在355 nm和532 nm波段均优于现有方法，无需辅助输入。

Conclusion: Atmos-Bench为卫星3D大气结构恢复设定了新标准，有助于更深入的气候研究。

Abstract: Atmospheric structure, represented by backscatter coefficients (BC) recovered
from satellite LiDAR attenuated backscatter (ATB), provides a volumetric view
of clouds, aerosols, and molecules, playing a critical role in human
activities, climate understanding, and extreme weather forecasting. Existing
methods often rely on auxiliary inputs and simplified physics-based
approximations, and lack a standardized 3D benchmark for fair evaluation.
However, such approaches may introduce additional uncertainties and
insufficiently capture realistic radiative transfer and atmospheric
scattering-absorption effects. To bridge these gaps, we present Atmos-Bench:
the first 3D atmospheric benchmark, along with a novel FourCastX:
Frequency-enhanced Spatio-Temporal Mixture-of-Experts Network that (a)
generates 921,600 image slices from 3D scattering volumes simulated at 532 nm
and 355 nm by coupling WRF with an enhanced COSP simulator over 384 land-ocean
time steps, yielding high-quality voxel-wise references; (b) embeds ATB-BC
physical constraints into the model architecture, promoting energy consistency
during restoration; (c) achieves consistent improvements on the Atmos-Bench
dataset across both 355 nm and 532 nm bands, outperforming state-of-the-art
baseline models without relying on auxiliary inputs. Atmos-Bench establishes a
new standard for satellite-based 3D atmospheric structure recovery and paves
the way for deeper climate insight.

</details>


### [43] [A Survey on Interpretability in Visual Recognition](https://arxiv.org/abs/2507.11099)
*Qiyang Wan,Chengzhi Gao,Ruiping Wang,Xilin Chen*

Main category: cs.CV

TL;DR: 本文系统回顾了视觉识别模型的可解释性研究，并提出了一种以人为中心的分类法，总结了评估指标需求，并探讨了新技术带来的机遇。


<details>
  <summary>Details</summary>
Motivation: 随着视觉识别模型在关键领域的应用增加，理解其机制和失败原因的需求推动了可解释性研究的发展。

Method: 提出了一种基于意图、对象、呈现和方法论的分类法，系统化现有XAI方法。

Result: 建立了视觉识别模型可解释性方法的系统分类标准，并总结了评估指标需求。

Conclusion: 本文旨在组织现有研究并启发未来对视觉识别模型可解释性的探索。

Abstract: In recent years, visual recognition methods have advanced significantly,
finding applications across diverse fields. While researchers seek to
understand the mechanisms behind the success of these models, there is also a
growing impetus to deploy them in critical areas like autonomous driving and
medical diagnostics to better diagnose failures, which promotes the development
of interpretability research. This paper systematically reviews existing
research on the interpretability of visual recognition models and proposes a
taxonomy of methods from a human-centered perspective. The proposed taxonomy
categorizes interpretable recognition methods based on Intent, Object,
Presentation, and Methodology, thereby establishing a systematic and coherent
set of grouping criteria for these XAI methods. Additionally, we summarize the
requirements for evaluation metrics and explore new opportunities enabled by
recent technologies, such as large multimodal models. We aim to organize
existing research in this domain and inspire future investigations into the
interpretability of visual recognition models.

</details>


### [44] [KptLLM++: Towards Generic Keypoint Comprehension with Large Language Model](https://arxiv.org/abs/2507.11102)
*Jie Yang,Wang Zeng,Sheng Jin,Lumin Xu,Wentao Liu,Chen Qian,Zhen Li,Ruimao Zhang*

Main category: cs.CV

TL;DR: KptLLM++ 是一种新型多模态大语言模型，专注于通用关键点理解，通过用户指令整合多种输入模态，实现高精度关键点检测。


<details>
  <summary>Details</summary>
Motivation: 现有 MLLMs 在捕捉细粒度语义信息（如对象关键点）方面表现不足，而关键点对细粒度图像分析、对象检索和行为识别等应用至关重要。

Method: 提出 identify-then-detect 范式，先解析关键点语义，再通过结构化思维链机制定位其精确位置，并扩展训练数据集至 50 万样本。

Result: 在多个关键点检测基准测试中表现优异，展示了卓越的准确性和泛化能力。

Conclusion: KptLLM++ 是细粒度图像理解的统一解决方案，对提升人机交互具有变革性意义。

Abstract: The emergence of Multimodal Large Language Models (MLLMs) has revolutionized
image understanding by bridging textual and visual modalities. However, these
models often struggle with capturing fine-grained semantic information, such as
the precise identification and analysis of object keypoints. Keypoints, as
structure-aware, pixel-level, and compact representations of objects,
particularly articulated ones, play a crucial role in applications such as
fine-grained image analysis, object retrieval, and behavior recognition. In
this paper, we propose KptLLM++, a novel multimodal large language model that
specifically designed for generic keypoint comprehension through the
integration of diverse input modalities guided by user-defined instructions. By
unifying keypoint detection across varied contexts, KptLLM++ establishes itself
as an advanced interface, fostering more effective human-AI collaboration. The
model is built upon a novel identify-then-detect paradigm, which first
interprets keypoint semantics and subsequently localizes their precise
positions through a structured chain-of-thought reasoning mechanism. To push
the boundaries of performance, we have scaled up the training dataset to over
500K samples, encompassing diverse objects, keypoint categories, image styles,
and scenarios with complex occlusions. This extensive scaling enables KptLLM++
to unlock its potential, achieving remarkable accuracy and generalization.
Comprehensive experiments on multiple keypoint detection benchmarks demonstrate
its state-of-the-art performance, underscoring its potential as a unified
solution for fine-grained image understanding and its transformative
implications for human-AI interaction.

</details>


### [45] [Jellyfish Species Identification: A CNN Based Artificial Neural Network Approach](https://arxiv.org/abs/2507.11116)
*Md. Sabbir Hossen,Md. Saiduzzaman,Pabon Shaha,Mostofa Kamal Nasir*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的框架，用于水母物种的检测和分类，结合多种特征提取技术和分类器，最高准确率达98%。


<details>
  <summary>Details</summary>
Motivation: 水母在海洋生态系统中扮演重要角色，但其快速繁殖和生态影响对生物多样性保护构成挑战，准确识别水母物种对生态监测和管理至关重要。

Method: 整合MobileNetV3、ResNet50、EfficientNetV2-B0和VGG16等特征提取技术，结合传统机器学习分类器和前馈神经网络分类器，并使用softmax函数直接分类。

Result: 结合MobileNetV3的人工神经网络模型表现最佳，准确率达98%，显著优于其他组合。

Conclusion: 深度学习与混合框架在解决生物多样性挑战和推进海洋物种检测方面具有高效性。

Abstract: Jellyfish, a diverse group of gelatinous marine organisms, play a crucial
role in maintaining marine ecosystems but pose significant challenges for
biodiversity and conservation due to their rapid proliferation and ecological
impact. Accurate identification of jellyfish species is essential for
ecological monitoring and management. In this study, we proposed a deep
learning framework for jellyfish species detection and classification using an
underwater image dataset. The framework integrates advanced feature extraction
techniques, including MobileNetV3, ResNet50, EfficientNetV2-B0, and VGG16,
combined with seven traditional machine learning classifiers and three
Feedforward Neural Network classifiers for precise species identification.
Additionally, we activated the softmax function to directly classify jellyfish
species using the convolutional neural network models. The combination of the
Artificial Neural Network with MobileNetV3 is our best-performing model,
achieving an exceptional accuracy of 98%, significantly outperforming other
feature extractor-classifier combinations. This study demonstrates the efficacy
of deep learning and hybrid frameworks in addressing biodiversity challenges
and advancing species detection in marine environments.

</details>


### [46] [Try Harder: Hard Sample Generation and Learning for Clothes-Changing Person Re-ID](https://arxiv.org/abs/2507.11119)
*Hankun Liu,Yujian Zhao,Guanglin Niu*

Main category: cs.CV

TL;DR: 提出了一种多模态引导的硬样本生成与学习框架（HSGL），通过结合文本和视觉模态来定义、生成和优化硬样本，提升了服装变化行人重识别（CC-ReID）的性能。


<details>
  <summary>Details</summary>
Motivation: 硬样本在行人重识别任务中具有挑战性，尤其是在服装变化场景下。其模糊性和相似性限制了学习策略的设计和模型的鲁棒性。

Method: HSGL框架包含两个核心组件：双粒度硬样本生成（DGHSG）和硬样本自适应学习（HSAL），分别用于生成多样化的硬样本和优化特征距离。

Result: 在多个CC-ReID基准测试中表现优异，显著加速了学习过程，并在PRCC和LTCC数据集上达到了最先进性能。

Conclusion: 多模态引导的硬样本生成与学习为CC-ReID任务提供了新的解决方案，显著提升了模型的判别能力和鲁棒性。

Abstract: Hard samples pose a significant challenge in person re-identification (ReID)
tasks, particularly in clothing-changing person Re-ID (CC-ReID). Their inherent
ambiguity or similarity, coupled with the lack of explicit definitions, makes
them a fundamental bottleneck. These issues not only limit the design of
targeted learning strategies but also diminish the model's robustness under
clothing or viewpoint changes. In this paper, we propose a novel
multimodal-guided Hard Sample Generation and Learning (HSGL) framework, which
is the first effort to unify textual and visual modalities to explicitly
define, generate, and optimize hard samples within a unified paradigm. HSGL
comprises two core components: (1) Dual-Granularity Hard Sample Generation
(DGHSG), which leverages multimodal cues to synthesize semantically consistent
samples, including both coarse- and fine-grained hard positives and negatives
for effectively increasing the hardness and diversity of the training data. (2)
Hard Sample Adaptive Learning (HSAL), which introduces a hardness-aware
optimization strategy that adjusts feature distances based on textual semantic
labels, encouraging the separation of hard positives and drawing hard negatives
closer in the embedding space to enhance the model's discriminative capability
and robustness to hard samples. Extensive experiments on multiple CC-ReID
benchmarks demonstrate the effectiveness of our approach and highlight the
potential of multimodal-guided hard sample generation and learning for robust
CC-ReID. Notably, HSAL significantly accelerates the convergence of the
targeted learning procedure and achieves state-of-the-art performance on both
PRCC and LTCC datasets. The code is available at
https://github.com/undooo/TryHarder-ACMMM25.

</details>


### [47] [MMOne: Representing Multiple Modalities in One Scene](https://arxiv.org/abs/2507.11129)
*Zhifeng Gu,Bing Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为MMOne的通用框架，用于解决多模态场景表示中的模态冲突问题，通过模态建模模块和多模态分解机制实现高效表示。


<details>
  <summary>Details</summary>
Motivation: 人类通过多模态感知世界，但不同模态间的差异（如属性差异和粒度差异）带来了挑战。

Method: 提出MMOne框架，包括模态建模模块（含模态指示器）和多模态分解机制，将多模态信息解耦为共享和模态特定部分。

Result: 实验表明，该方法能有效提升各模态的表示能力，并支持扩展到更多模态。

Conclusion: MMOne框架能高效解决多模态场景表示中的模态冲突问题，具有扩展性和实用性。

Abstract: Humans perceive the world through multimodal cues to understand and interact
with the environment. Learning a scene representation for multiple modalities
enhances comprehension of the physical world. However, modality conflicts,
arising from inherent distinctions among different modalities, present two
critical challenges: property disparity and granularity disparity. To address
these challenges, we propose a general framework, MMOne, to represent multiple
modalities in one scene, which can be readily extended to additional
modalities. Specifically, a modality modeling module with a novel modality
indicator is proposed to capture the unique properties of each modality.
Additionally, we design a multimodal decomposition mechanism to separate
multi-modal Gaussians into single-modal Gaussians based on modality
differences. We address the essential distinctions among modalities by
disentangling multimodal information into shared and modality-specific
components, resulting in a more compact and efficient multimodal scene
representation. Extensive experiments demonstrate that our method consistently
enhances the representation capability for each modality and is scalable to
additional modalities. The code is available at
https://github.com/Neal2020GitHub/MMOne.

</details>


### [48] [RMAU-NET: A Residual-Multihead-Attention U-Net Architecture for Landslide Segmentation and Detection from Remote Sensing Images](https://arxiv.org/abs/2507.11143)
*Lam Pham,Cam Le,Hieu Tang,Khang Truong,Truong Nguyen,Jasmin Lampert,Alexander Schindler,Martin Boyer,Son Phan*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的端到端模型，利用遥感图像自动观测滑坡事件，并在多个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于极端天气和人类活动导致滑坡灾害频发，但传统观测方法在大范围和复杂地形中难以实现自动化。

Method: 设计了一种新型神经网络架构，用于滑坡检测和分割任务，输入为遥感图像。

Result: 在LandSlide4Sense、Bijie和Nepal数据集上，检测任务的F1分数分别为98.23和93.83，分割任务的mIoU分数为63.74和76.88。

Conclusion: 实验结果证明了该模型在实际滑坡观测系统中的潜在应用价值。

Abstract: In recent years, landslide disasters have reported frequently due to the
extreme weather events of droughts, floods , storms, or the consequence of
human activities such as deforestation, excessive exploitation of natural
resources. However, automatically observing landslide is challenging due to the
extremely large observing area and the rugged topography such as mountain or
highland. This motivates us to propose an end-to-end deep-learning-based model
which explores the remote sensing images for automatically observing landslide
events. By considering remote sensing images as the input data, we can obtain
free resource, observe large and rough terrains by time. To explore the remote
sensing images, we proposed a novel neural network architecture which is for
two tasks of landslide detection and landslide segmentation. We evaluated our
proposed model on three different benchmark datasets of LandSlide4Sense, Bijie,
and Nepal. By conducting extensive experiments, we achieve F1 scores of 98.23,
93.83 for the landslide detection task on LandSlide4Sense, Bijie datasets; mIoU
scores of 63.74, 76.88 on the segmentation tasks regarding LandSlide4Sense,
Nepal datasets. These experimental results prove potential to integrate our
proposed model into real-life landslide observation systems.

</details>


### [49] [Assessing Color Vision Test in Large Vision-language Models](https://arxiv.org/abs/2507.11153)
*Hongfei Ye,Bin Chen,Wenxi Liu,Yu Zhang,Zhao Li,Dandan Ni,Hongyang Chen*

Main category: cs.CV

TL;DR: 本文研究了大型视觉语言模型的色彩视觉能力，提出了一个测试任务并构建了数据集，分析了错误类型并提出了优化策略。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型的色彩视觉能力尚未被充分研究，填补这一空白是本文的动机。

Method: 定义了色彩视觉测试任务，构建了多类别、多难度级别的数据集，并分析了模型的错误类型。

Result: 提出了针对色彩视觉测试的微调策略，以提升模型性能。

Conclusion: 通过测试和优化策略，本文为大型视觉语言模型的色彩视觉能力研究提供了基础。

Abstract: With the widespread adoption of large vision-language models, the capacity
for color vision in these models is crucial. However, the color vision
abilities of large visual-language models have not yet been thoroughly
explored. To address this gap, we define a color vision testing task for large
vision-language models and construct a dataset \footnote{Anonymous Github
Showing some of the data
https://anonymous.4open.science/r/color-vision-test-dataset-3BCD} that covers
multiple categories of test questions and tasks of varying difficulty levels.
Furthermore, we analyze the types of errors made by large vision-language
models and propose fine-tuning strategies to enhance their performance in color
vision tests.

</details>


### [50] [Clustering-Guided Multi-Layer Contrastive Representation Learning for Citrus Disease Classification](https://arxiv.org/abs/2507.11171)
*Jun Chen,Yonghua Yu,Weifu Li,Yaohui Chen,Hong Chen*

Main category: cs.CV

TL;DR: 提出了一种基于聚类引导的自监督多层对比表示学习算法（CMCRL），用于柑橘病害检测与分类，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 柑橘病害严重影响产量，传统深度学习方法依赖大量标注数据，而CMCRL通过自监督学习减少标注需求。

Method: 引入聚类中心对比和多层对比训练（MCT），利用无标注样本优化模型，适应症状相似性并学习分层特征表示。

Result: 在公开数据集CDD上，CMCRL比现有方法准确率提升4.5%-30.1%，且在其他评估指标（F1、精确率、召回率）上表现优异。

Conclusion: CMCRL在减少标注需求的同时，实现了接近全监督方法的性能，为柑橘病害检测提供了高效解决方案。

Abstract: Citrus, as one of the most economically important fruit crops globally,
suffers severe yield depressions due to various diseases. Accurate disease
detection and classification serve as critical prerequisites for implementing
targeted control measures. Recent advancements in artificial intelligence,
particularly deep learning-based computer vision algorithms, have substantially
decreased time and labor requirements while maintaining the accuracy of
detection and classification. Nevertheless, these methods predominantly rely on
massive, high-quality annotated training examples to attain promising
performance. By introducing two key designs: contrasting with cluster centroids
and a multi-layer contrastive training (MCT) paradigm, this paper proposes a
novel clustering-guided self-supervised multi-layer contrastive representation
learning (CMCRL) algorithm. The proposed method demonstrates several advantages
over existing counterparts: (1) optimizing with massive unannotated samples;
(2) effective adaptation to the symptom similarity across distinct citrus
diseases; (3) hierarchical feature representation learning. The proposed method
achieves state-of-the-art performance on the public citrus image set CDD,
outperforming existing methods by 4.5\%-30.1\% accuracy. Remarkably, our method
narrows the performance gap with fully supervised counterparts (all samples are
labeled). Beyond classification accuracy, our method shows great performance on
other evaluation metrics (F1 score, precision, and recall), highlighting the
robustness against the class imbalance challenge.

</details>


### [51] [How Far Have Medical Vision-Language Models Come? A Comprehensive Benchmarking Study](https://arxiv.org/abs/2507.11200)
*Che Liu,Jiazhen Pan,Weixiang Shen,Wenjia Bai,Daniel Rueckert,Rossella Arcucci*

Main category: cs.CV

TL;DR: 本文评估了开源通用和医学专用视觉语言模型（VLMs）在医疗任务中的表现，发现通用模型在某些任务上已优于医学专用模型，但推理能力仍是瓶颈，且临床可靠性尚未达标。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型在医疗任务中的能力，填补现有研究的空白。

Method: 对3B至72B参数的VLMs在八个医疗基准测试（如MedXpert、OmniMedVQA等）上进行综合评估，分为理解和推理两部分。

Result: 1. 通用模型在某些任务上优于医学专用模型；2. 推理能力普遍较弱；3. 任务表现差异大，临床可靠性不足。

Conclusion: 需加强多模态对齐和更严格的评估协议，以提升模型在医疗领域的可靠性。

Abstract: Vision-Language Models (VLMs) trained on web-scale corpora excel at natural
image tasks and are increasingly repurposed for healthcare; however, their
competence in medical tasks remains underexplored. We present a comprehensive
evaluation of open-source general-purpose and medically specialised VLMs,
ranging from 3B to 72B parameters, across eight benchmarks: MedXpert,
OmniMedVQA, PMC-VQA, PathVQA, MMMU, SLAKE, and VQA-RAD. To observe model
performance across different aspects, we first separate it into understanding
and reasoning components. Three salient findings emerge. First, large
general-purpose models already match or surpass medical-specific counterparts
on several benchmarks, demonstrating strong zero-shot transfer from natural to
medical images. Second, reasoning performance is consistently lower than
understanding, highlighting a critical barrier to safe decision support. Third,
performance varies widely across benchmarks, reflecting differences in task
design, annotation quality, and knowledge demands. No model yet reaches the
reliability threshold for clinical deployment, underscoring the need for
stronger multimodal alignment and more rigorous, fine-grained evaluation
protocols.

</details>


### [52] [A Robust Incomplete Multimodal Low-Rank Adaptation Approach for Emotion Recognition](https://arxiv.org/abs/2507.11202)
*Xinkui Zhao,Jinsong Shu,Yangyang Wu,Guanjie Cheng,Zihe Liu,Naibo Wang,Shuiguang Deng,Zhongle Xie,Jianwei Yin*

Main category: cs.CV

TL;DR: 提出了一种名为MCULoRA的新方法，通过解耦模态组合的共享信息和动态调整训练比例，解决了多模态情感识别中模态不完整的问题。


<details>
  <summary>Details</summary>
Motivation: 实际应用中多模态数据常因传感器故障或隐私保护而不完整，现有方法因模态组合训练梯度冲突而性能受限。

Method: MCULoRA包含两个模块：MCLA（解耦模态组合的共享信息）和DPFT（动态调整训练比例）。

Result: 在多个基准数据集上，MCULoRA显著优于现有方法。

Conclusion: MCULoRA为不完整多模态学习提供了一种高效参数训练框架。

Abstract: Multimodal Emotion Recognition (MER) often encounters incomplete
multimodality in practical applications due to sensor failures or privacy
protection requirements. While existing methods attempt to address various
incomplete multimodal scenarios by balancing the training of each modality
combination through additional gradients, these approaches face a critical
limitation: training gradients from different modality combinations conflict
with each other, ultimately degrading the performance of the final prediction
model. In this paper, we propose a unimodal decoupled dynamic low-rank
adaptation method based on modality combinations, named MCULoRA, which is a
novel framework for the parameter-efficient training of incomplete multimodal
learning models. MCULoRA consists of two key modules, modality combination
aware low-rank adaptation (MCLA) and dynamic parameter fine-tuning (DPFT). The
MCLA module effectively decouples the shared information from the distinct
characteristics of individual modality combinations. The DPFT module adjusts
the training ratio of modality combinations based on the separability of each
modality's representation space, optimizing the learning efficiency across
different modality combinations. Our extensive experimental evaluation in
multiple benchmark datasets demonstrates that MCULoRA substantially outperforms
previous incomplete multimodal learning approaches in downstream task accuracy.

</details>


### [53] [NarrLV: Towards a Comprehensive Narrative-Centric Evaluation for Long Video Generation Models](https://arxiv.org/abs/2507.11245)
*X. Feng,H. Yu,M. Wu,S. Hu,J. Chen,C. Zhu,J. Wu,X. Chu,K. Huang*

Main category: cs.CV

TL;DR: 提出了首个用于评估长视频生成模型叙事表达能力的基准NarrLV，通过引入时间叙事原子（TNA）和自动提示生成管道，结合MLLM框架设计评估指标，实验表明其与人类判断一致。


<details>
  <summary>Details</summary>
Motivation: 当前长视频生成模型的评估缺乏专门针对叙事表达能力的基准，现有基准如VBench仅支持简单叙事提示。

Method: 1. 引入TNA作为基本叙事单元；2. 构建自动提示生成管道；3. 基于MLLM框架设计评估指标。

Result: 实验结果显示，NarrLV的评估指标与人类判断高度一致，揭示了当前视频生成模型在叙事表达上的能力边界。

Conclusion: NarrLV为长视频生成模型的叙事表达能力提供了首个全面评估基准，填补了研究空白。

Abstract: With the rapid development of foundation video generation technologies, long
video generation models have exhibited promising research potential thanks to
expanded content creation space. Recent studies reveal that the goal of long
video generation tasks is not only to extend video duration but also to
accurately express richer narrative content within longer videos. However, due
to the lack of evaluation benchmarks specifically designed for long video
generation models, the current assessment of these models primarily relies on
benchmarks with simple narrative prompts (e.g., VBench). To the best of our
knowledge, our proposed NarrLV is the first benchmark to comprehensively
evaluate the Narrative expression capabilities of Long Video generation models.
Inspired by film narrative theory, (i) we first introduce the basic narrative
unit maintaining continuous visual presentation in videos as Temporal Narrative
Atom (TNA), and use its count to quantitatively measure narrative richness.
Guided by three key film narrative elements influencing TNA changes, we
construct an automatic prompt generation pipeline capable of producing
evaluation prompts with a flexibly expandable number of TNAs. (ii) Then, based
on the three progressive levels of narrative content expression, we design an
effective evaluation metric using the MLLM-based question generation and
answering framework. (iii) Finally, we conduct extensive evaluations on
existing long video generation models and the foundation generation models.
Experimental results demonstrate that our metric aligns closely with human
judgments. The derived evaluation outcomes reveal the detailed capability
boundaries of current video generation models in narrative content expression.

</details>


### [54] [Fairness-Aware Grouping for Continuous Sensitive Variables: Application for Debiasing Face Analysis with respect to Skin Tone](https://arxiv.org/abs/2507.11247)
*Veronika Shilova,Emmanuel Malherbe,Giovanni Palma,Laurent Risser,Jean-Michel Loubes*

Main category: cs.CV

TL;DR: 提出了一种基于公平性的分组方法，用于处理连续敏感属性，通过最大化组间歧视方差来识别关键子群，并在实验中验证了其有效性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理连续敏感属性（如肤色）时，通过预设分组可能忽略少数群体的歧视问题，因此需要一种更精细的分组方法。

Method: 提出了一种基于观察到的歧视水平的分组方法，通过最大化组间歧视方差的新标准来识别关键子群，并应用于去偏目的。

Result: 在合成数据集和真实数据集（CelebA和FFHQ）上验证了方法的有效性，揭示了更细微的歧视模式，并在去偏后保持了准确性。

Conclusion: 该方法不仅提高了公平性，且对准确性影响最小，适用于工业部署。

Abstract: Within a legal framework, fairness in datasets and models is typically
assessed by dividing observations into predefined groups and then computing
fairness measures (e.g., Disparate Impact or Equality of Odds with respect to
gender). However, when sensitive attributes such as skin color are continuous,
dividing into default groups may overlook or obscure the discrimination
experienced by certain minority subpopulations. To address this limitation, we
propose a fairness-based grouping approach for continuous (possibly
multidimensional) sensitive attributes. By grouping data according to observed
levels of discrimination, our method identifies the partition that maximizes a
novel criterion based on inter-group variance in discrimination, thereby
isolating the most critical subgroups.
  We validate the proposed approach using multiple synthetic datasets and
demonstrate its robustness under changing population distributions - revealing
how discrimination is manifested within the space of sensitive attributes.
Furthermore, we examine a specialized setting of monotonic fairness for the
case of skin color. Our empirical results on both CelebA and FFHQ, leveraging
the skin tone as predicted by an industrial proprietary algorithm, show that
the proposed segmentation uncovers more nuanced patterns of discrimination than
previously reported, and that these findings remain stable across datasets for
a given model. Finally, we leverage our grouping model for debiasing purpose,
aiming at predicting fair scores with group-by-group post-processing. The
results demonstrate that our approach improves fairness while having minimal
impact on accuracy, thus confirming our partition method and opening the door
for industrial deployment.

</details>


### [55] [MFGDiffusion: Mask-Guided Smoke Synthesis for Enhanced Forest Fire Detection](https://arxiv.org/abs/2507.11252)
*Guanghao Wu,Chen Xu,Hai Song,Chong Wang,Qixing Zhang*

Main category: cs.CV

TL;DR: 提出了一种生成森林火灾烟雾图像的框架，通过改进掩码和图像特征利用，以及引入新的损失函数，提升了烟雾图像的质量和多样性，从而增强了烟雾检测模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决森林火灾烟雾图像数据稀缺问题，并改进现有修复模型在烟雾生成中的不一致性问题。

Method: 使用预训练分割模型和多模态模型获取烟雾掩码和图像描述；提出掩码和掩码图像特征引导的网络架构；引入掩码随机差异损失函数；利用多模态大语言模型筛选合成图像。

Result: 生成的烟雾图像真实且多样，有效提升了烟雾检测模型的性能。

Conclusion: 提出的框架能够生成高质量的烟雾图像，为森林火灾烟雾检测任务提供了有效的数据支持。

Abstract: Smoke is the first visible indicator of a wildfire.With the advancement of
deep learning, image-based smoke detection has become a crucial method for
detecting and preventing forest fires. However, the scarcity of smoke image
data from forest fires is one of the significant factors hindering the
detection of forest fire smoke. Image generation models offer a promising
solution for synthesizing realistic smoke images. However, current inpainting
models exhibit limitations in generating high-quality smoke representations,
particularly manifesting as inconsistencies between synthesized smoke and
background contexts. To solve these problems, we proposed a comprehensive
framework for generating forest fire smoke images. Firstly, we employed the
pre-trained segmentation model and the multimodal model to obtain smoke masks
and image captions.Then, to address the insufficient utilization of masks and
masked images by inpainting models, we introduced a network architecture guided
by mask and masked image features. We also proposed a new loss function, the
mask random difference loss, which enhances the consistency of the generated
effects around the mask by randomly expanding and eroding the mask
edges.Finally, to generate a smoke image dataset using random masks for
subsequent detection tasks, we incorporated smoke characteristics and use a
multimodal large language model as a filtering tool to select diverse and
reasonable smoke images, thereby improving the quality of the synthetic
dataset. Experiments showed that our generated smoke images are realistic and
diverse, and effectively enhance the performance of forest fire smoke detection
models. Code is available at https://github.com/wghr123/MFGDiffusion.

</details>


### [56] [ViewSRD: 3D Visual Grounding via Structured Multi-View Decomposition](https://arxiv.org/abs/2507.11261)
*Ronggang Huang,Haoxin Yang,Yan Cai,Xuemiao Xu,Huaidong Zhang,Shengfeng He*

Main category: cs.CV

TL;DR: ViewSRD框架通过结构化多视角分解解决3D视觉定位中的复杂查询和视角不一致问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理复杂多锚点查询和视角变化导致的空间描述不一致问题。

Method: 提出ViewSRD框架，包含Simple Relation Decoupling模块分解查询，Multi-view Textual-Scene Interaction模块整合多视角特征，以及Textual-Scene Reasoning模块综合预测。

Result: 在3D视觉定位数据集上表现显著优于现有方法，尤其在复杂查询中。

Conclusion: ViewSRD通过结构化多视角分解有效提升了3D视觉定位的准确性和鲁棒性。

Abstract: 3D visual grounding aims to identify and localize objects in a 3D space based
on textual descriptions. However, existing methods struggle with disentangling
targets from anchors in complex multi-anchor queries and resolving
inconsistencies in spatial descriptions caused by perspective variations. To
tackle these challenges, we propose ViewSRD, a framework that formulates 3D
visual grounding as a structured multi-view decomposition process. First, the
Simple Relation Decoupling (SRD) module restructures complex multi-anchor
queries into a set of targeted single-anchor statements, generating a
structured set of perspective-aware descriptions that clarify positional
relationships. These decomposed representations serve as the foundation for the
Multi-view Textual-Scene Interaction (Multi-TSI) module, which integrates
textual and scene features across multiple viewpoints using shared, Cross-modal
Consistent View Tokens (CCVTs) to preserve spatial correlations. Finally, a
Textual-Scene Reasoning module synthesizes multi-view predictions into a
unified and robust 3D visual grounding. Experiments on 3D visual grounding
datasets show that ViewSRD significantly outperforms state-of-the-art methods,
particularly in complex queries requiring precise spatial differentiation.

</details>


### [57] [YOLOatr : Deep Learning Based Automatic Target Detection and Localization in Thermal Infrared Imagery](https://arxiv.org/abs/2507.11267)
*Aon Safdar,Usman Akram,Waseem Anwar,Basit Malik,Mian Ibad Ali*

Main category: cs.CV

TL;DR: 论文提出了一种改进的YOLOv5s模型YOLOatr，用于热红外图像中的目标检测与识别，解决了该领域特有的挑战，并在测试中达到了99.6%的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 热红外图像在国防和监控领域的自动目标检测与识别（ATR）面临诸多挑战，如数据集有限、硬件限制、尺度变化、遮挡、低分辨率等，导致现有深度学习模型性能不佳。

Method: 提出YOLOatr，基于改进的YOLOv5s，优化了检测头、特征融合和自定义数据增强策略。

Result: 在DSIAC MWIR数据集上测试，YOLOatr在相关和非相关测试协议下均达到99.6%的SOTA性能。

Conclusion: YOLOatr显著提升了热红外图像中的ATR性能，适用于实时应用。

Abstract: Automatic Target Detection (ATD) and Recognition (ATR) from Thermal Infrared
(TI) imagery in the defense and surveillance domain is a challenging computer
vision (CV) task in comparison to the commercial autonomous vehicle perception
domain. Limited datasets, peculiar domain-specific and TI modality-specific
challenges, i.e., limited hardware, scale invariance issues due to greater
distances, deliberate occlusion by tactical vehicles, lower sensor resolution
and resultant lack of structural information in targets, effects of weather,
temperature, and time of day variations, and varying target to clutter ratios
all result in increased intra-class variability and higher inter-class
similarity, making accurate real-time ATR a challenging CV task. Resultantly,
contemporary state-of-the-art (SOTA) deep learning architectures underperform
in the ATR domain. We propose a modified anchor-based single-stage detector,
called YOLOatr, based on a modified YOLOv5s, with optimal modifications to the
detection heads, feature fusion in the neck, and a custom augmentation profile.
We evaluate the performance of our proposed model on a comprehensive DSIAC MWIR
dataset for real-time ATR over both correlated and decorrelated testing
protocols. The results demonstrate that our proposed model achieves
state-of-the-art ATR performance of up to 99.6%.

</details>


### [58] [Tomato Multi-Angle Multi-Pose Dataset for Fine-Grained Phenotyping](https://arxiv.org/abs/2507.11279)
*Yujie Zhang,Sabine Struckmeyer,Andreas Kolb,Sven Reichardt*

Main category: cs.CV

TL;DR: TomatoMAP是一个基于物联网的番茄植物表型数据集，包含64,464张RGB图像和3,616张高分辨率图像，用于精细表型分析。通过深度学习框架验证，其准确性和速度与专家相当。


<details>
  <summary>Details</summary>
Motivation: 传统植物表型分析方法存在观察者偏差和不一致性，影响准确性和可重复性。

Method: 开发了TomatoMAP数据集，使用物联网成像系统和标准化数据采集协议，结合深度学习框架（MobileNetv3、YOLOv11、MaskRCNN）进行验证。

Result: 模型在精细表型分析中的准确性和速度与专家相当，Cohen's Kappa和热图验证了方法的可靠性。

Conclusion: TomatoMAP为植物表型分析提供了可靠且高效的自动化解决方案。

Abstract: Observer bias and inconsistencies in traditional plant phenotyping methods
limit the accuracy and reproducibility of fine-grained plant analysis. To
overcome these challenges, we developed TomatoMAP, a comprehensive dataset for
Solanum lycopersicum using an Internet of Things (IoT) based imaging system
with standardized data acquisition protocols. Our dataset contains 64,464 RGB
images that capture 12 different plant poses from four camera elevation angles.
Each image includes manually annotated bounding boxes for seven regions of
interest (ROIs), including leaves, panicle, batch of flowers, batch of fruits,
axillary shoot, shoot and whole plant area, along with 50 fine-grained growth
stage classifications based on the BBCH scale. Additionally, we provide 3,616
high-resolution image subset with pixel-wise semantic and instance segmentation
annotations for fine-grained phenotyping. We validated our dataset using a
cascading model deep learning framework combining MobileNetv3 for
classification, YOLOv11 for object detection, and MaskRCNN for segmentation.
Through AI vs. Human analysis involving five domain experts, we demonstrate
that the models trained on our dataset achieve accuracy and speed comparable to
the experts. Cohen's Kappa and inter-rater agreement heatmap confirm the
reliability of automated fine-grained phenotyping using our approach.

</details>


### [59] [Task-Oriented Human Grasp Synthesis via Context- and Task-Aware Diffusers](https://arxiv.org/abs/2507.11287)
*An-Lun Liu,Yu-Wei Chao,Yi-Ting Chen*

Main category: cs.CV

TL;DR: 本文提出了一种任务导向的人体抓取合成方法，通过任务感知接触图结合场景和任务信息，显著提升了抓取质量和任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统抓取合成方法仅考虑物体与手的关系，缺乏对场景和任务的综合考量，导致抓取效果不佳。本文旨在解决这一问题。

Method: 采用两阶段流程：首先生成任务感知接触图，随后利用该图合成任务导向的人体抓取姿势。

Result: 实验表明，该方法在抓取质量和任务性能上均优于现有方法。

Conclusion: 任务和场景信息的综合建模对提升抓取合成效果至关重要。

Abstract: In this paper, we study task-oriented human grasp synthesis, a new grasp
synthesis task that demands both task and context awareness. At the core of our
method is the task-aware contact maps. Unlike traditional contact maps that
only reason about the manipulated object and its relation with the hand, our
enhanced maps take into account scene and task information. This comprehensive
map is critical for hand-object interaction, enabling accurate grasping poses
that align with the task. We propose a two-stage pipeline that first constructs
a task-aware contact map informed by the scene and task. In the subsequent
stage, we use this contact map to synthesize task-oriented human grasps. We
introduce a new dataset and a metric for the proposed task to evaluate our
approach. Our experiments validate the importance of modeling both scene and
task, demonstrating significant improvements over existing methods in both
grasp quality and task performance. See our project page for more details:
https://hcis-lab.github.io/TOHGS/

</details>


### [60] [Detección y Cuantificación de Erosión Fluvial con Visión Artificial](https://arxiv.org/abs/2507.11301)
*Paúl Maji,Marlon Túquerres,Stalin Valencia,Marcela Valenzuela,Christian Mejia-Escobar*

Main category: cs.CV

TL;DR: 论文提出了一种基于人工智能的方法，利用YOLOv11模型自动识别侵蚀区域并估算面积，开发了交互式网页应用EROSCAN。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖专业知识和手动处理，效率低，需自动化解决方案。

Method: 使用YOLOv11模型，结合照片和LiDAR图像训练，通过Roboflow平台标注数据。

Result: 模型准确率70%，能精确识别侵蚀区域并计算面积，开发了EROSCAN系统。

Conclusion: 该方法优化了侵蚀检测和量化，支持风险管理和土地规划决策。

Abstract: Fluvial erosion is a natural process that can generate significant impacts on
soil stability and strategic infrastructures. The detection and monitoring of
this phenomenon is traditionally addressed by photogrammetric methods and
analysis in geographic information systems. These tasks require specific
knowledge and intensive manual processing. This study proposes an artificial
intelligence-based approach for automatic identification of eroded zones and
estimation of their area. The state-of-the-art computer vision model YOLOv11,
adjusted by fine-tuning and trained with photographs and LiDAR images, is used.
This combined dataset was segmented and labeled using the Roboflow platform.
Experimental results indicate efficient detection of erosion patterns with an
accuracy of 70%, precise identification of eroded areas and reliable
calculation of their extent in pixels and square meters. As a final product,
the EROSCAN system has been developed, an interactive web application that
allows users to upload images and obtain automatic segmentations of fluvial
erosion, together with the estimated area. This tool optimizes the detection
and quantification of the phenomenon, facilitating decision making in risk
management and territorial planning.

</details>


### [61] [A Mixed-Primitive-based Gaussian Splatting Method for Surface Reconstruction](https://arxiv.org/abs/2507.11321)
*Haoxuan Qu,Yujun Cai,Hossein Rahmani,Ajay Kumar,Junsong Yuan,Jun Liu*

Main category: cs.CV

TL;DR: 提出了一种新型框架，首次在Gaussian Splatting中引入多种几何基元，提升表面重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有GS方法仅使用单一基元（椭圆或椭球）表示复杂物体表面，不足以实现高质量重建。

Method: 提出组合式splatting策略、混合基元初始化策略和顶点修剪机制，支持多种基元的渲染与学习。

Result: 实验证明框架有效，实现了精确的表面重建。

Conclusion: 多基元策略显著提升了Gaussian Splatting的表面重建能力。

Abstract: Recently, Gaussian Splatting (GS) has received a lot of attention in surface
reconstruction. However, while 3D objects can be of complex and diverse shapes
in the real world, existing GS-based methods only limitedly use a single type
of splatting primitive (Gaussian ellipse or Gaussian ellipsoid) to represent
object surfaces during their reconstruction. In this paper, we highlight that
this can be insufficient for object surfaces to be represented in high quality.
Thus, we propose a novel framework that, for the first time, enables Gaussian
Splatting to incorporate multiple types of (geometrical) primitives during its
surface reconstruction process. Specifically, in our framework, we first
propose a compositional splatting strategy, enabling the splatting and
rendering of different types of primitives in the Gaussian Splatting pipeline.
In addition, we also design our framework with a mixed-primitive-based
initialization strategy and a vertex pruning mechanism to further promote its
surface representation learning process to be well executed leveraging
different types of primitives. Extensive experiments show the efficacy of our
framework and its accurate surface reconstruction performance.

</details>


### [62] [Attributes Shape the Embedding Space of Face Recognition Models](https://arxiv.org/abs/2507.11372)
*Pierrick Leroy,Antonio Mastropietro,Marco Nurisso,Francesco Vaccarino*

Main category: cs.CV

TL;DR: 论文提出了一种几何方法分析人脸识别模型中嵌入空间的属性依赖性，并引入了一种物理启发的对齐度量。


<details>
  <summary>Details</summary>
Motivation: 研究人脸识别模型在嵌入空间中表现出的多尺度几何结构，以及这些结构如何受可解释的面部和图像属性影响。

Method: 提出几何方法描述模型对属性的依赖性或不变性，并引入物理启发的对齐度量进行评估。

Result: 模型在不同属性上表现出不同程度的不变性，揭示了其优缺点并增强了可解释性。

Conclusion: 该方法为理解人脸识别模型的属性依赖性提供了新视角，并有助于提升模型的可解释性。

Abstract: Face Recognition (FR) tasks have made significant progress with the advent of
Deep Neural Networks, particularly through margin-based triplet losses that
embed facial images into high-dimensional feature spaces. During training,
these contrastive losses focus exclusively on identity information as labels.
However, we observe a multiscale geometric structure emerging in the embedding
space, influenced by interpretable facial (e.g., hair color) and image
attributes (e.g., contrast). We propose a geometric approach to describe the
dependence or invariance of FR models to these attributes and introduce a
physics-inspired alignment metric. We evaluate the proposed metric on
controlled, simplified models and widely used FR models fine-tuned with
synthetic data for targeted attribute augmentation. Our findings reveal that
the models exhibit varying degrees of invariance across different attributes,
providing insight into their strengths and weaknesses and enabling deeper
interpretability. Code available here:
https://github.com/mantonios107/attrs-fr-embs}{https://github.com/mantonios107/attrs-fr-embs

</details>


### [63] [COLI: A Hierarchical Efficient Compressor for Large Images](https://arxiv.org/abs/2507.11443)
*Haoran Wang,Hanyu Pei,Yang Lyu,Kai Zhang,Li Li,Feng-Lei Fan*

Main category: cs.CV

TL;DR: 论文提出COLI框架，利用NeRV技术改进INR压缩方法，解决大图像压缩的速度和压缩比问题。


<details>
  <summary>Details</summary>
Motivation: 高分辨率大视场图像的普及需要高效压缩方法，传统方法难以保留细节，数据驱动方法泛化性差。

Method: 采用NeRV技术，通过预训练-微调、混合精度训练和并行化目标加速INR压缩；提出Hyper-Compression技术提升压缩比。

Result: 在医学影像数据集上，COLI在PSNR和SSIM指标上表现优异，压缩速度提升4倍。

Conclusion: COLI框架显著提升大图像压缩的效率和性能，具有实际应用潜力。

Abstract: The escalating adoption of high-resolution, large-field-of-view imagery
amplifies the need for efficient compression methodologies. Conventional
techniques frequently fail to preserve critical image details, while
data-driven approaches exhibit limited generalizability. Implicit Neural
Representations (INRs) present a promising alternative by learning continuous
mappings from spatial coordinates to pixel intensities for individual images,
thereby storing network weights rather than raw pixels and avoiding the
generalization problem. However, INR-based compression of large images faces
challenges including slow compression speed and suboptimal compression ratios.
To address these limitations, we introduce COLI (Compressor for Large Images),
a novel framework leveraging Neural Representations for Videos (NeRV). First,
recognizing that INR-based compression constitutes a training process, we
accelerate its convergence through a pretraining-finetuning paradigm,
mixed-precision training, and reformulation of the sequential loss into a
parallelizable objective. Second, capitalizing on INRs' transformation of image
storage constraints into weight storage, we implement Hyper-Compression, a
novel post-training technique to substantially enhance compression ratios while
maintaining minimal output distortion. Evaluations across two medical imaging
datasets demonstrate that COLI consistently achieves competitive or superior
PSNR and SSIM metrics at significantly reduced bits per pixel (bpp), while
accelerating NeRV training by up to 4 times.

</details>


### [64] [MonoMVSNet: Monocular Priors Guided Multi-View Stereo Network](https://arxiv.org/abs/2507.11333)
*Jianfei Jiang,Qiankun Liu,Haochen Yu,Hongyuan Liu,Liyong Wang,Jiansheng Chen,Huimin Ma*

Main category: cs.CV

TL;DR: MonoMVSNet结合单目深度估计与多视角立体视觉，通过注意力机制和动态深度候选更新，解决了纹理缺失和反射表面的挑战，在DTU和Tanks-and-Temples数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有MVS方法在纹理缺失和反射表面等挑战区域表现不佳，而单目深度估计无需特征匹配，具有鲁棒性。

Method: 提出MonoMVSNet，通过注意力机制整合单目特征，动态更新深度候选，并设计相对一致性损失监督深度预测。

Result: 在DTU和Tanks-and-Temples数据集上达到最优性能，Tanks-and-Temples Intermediate和Advanced基准排名第一。

Conclusion: MonoMVSNet通过结合单目深度估计与多视角几何，显著提升了MVS在挑战区域的性能。

Abstract: Learning-based Multi-View Stereo (MVS) methods aim to predict depth maps for
a sequence of calibrated images to recover dense point clouds. However,
existing MVS methods often struggle with challenging regions, such as
textureless regions and reflective surfaces, where feature matching fails. In
contrast, monocular depth estimation inherently does not require feature
matching, allowing it to achieve robust relative depth estimation in these
regions. To bridge this gap, we propose MonoMVSNet, a novel monocular feature
and depth guided MVS network that integrates powerful priors from a monocular
foundation model into multi-view geometry. Firstly, the monocular feature of
the reference view is integrated into source view features by the attention
mechanism with a newly designed cross-view position encoding. Then, the
monocular depth of the reference view is aligned to dynamically update the
depth candidates for edge regions during the sampling procedure. Finally, a
relative consistency loss is further designed based on the monocular depth to
supervise the depth prediction. Extensive experiments demonstrate that
MonoMVSNet achieves state-of-the-art performance on the DTU and
Tanks-and-Temples datasets, ranking first on the Tanks-and-Temples Intermediate
and Advanced benchmarks. The source code is available at
https://github.com/JianfeiJ/MonoMVSNet.

</details>


### [65] [COLIBRI Fuzzy Model: Color Linguistic-Based Representation and Interpretation](https://arxiv.org/abs/2507.11488)
*Pakizar Shamoi,Nuray Toganas,Muragul Muratbekova,Elnara Kadyrgali,Adilet Yerkin,Ayan Igali,Malika Ziyada,Ayana Adilova,Aron Karatayev,Yerdauit Torekhan*

Main category: cs.CV

TL;DR: 论文提出了一种基于人类感知的模糊颜色模型COLIBRI，旨在弥合计算机颜色表示与人类视觉感知之间的差距。通过大规模实验和模糊逻辑，模型更贴近人类感知。


<details>
  <summary>Details</summary>
Motivation: 计算机难以模仿人类颜色感知，需要一种更贴近人类视觉的颜色表示方法。

Method: 采用三阶段实验方法，包括初步实验、大规模人类分类调查和模糊分区提取，生成反映感知不确定性的隶属函数。

Result: 模型在人类感知对齐方面优于传统颜色模型（如RGB、HSV、LAB），适用于设计、AI、营销等领域。

Conclusion: COLIBRI模型为颜色属性规范提供了新方法，对需要感知相关颜色表示的领域具有重要意义。

Abstract: Colors are omnipresent in today's world and play a vital role in how humans
perceive and interact with their surroundings. However, it is challenging for
computers to imitate human color perception. This paper introduces the Human
Perception-Based Fuzzy Color Model, COLIBRI (Color Linguistic-Based
Representation and Interpretation), designed to bridge the gap between
computational color representations and human visual perception. The proposed
model uses fuzzy sets and logic to create a framework for color categorization.
Using a three-phase experimental approach, the study first identifies
distinguishable color stimuli for hue, saturation, and intensity through
preliminary experiments, followed by a large-scale human categorization survey
involving more than 1000 human subjects. The resulting data are used to extract
fuzzy partitions and generate membership functions that reflect real-world
perceptual uncertainty. The model incorporates a mechanism for adaptation that
allows refinement based on feedback and contextual changes. Comparative
evaluations demonstrate the model's alignment with human perception compared to
traditional color models, such as RGB, HSV, and LAB. To the best of our
knowledge, no previous research has documented the construction of a model for
color attribute specification based on a sample of this size or a comparable
sample of the human population (n = 2496). Our findings are significant for
fields such as design, artificial intelligence, marketing, and human-computer
interaction, where perceptually relevant color representation is critical.

</details>


### [66] [UGC-VideoCaptioner: An Omni UGC Video Detail Caption Model and New Benchmarks](https://arxiv.org/abs/2507.11336)
*Peiran Wu,Yunze Liu,Zhengdong Zhu,Enmin Zhou,Shawn Shen*

Main category: cs.CV

TL;DR: 论文提出了UGC-VideoCap，一个专注于短用户生成视频的多模态字幕基准和模型框架，强调音频与视觉的平衡整合。


<details>
  <summary>Details</summary>
Motivation: 现有视频字幕基准和模型过于视觉中心化，忽视了音频在场景动态、说话者意图和叙事背景中的关键作用。

Method: 通过三阶段人工标注流程构建数据集，并提出3B参数的字幕模型UGC-VideoCaptioner，采用两阶段训练策略（监督微调+GRPO）。

Result: UGC-VideoCap包含1000个TikTok视频和4000个QA对，模型在有限数据下保持竞争力。

Conclusion: UGC-VideoCap为无约束真实场景下的多模态视频字幕提供了高质量基准和数据高效解决方案。

Abstract: Real-world user-generated videos, especially on platforms like TikTok, often
feature rich and intertwined audio visual content. However, existing video
captioning benchmarks and models remain predominantly visual centric,
overlooking the crucial role of audio in conveying scene dynamics, speaker
intent, and narrative context. This lack of omni datasets and lightweight,
capable models hampers progress in fine grained, multimodal video
understanding. To address these challenges, we introduce UGC-VideoCap, a new
benchmark and model framework specifically designed for detailed omnimodal
captioning of short form user-generated videos. Unlike prior datasets,
UGC-VideoCap emphasizes balanced integration of audio and visual modalities,
featuring 1000 TikTok videos annotated through a structured three stage
human-in-the-loop pipeline covering audio only, visual only, and joint audio
visual semantics. The benchmark also includes 4000 carefully crafted QA pairs
probing both unimodal and cross modal understanding. Alongside the dataset, we
propose UGC-VideoCaptioner(3B), a 3B parameter captioning model distilled from
Gemini 2.5 Flash. Using a novel two-stage training strategy supervised fine
tuning followed by Group Relative Policy Optimization (GRPO), our approach
enables efficient adaptation from limited data while maintaining competitive
performance. Together, our benchmark and model offer a high-quality foundation
and a data-efficient solution for advancing omnimodal video captioning in
unconstrained real-world UGC settings.

</details>


### [67] [Streaming 4D Visual Geometry Transformer](https://arxiv.org/abs/2507.11539)
*Dong Zhuo,Wenzhao Zheng,Jiahe Guo,Yuqi Wu,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: 提出了一种流式4D视觉几何变换器，用于实时感知和重建视频中的4D时空几何，采用因果变换器架构和隐式记忆缓存，支持高效训练和推理。


<details>
  <summary>Details</summary>
Motivation: 解决视频中4D时空几何感知与重建的实时性和交互性挑战。

Method: 使用因果变换器架构和时序因果注意力，缓存历史键值作为隐式记忆，并从双向视觉几何变换器中蒸馏知识。

Result: 在多个4D几何感知基准测试中，模型在在线场景下显著提升推理速度，同时保持竞争力。

Conclusion: 该模型为可扩展和交互式4D视觉系统铺平了道路。

Abstract: Perceiving and reconstructing 4D spatial-temporal geometry from videos is a
fundamental yet challenging computer vision task. To facilitate interactive and
real-time applications, we propose a streaming 4D visual geometry transformer
that shares a similar philosophy with autoregressive large language models. We
explore a simple and efficient design and employ a causal transformer
architecture to process the input sequence in an online manner. We use temporal
causal attention and cache the historical keys and values as implicit memory to
enable efficient streaming long-term 4D reconstruction. This design can handle
real-time 4D reconstruction by incrementally integrating historical information
while maintaining high-quality spatial consistency. For efficient training, we
propose to distill knowledge from the dense bidirectional visual geometry
grounded transformer (VGGT) to our causal model. For inference, our model
supports the migration of optimized efficient attention operator (e.g.,
FlashAttention) from the field of large language models. Extensive experiments
on various 4D geometry perception benchmarks demonstrate that our model
increases the inference speed in online scenarios while maintaining competitive
performance, paving the way for scalable and interactive 4D vision systems.
Code is available at: https://github.com/wzzheng/StreamVGGT.

</details>


### [68] [Implementing Adaptations for Vision AutoRegressive Model](https://arxiv.org/abs/2507.11441)
*Kaif Shaikh,Antoni Kowalczuk,Franziska Boenisch,Adam Dziedzic*

Main category: cs.CV

TL;DR: VAR在图像生成领域作为DM的替代方案被提出，但其适应性和隐私保护研究不足。本文实现并比较了VAR与DM的适应策略，发现VAR在非隐私保护任务中表现更优，但在隐私保护任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 研究VAR在特定下游任务（如医学数据生成）中的适应性及隐私保护策略，填补VAR在此领域的空白。

Method: 实现并比较多种VAR适应策略，包括隐私保护和非隐私保护方法，并与DM的现有策略进行对比。

Result: VAR在非隐私保护任务中优于DM，但在隐私保护任务中表现较差。

Conclusion: VAR在非隐私保护任务中具有优势，但隐私保护适应性仍需进一步研究。

Abstract: Vision AutoRegressive model (VAR) was recently introduced as an alternative
to Diffusion Models (DMs) in image generation domain. In this work we focus on
its adaptations, which aim to fine-tune pre-trained models to perform specific
downstream tasks, like medical data generation. While for DMs there exist many
techniques, adaptations for VAR remain underexplored. Similarly, differentially
private (DP) adaptations-ones that aim to preserve privacy of the adaptation
data-have been extensively studied for DMs, while VAR lacks such solutions. In
our work, we implement and benchmark many strategies for VAR, and compare them
to state-of-the-art DM adaptation strategies. We observe that VAR outperforms
DMs for non-DP adaptations, however, the performance of DP suffers, which
necessitates further research in private adaptations for VAR. Code is available
at https://github.com/sprintml/finetuning_var_dp.

</details>


### [69] [HUG-VAS: A Hierarchical NURBS-Based Generative Model for Aortic Geometry Synthesis and Controllable Editing](https://arxiv.org/abs/2507.11474)
*Pan Du,Mingqi Xu,Xiaozhi Zhu,Jian-xun Wang*

Main category: cs.CV

TL;DR: HUG-VAS是一种基于NURBS和扩散模型的层次生成模型，用于合成高保真度的主动脉几何结构，支持零样本条件生成。


<details>
  <summary>Details</summary>
Motivation: 传统统计形状建模方法受限于线性假设，难以处理复杂血管拓扑结构，因此需要更灵活且高保真的建模方法。

Method: 结合NURBS表面参数化和扩散生成模型，采用分层架构（中心线去噪扩散模型和径向轮廓引导扩散模型）生成血管几何。

Result: 生成的主动脉几何与原始数据集生物标志物分布高度匹配，支持零样本条件生成，适用于多种实际应用。

Conclusion: HUG-VAS首次通过NURBS和分层扩散过程的统一集成，实现了图像先验与生成形状建模的桥梁。

Abstract: Accurate characterization of vascular geometry is essential for
cardiovascular diagnosis and treatment planning. Traditional statistical shape
modeling (SSM) methods rely on linear assumptions, limiting their expressivity
and scalability to complex topologies such as multi-branch vascular structures.
We introduce HUG-VAS, a Hierarchical NURBS Generative model for Vascular
geometry Synthesis, which integrates NURBS surface parameterization with
diffusion-based generative modeling to synthesize realistic, fine-grained
aortic geometries. Trained with 21 patient-specific samples, HUG-VAS generates
anatomically faithful aortas with supra-aortic branches, yielding biomarker
distributions that closely match those of the original dataset. HUG-VAS adopts
a hierarchical architecture comprising a denoising diffusion model that
generates centerlines and a guided diffusion model that synthesizes radial
profiles conditioned on those centerlines, thereby capturing two layers of
anatomical variability. Critically, the framework supports zero-shot
conditional generation from image-derived priors, enabling practical
applications such as interactive semi-automatic segmentation, robust
reconstruction under degraded imaging conditions, and implantable device
optimization. To our knowledge, HUG-VAS is the first SSM framework to bridge
image-derived priors with generative shape modeling via a unified integration
of NURBS parameterization and hierarchical diffusion processes.

</details>


### [70] [C-FBI: A Combinatorial method using Convolutions for Circle Fitting in Blurry Images](https://arxiv.org/abs/2507.11476)
*Esteban Román Catafau,Torbjörn E. M. Nordling*

Main category: cs.CV

TL;DR: 3C-FBI算法通过组合边缘像素采样和卷积密度估计，在模糊图像中实现高精度圆检测与拟合，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决在退化成像条件下鲁棒的圆检测与拟合问题，填补圆检测与参数拟合之间的技术空白。

Method: 结合高效的组合边缘像素采样和参数空间中的卷积密度估计。

Result: 在真实医学数据、合成数据和不同分辨率/噪声条件下，3C-FBI表现出高精度（Jaccard指数0.896）和实时性能（40.3 fps），优于RCD等方法。

Conclusion: 3C-FBI在精度、速度和鲁棒性上的优异表现，使其适用于医疗影像、机器人和工业检测等挑战性场景。

Abstract: This paper addresses the fundamental computer vision challenge of robust
circle detection and fitting in degraded imaging conditions. We present
Combinatorial Convolution-based Circle Fitting for Blurry Images (3C-FBI), an
algorithm that bridges the gap between circle detection and precise parametric
fitting by combining (1) efficient combinatorial edge pixel (edgel) sampling
and (2) convolution-based density estimation in parameter space.
  We evaluate 3C-FBI across three experimental frameworks: (1) real-world
medical data from Parkinson's disease assessments (144 frames from 36 videos),
(2) controlled synthetic data following established circle-fitting benchmarks,
and (3) systematic analysis across varying spatial resolutions and outlier
contamination levels. Results show that 3C-FBI achieves state-of-the-art
accuracy (Jaccard index 0.896) while maintaining real-time performance (40.3
fps), significantly outperforming classical methods like RCD (6.8 fps) on a
standard CPU (i7-10875H). It maintains near-perfect accuracy (Jaccard almost
1.0) at high resolutions (480x480) and reliable performance (Jaccard higher
than 0.95) down to 160x160 with up to 20% outliers.
  In extensive synthetic testing, 3C-FBI achieves a mean Jaccard Index of 0.989
across contamination levels, comparable to modern methods like Qi et al. (2024,
0.991), and surpassing RHT (0.964). This combination of accuracy, speed, and
robustness makes 3C-FBI ideal for medical imaging, robotics, and industrial
inspection under challenging conditions.

</details>


### [71] [CATVis: Context-Aware Thought Visualization](https://arxiv.org/abs/2507.11522)
*Tariq Mehmood,Hamza Ahmad,Muhammad Haroon Shakeel,Murtaza Taj*

Main category: cs.CV

TL;DR: 提出了一种5阶段框架，用于从EEG信号解码视觉表示，通过跨模态对齐和重排序实现高质量的EEG到图像生成。


<details>
  <summary>Details</summary>
Motivation: EEG信号复杂且噪声多，解码视觉表示具有挑战性。

Method: 5阶段框架：EEG编码器、跨模态对齐、标题重排序、加权插值和图像生成。

Result: 生成高质量图像，分类和生成准确率分别提升13.43%和15.21%，FID降低36.61%。

Conclusion: 方法在语义对齐和图像质量上优于现有技术。

Abstract: EEG-based brain-computer interfaces (BCIs) have shown promise in various
applications, such as motor imagery and cognitive state monitoring. However,
decoding visual representations from EEG signals remains a significant
challenge due to their complex and noisy nature. We thus propose a novel
5-stage framework for decoding visual representations from EEG signals: (1) an
EEG encoder for concept classification, (2) cross-modal alignment of EEG and
text embeddings in CLIP feature space, (3) caption refinement via re-ranking,
(4) weighted interpolation of concept and caption embeddings for richer
semantics, and (5) image generation using a pre-trained Stable Diffusion model.
We enable context-aware EEG-to-image generation through cross-modal alignment
and re-ranking. Experimental results demonstrate that our method generates
high-quality images aligned with visual stimuli, outperforming SOTA approaches
by 13.43% in Classification Accuracy, 15.21% in Generation Accuracy and
reducing Fr\'echet Inception Distance by 36.61%, indicating superior semantic
alignment and image quality.

</details>


### [72] [CharaConsist: Fine-Grained Consistent Character Generation](https://arxiv.org/abs/2507.11533)
*Mengyu Wang,Henghui Ding,Jianing Peng,Yao Zhao,Yunpeng Chen,Yunchao Wei*

Main category: cs.CV

TL;DR: 提出CharaConsist方法，通过点跟踪注意力和自适应令牌合并，解决文本到图像生成中一致性问题，支持连续或离散场景中的角色一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在保持背景细节和角色大动作变化时的一致性上表现不佳，限制了实际应用。

Method: 采用点跟踪注意力、自适应令牌合并及前景背景解耦控制。

Result: CharaConsist能实现细粒度一致性，支持固定场景或跨场景的角色生成，并适配DiT模型。

Conclusion: CharaConsist扩展了文本到图像生成的应用范围，提升了生成质量。

Abstract: In text-to-image generation, producing a series of consistent contents that
preserve the same identity is highly valuable for real-world applications.
Although a few works have explored training-free methods to enhance the
consistency of generated subjects, we observe that they suffer from the
following problems. First, they fail to maintain consistent background details,
which limits their applicability. Furthermore, when the foreground character
undergoes large motion variations, inconsistencies in identity and clothing
details become evident. To address these problems, we propose CharaConsist,
which employs point-tracking attention and adaptive token merge along with
decoupled control of the foreground and background. CharaConsist enables
fine-grained consistency for both foreground and background, supporting the
generation of one character in continuous shots within a fixed scene or in
discrete shots across different scenes. Moreover, CharaConsist is the first
consistent generation method tailored for text-to-image DiT model. Its ability
to maintain fine-grained consistency, combined with the larger capacity of
latest base model, enables it to produce high-quality visual outputs,
broadening its applicability to a wider range of real-world scenarios. The
source code has been released at https://github.com/Murray-Wang/CharaConsist

</details>


### [73] [Towards Depth Foundation Model: Recent Trends in Vision-Based Depth Estimation](https://arxiv.org/abs/2507.11540)
*Zhen Xu,Hongyu Zhou,Sida Peng,Haotong Lin,Haoyu Guo,Jiahao Shao,Peishan Yang,Qinglin Yang,Sheng Miao,Xingyi He,Yifan Wang,Yue Wang,Ruizhen Hu,Yiyi Liao,Xiaowei Zhou,Hujun Bao*

Main category: cs.CV

TL;DR: 该论文综述了深度估计在3D计算机视觉中的重要性，探讨了传统硬件方法的局限性以及基于视觉方法的挑战，并提出了深度基础模型的潜力。


<details>
  <summary>Details</summary>
Motivation: 深度估计是3D计算机视觉中的基础任务，但传统硬件方法成本高且受限，而现有视觉方法在泛化和稳定性方面存在问题。深度基础模型可能解决这些问题。

Method: 论文综述了单目、立体、多视角和单目视频设置下的深度学习架构和范式，并探讨了大规模数据集的作用。

Result: 通过分析关键架构和训练策略，论文指出了构建鲁棒深度基础模型的路径。

Conclusion: 深度基础模型有望解决现有挑战，未来研究和应用前景广阔。

Abstract: Depth estimation is a fundamental task in 3D computer vision, crucial for
applications such as 3D reconstruction, free-viewpoint rendering, robotics,
autonomous driving, and AR/VR technologies. Traditional methods relying on
hardware sensors like LiDAR are often limited by high costs, low resolution,
and environmental sensitivity, limiting their applicability in real-world
scenarios. Recent advances in vision-based methods offer a promising
alternative, yet they face challenges in generalization and stability due to
either the low-capacity model architectures or the reliance on domain-specific
and small-scale datasets. The emergence of scaling laws and foundation models
in other domains has inspired the development of "depth foundation models":
deep neural networks trained on large datasets with strong zero-shot
generalization capabilities. This paper surveys the evolution of deep learning
architectures and paradigms for depth estimation across the monocular, stereo,
multi-view, and monocular video settings. We explore the potential of these
models to address existing challenges and provide a comprehensive overview of
large-scale datasets that can facilitate their development. By identifying key
architectures and training strategies, we aim to highlight the path towards
robust depth foundation models, offering insights into their future research
and applications.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [74] [SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents](https://arxiv.org/abs/2507.10562)
*Hari Masoor*

Main category: cs.AI

TL;DR: SAMEP是一种新型框架，通过持久、安全且可语义搜索的内存共享解决AI代理的短暂记忆限制问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理架构存在短暂记忆限制，无法跨会话和代理边界有效协作和共享知识。

Method: SAMEP采用分布式内存存储库，结合向量语义搜索、加密访问控制和标准化API。

Result: 实验显示，SAMEP减少73%冗余计算，提升89%上下文相关性，并完全符合监管要求。

Conclusion: SAMEP为持久协作的AI代理生态系统提供了安全、隐私保障的新范式。

Abstract: Current AI agent architectures suffer from ephemeral memory limitations,
preventing effective collaboration and knowledge sharing across sessions and
agent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a
novel framework that enables persistent, secure, and semantically searchable
memory sharing among AI agents. Our protocol addresses three critical
challenges: (1) persistent context preservation across agent sessions, (2)
secure multi-agent collaboration with fine-grained access control, and (3)
efficient semantic discovery of relevant historical context. SAMEP implements a
distributed memory repository with vector-based semantic search, cryptographic
access controls (AES-256-GCM), and standardized APIs compatible with existing
agent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness
across diverse domains including multi-agent software development, healthcare
AI with HIPAA compliance, and multi-modal processing pipelines. Experimental
results show 73% reduction in redundant computations, 89% improvement in
context relevance scores, and complete compliance with regulatory requirements
including audit trail generation. SAMEP enables a new paradigm of persistent,
collaborative AI agent ecosystems while maintaining security and privacy
guarantees.

</details>


### [75] [AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems](https://arxiv.org/abs/2507.10566)
*Hung Ming Liu*

Main category: cs.AI

TL;DR: 论文提出了一种基于VQ-VAE的"AI Mother Tongue"框架，证明无需外部归纳偏置，代理可通过内生的符号系统实现自然语义压缩和纳什均衡驱动的语义收敛，从而达成有效通信。


<details>
  <summary>Details</summary>
Motivation: 解决去中心化多智能体强化学习中"联合探索困境"导致的"通信真空均衡"问题，质疑传统方法中人工归纳偏置的必要性。

Method: 采用基于VQ-VAE的AIM框架，通过内生符号系统实现语义压缩与收敛，避免外部偏置。

Result: AIM框架在无需人工偏置的情况下，实现了高效且通用的符号通信，符号使用呈现幂律分布，并提出了三项理论洞见。

Conclusion: AIM框架为连接符号主义与连接主义提供了新途径，未来将探索HQ-VAE增强表达能力及RL低阶预训练的潜力。

Abstract: In Decentralized Multi-Agent Reinforcement Learning (MARL), the development
of Emergent Communication has long been constrained by the ``Joint Exploration
Dilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' .
Traditional methods address this by introducing inductive biases to facilitate
communication emergence . This study fundamentally questions whether such
artificial inductive biases are, in fact, over-engineering. Through experiments
with the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized
Variational Autoencoder (VQ-VAE), we demonstrate that when agents possess an
endogenous symbol system, their neural representations naturally exhibit
spontaneous semantic compression and Nash equilibrium-driven semantic
convergence, achieving effective symbolic communication without external
inductive biases. This aligns with recent neuroscience findings suggesting that
the human brain does not directly use human language for internal thought , and
resonates with research on ``soft thinking'' capabilities in Large Language
Models (LLMs) . Compared to traditional explicit communication methods, AIM
demonstrates stronger generality and efficiency. The interpretable analysis
toolkit developed in this study confirms that symbol usage exhibits a
significant power-law distribution, leading to three major theoretical
insights: the ``Neural Communication Hypothesis'', the ``Tool-First
Principle'', and the ``Semantic Interpretability Paradigm''. Future research
will explore the integration of Hierarchical Quantized Variational Autoencoders
(HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the
potential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This
discovery offers new avenues for bridging symbolism and connectionism.

</details>


### [76] [Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning](https://arxiv.org/abs/2507.10571)
*Konstantinos I. Roumeliotis,Ranjan Sapkota,Manoj Karkee,Nikolaos D. Tselikas*

Main category: cs.AI

TL;DR: 论文提出了一种模块化的多智能体AI视觉分类框架，通过信任感知的协调和RAG模块，显著提升了零样本设置的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体AI在零样本设置中的信任问题，尤其是在视觉和语言理解结合的领域。

Method: 结合通用多模态智能体、非视觉推理协调器和RAG模块，通过置信度校准和图像检索增强信任。

Result: 在零样本设置中，信任感知协调和RAG使准确率提升77.94%，总体达到85.63%。

Conclusion: 该系统可扩展至诊断、生物学等信任关键领域，代码和模型已开源。

Abstract: Modern Artificial Intelligence (AI) increasingly relies on multi-agent
architectures that blend visual and language understanding. Yet, a pressing
challenge remains: How can we trust these agents especially in zero-shot
settings with no fine-tuning? We introduce a novel modular Agentic AI visual
classification framework that integrates generalist multimodal agents with a
non-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG)
module. Applied to apple leaf disease diagnosis, we benchmark three
configurations: (I) zero-shot with confidence-based orchestration, (II)
fine-tuned agents with improved performance, and (III) trust-calibrated
orchestration enhanced by CLIP-based image retrieval and re-evaluation loops.
Using confidence calibration metrics (ECE, OCR, CCC), the orchestrator
modulates trust across agents. Our results demonstrate a 77.94\% accuracy
improvement in the zero-shot setting using trust-aware orchestration and RAG,
achieving 85.63\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL
displayed overconfidence. Furthermore, image-RAG grounded predictions with
visually similar cases, enabling correction of agent overconfidence via
iterative re-evaluation. The proposed system separates perception (vision
agents) from meta-reasoning (orchestrator), enabling scalable and interpretable
multi-agent AI. This blueprint is extensible to diagnostics, biology, and other
trust-critical domains. All models, prompts, results, and system components
including the complete software source code are openly released to support
reproducibility, transparency, and community benchmarking at Github:
https://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust

</details>


### [77] [Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning](https://arxiv.org/abs/2507.10624)
*Zheng Zhang*

Main category: cs.AI

TL;DR: 论文分析了大型语言模型（LLMs）在符号推理、算术准确性和逻辑一致性任务中的系统性失败，提出了“计算分裂脑综合征”的概念，揭示了模型在理解和执行之间的鸿沟。


<details>
  <summary>Details</summary>
Motivation: 研究旨在诊断LLMs在复杂任务中失败的根本原因，揭示其表面流畅性与实际能力之间的不一致性。

Method: 通过控制实验和架构分析，研究LLMs在表达正确原则与应用这些原则之间的差距。

Result: 发现LLMs缺乏组合推理的架构支持，其行为脆弱性源于指令与执行路径的几何和功能分离。

Conclusion: 研究界定了当前LLMs的能力边界，并提出了未来模型需要具备元认知控制、原则提升和结构化执行能力的建议。

Abstract: Large Language Models (LLMs) display striking surface fluency yet
systematically fail at tasks requiring symbolic reasoning, arithmetic accuracy,
and logical consistency. This paper offers a structural diagnosis of such
failures, revealing a persistent gap between \textit{comprehension} and
\textit{competence}. Through controlled experiments and architectural analysis,
we demonstrate that LLMs often articulate correct principles without reliably
applying them--a failure rooted not in knowledge access, but in computational
execution. We term this phenomenon the computational \textit{split-brain
syndrome}, where instruction and action pathways are geometrically and
functionally dissociated. This core limitation recurs across domains, from
mathematical operations to relational inferences, and explains why model
behavior remains brittle even under idealized prompting. We argue that LLMs
function as powerful pattern completion engines, but lack the architectural
scaffolding for principled, compositional reasoning. Our findings delineate the
boundary of current LLM capabilities and motivate future models with
metacognitive control, principle lifting, and structurally grounded execution.
This diagnosis also clarifies why mechanistic interpretability findings may
reflect training-specific pattern coordination rather than universal
computational principles, and why the geometric separation between instruction
and execution pathways suggests limitations in neural introspection and
mechanistic analysis.

</details>


### [78] [Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs](https://arxiv.org/abs/2507.10630)
*Ye Yang,Xue Xiao,Ping Yin,Taotao Xie*

Main category: cs.AI

TL;DR: KG2data是一个结合知识图谱、LLMs、ReAct代理和工具使用技术的系统，用于气象领域的数据获取和查询处理，性能优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs通过API调用在知识密集型领域（如气象学）中有效利用工具的能力。

Method: 集成知识图谱、LLMs、ReAct代理和工具使用技术，通过虚拟API评估API调用的准确性。

Result: KG2data在名称识别失败（1.43%）、幻觉失败（0%）和调用正确性（88.57%）上表现优于RAG2data和chat2data。

Conclusion: KG2data为高知识需求领域提供了智能、基于知识的问答和数据分析解决方案。

Abstract: API calls by large language models (LLMs) offer a cutting-edge approach for
data analysis. However, their ability to effectively utilize tools via API
calls remains underexplored in knowledge-intensive domains like meteorology.
This paper introduces KG2data, a system that integrates knowledge graphs, LLMs,
ReAct agents, and tool-use technologies to enable intelligent data acquisition
and query handling in the meteorological field. Using a virtual API, we
evaluate API call accuracy across three metrics: name recognition failure,
hallucination failure, and call correctness. KG2data achieves superior
performance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and
chat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based
systems by addressing their limited access to domain-specific knowledge, which
hampers performance on complex or terminology-rich queries. By using a
knowledge graph as persistent memory, our system enhances content retrieval,
complex query handling, domain-specific reasoning, semantic relationship
resolution, and heterogeneous data integration. It also mitigates the high cost
of fine-tuning LLMs, making the system more adaptable to evolving domain
knowledge and API structures. In summary, KG2data provides a novel solution for
intelligent, knowledge-based question answering and data analysis in domains
with high knowledge demands.

</details>


### [79] [From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents](https://arxiv.org/abs/2507.10644)
*Tatiana Petrova,Aleksandr Puzikov,Boris Bliznukov,Radu State*

Main category: cs.AI

TL;DR: 本文提出了Web of Agents (WoA)的全面进化概述，揭示了现代协议如A2A和MCP是对早期标准如FIPA和OWL的直接进化响应，并通过四轴分类法统一分析了各代代理架构。


<details>
  <summary>Details</summary>
Motivation: 研究WoA领域的碎片化问题，揭示其历史脉络，促进对该领域发展的整体理解。

Method: 引入四轴分类法（语义基础、通信范式、智能中心、发现机制）系统比较各代代理架构。

Result: 发现智能中心从外部数据或平台转移到代理核心模型的范式转变，这是现代Agentic AI的基础。

Conclusion: 新协议虽必要但不足，未来研究应聚焦于去中心化身份、经济模型、安全和治理等社会技术挑战。

Abstract: The concept of the Web of Agents (WoA), which transforms the static,
document-centric Web into an environment of autonomous agents acting on users'
behalf, has attracted growing interest as large language models (LLMs) become
more capable. However, research in this area is still fragmented across
different communities. Contemporary surveys catalog the latest LLM-powered
frameworks, while the rich histories of Multi-Agent Systems (MAS) and the
Semantic Web are often treated as separate, legacy domains. This fragmentation
obscures the intellectual lineage of modern systems and hinders a holistic
understanding of the field's trajectory. We present the first comprehensive
evolutionary overview of the WoA. We show that modern protocols like A2A and
the MCP, are direct evolutionary responses to the well-documented limitations
of earlier standards like FIPA standards and OWL-based semantic agents. To
systematize this analysis, we introduce a four-axis taxonomy (semantic
foundation, communication paradigm, locus of intelligence, discovery
mechanism). This framework provides a unified analytical lens for comparing
agent architectures across all generations, revealing a clear line of descent
where others have seen a disconnect. Our analysis identifies a paradigm shift
in the 'locus of intelligence': from being encoded in external data (Semantic
Web) or the platform (MAS) to being embedded within the agent's core model
(LLM). This shift is foundational to modern Agentic AI, enabling the scalable
and adaptive systems the WoA has long envisioned. We conclude that while new
protocols are essential, they are insufficient for building a robust, open,
trustworthy ecosystem. Finally, we argue that the next research frontier lies
in solving persistent socio-technical challenges, and we map out a new agenda
focused on decentralized identity, economic models, security, and governance
for the emerging WoA.

</details>


### [80] [Parsing Musical Structure to Enable Meaningful Variations](https://arxiv.org/abs/2507.10740)
*Maziar Kanani,Sean O Leary,James McDermott*

Main category: cs.AI

TL;DR: 提出了一种基于规则的音乐生成方法，通过变异现有曲调的语法结构生成新曲调，分析了变异对曲调的影响。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过变异现有曲调的语法结构生成新曲调，并研究变异对曲调的影响。

Method: 使用Sequitur算法解析曲调生成语法结构，随机应用19种变异类型，扩展语法生成新曲调。

Result: 通过编辑距离、结构复杂度和曲调长度分析变异效果，并评估输出曲调的音乐性。

Conclusion: 该方法能有效生成与原曲调相关的新曲调，但仅关注音高序列生成。

Abstract: This paper presents a novel rule-based approach for generating music by
varying existing tunes. We parse each tune to find the Pathway Assembly (PA) [
1], that is a structure representing all repetitions in the tune. The Sequitur
algorithm [2 ] is used for this. The result is a grammar. We then carry out
mutation on the grammar, rather than on a tune directly. There are potentially
19 types of mutations such as adding, removing, swapping or reversing parts of
the grammar that can be applied to the grammars. The system employs one of the
mutations randomly in this step to automatically manipulate the grammar.
Following the mutation, we need to expand the grammar which returns a new tune.
The output after 1 or more mutations will be a new tune related to the original
tune. Our study examines how tunes change gradually over the course of multiple
mutations. Edit distances, structural complexity and length of the tunes are
used to show how a tune is changed after multiple mutations. In addition, the
size of effect of each mutation type is analyzed. As a final point, we review
the musical aspect of the output tunes. It should be noted that the study only
focused on generating new pitch sequences. The study is based on an Irish
traditional tune dataset and a list of integers has been used to represent each
tune's pitch values.

</details>


### [81] [AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition](https://arxiv.org/abs/2507.10750)
*Pandu Devarakota,Nicolas Tsesmetzis,Faruk O. Alpak,Apurva Gala,Detlef Hohl*

Main category: cs.AI

TL;DR: AI的快速发展增加了数据中心的能源消耗和温室气体排放，短期内可能加剧环境问题，但长期来看，AI有望通过优化能源使用和流程自动化显著减少碳排放。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在能源消耗和温室气体排放方面的双重影响，评估其短期和长期对环境的潜在贡献。

Method: 分析数据中心的能源消耗情景，结合近远期（2030年及以后）的预测，评估AI对碳排放的影响。

Result: 短期内AI可能增加碳排放，但长期来看，其优化和自动化能力有望显著减少碳足迹。

Conclusion: AI虽在初期可能对环境造成压力，但长期具备支持气候缓解的潜力。

Abstract: Thanks to the availability of massive amounts of data, computing resources,
and advanced algorithms, AI has entered nearly every sector. This has sparked
significant investment and interest, particularly in building data centers with
the necessary hardware and software to develop and operate AI models and
AI-based workflows. In this technical review article, we present energy
consumption scenarios of data centers and impact on GHG emissions, considering
both near-term projections (up to 2030) and long-term outlook (2035 and
beyond). We address the quintessential question of whether AI will have a net
positive, neutral, or negative impact on CO2 emissions by 2035. Additionally,
we discuss AI's potential to automate, create efficient and disruptive
workflows across various fields related to energy production, supply and
consumption. In the near-term scenario, the growing demand for AI will likely
strain computing resources, lead to increase in electricity consumption and
therefore associated CO2 emissions. This is due to the power-hungry nature of
big data centers and the requirements for training and running of large and
complex AI models, as well as the penetration of AI assistant search and
applications for public use. However, the long-term outlook could be more
promising. AI has the potential to be a game-changer in CO2 reduction. Its
ability to further automate and optimize processes across industries, from
energy production to logistics, could significantly decrease our carbon
footprint. This positive impact is anticipated to outweigh the initial
emissions bump, creating value for businesses and society in areas where
traditional solutions have fallen short. In essence, AI might cause some
initial growing pains for the environment, but it has the potential to support
climate mitigation efforts.

</details>


### [82] [IoT Malware Network Traffic Detection using Deep Learning and GraphSAGE Models](https://arxiv.org/abs/2507.10758)
*Nikesh Prajapati,Bimal Karki,Saroj Gopali,Akbar Siami Namin*

Main category: cs.AI

TL;DR: 该论文通过深度学习模型检测物联网恶意攻击，评估了多种模型在恶意流量检测中的表现，BERT表现最佳。


<details>
  <summary>Details</summary>
Motivation: 物联网系统流量模式具有时序性和多样性，为模型学习提供了丰富的时间模式，因此研究如何利用深度学习模型检测恶意攻击具有重要意义。

Method: 采用了GraphSAGE、BERT、TCN、Multi-Head Attention、BI-LSTM和LSTM等模型，以捕捉时序模式和特征重要性。

Result: BERT表现最优，准确率达99.94%，其他指标如精确率、召回率、F1-score和AUC-ROC均接近99.99%。Multi-Head Attention表现良好但耗时较长，GraphSAGE训练最快但性能最低。

Conclusion: BERT在捕捉时序依赖性方面表现最佳，适合物联网恶意攻击检测；Multi-Head Attention提供可解释结果但效率较低；GraphSAGE适合快速训练但对性能要求不高的场景。

Abstract: This paper intends to detect IoT malicious attacks through deep learning
models and demonstrates a comprehensive evaluation of the deep learning and
graph-based models regarding malicious network traffic detection. The models
particularly are based on GraphSAGE, Bidirectional encoder representations from
transformers (BERT), Temporal Convolutional Network (TCN) as well as Multi-Head
Attention, together with Bidirectional Long Short-Term Memory (BI-LSTM)
Multi-Head Attention and BI-LSTM and LSTM models. The chosen models
demonstrated great performance to model temporal patterns and detect feature
significance. The observed performance are mainly due to the fact that IoT
system traffic patterns are both sequential and diverse, leaving a rich set of
temporal patterns for the models to learn. Experimental results showed that
BERT maintained the best performance. It achieved 99.94% accuracy rate
alongside high precision and recall, F1-score and AUC-ROC score of 99.99% which
demonstrates its capabilities through temporal dependency capture. The
Multi-Head Attention offered promising results by providing good detection
capabilities with interpretable results. On the other side, the Multi-Head
Attention model required significant processing time like BI-LSTM variants. The
GraphSAGE model achieved good accuracy while requiring the shortest training
time but yielded the lowest accuracy, precision, and F1 score compared to the
other models

</details>


### [83] [Detecting AI Assistance in Abstract Complex Tasks](https://arxiv.org/abs/2507.10761)
*Tyler King,Nikolos Gurney,John H. Miller,Volkan Ustun*

Main category: cs.AI

TL;DR: 论文提出将AI辅助检测视为分类任务，通过适当预处理数据，常见模型能有效分类抽象任务数据。作者构建了四种图像表达方式和一种时间序列表达方式，验证了其在经典深度学习架构中的效果。


<details>
  <summary>Details</summary>
Motivation: 随着AI在复杂任务中的普及，检测AI辅助变得重要，但抽象任务数据对检测具有挑战性。

Method: 将AI辅助检测作为分类任务，构建四种图像表达方式和一种时间序列表达方式，测试其在经典深度学习架构中的表现。

Result: 实验表明，适当预处理后，常见模型能有效分类抽象任务数据，时间序列表达方式提升了检测性能。

Conclusion: 编码时空信息对检测抽象任务中的AI辅助至关重要，时间序列表达方式具有通用性。

Abstract: Detecting assistance from artificial intelligence is increasingly important
as they become ubiquitous across complex tasks such as text generation, medical
diagnosis, and autonomous driving. Aid detection is challenging for humans,
especially when looking at abstract task data. Artificial neural networks excel
at classification thanks to their ability to quickly learn from and process
large amounts of data -- assuming appropriate preprocessing. We posit detecting
help from AI as a classification task for such models. Much of the research in
this space examines the classification of complex but concrete data classes,
such as images. Many AI assistance detection scenarios, however, result in data
that is not machine learning-friendly. We demonstrate that common models can
effectively classify such data when it is appropriately preprocessed. To do so,
we construct four distinct neural network-friendly image formulations along
with an additional time-series formulation that explicitly encodes the
exploration/exploitation of users, which allows for generalizability to other
abstract tasks. We benchmark the quality of each image formulation across three
classical deep learning architectures, along with a parallel CNN-RNN
architecture that leverages the additional time series to maximize testing
performance, showcasing the importance of encoding temporal and spatial
quantities for detecting AI aid in abstract tasks.

</details>


### [84] [Uncertainty-Informed Scheduling of Decision Points for Intelligent Mobile Health Interventions](https://arxiv.org/abs/2507.10798)
*Asim H. Gazi,Bhanu T. Gullapalli,Daiqi Gao,Benjamin M. Marlin,Vivek Shetty,Susan A. Murphy*

Main category: cs.AI

TL;DR: SigmaScheduling动态调整决策点时间，提高移动健康干预的及时性。


<details>
  <summary>Details</summary>
Motivation: 固定间隔的决策点调度方法对习惯性行为干预效果不佳，尤其是对作息不规律的用户。

Method: 提出SigmaScheduling方法，根据行为时间预测的不确定性动态调整决策点。

Result: 在68名参与者的真实数据中，SigmaScheduling在70%以上的情况下确保决策点位于刷牙行为之前。

Conclusion: SigmaScheduling可提升精准移动健康干预的效果，尤其适用于时间敏感的习惯性行为。

Abstract: Timely decision making is critical to the effectiveness of mobile health
(mHealth) interventions. At predefined timepoints called "decision points,"
intelligent mHealth systems such as just-in-time adaptive interventions
(JITAIs) estimate an individual's biobehavioral context from sensor or survey
data and determine whether and how to intervene. For interventions targeting
habitual behavior (e.g., oral hygiene), effectiveness often hinges on
delivering support shortly before the target behavior is likely to occur.
Current practice schedules decision points at a fixed interval (e.g., one hour)
before user-provided behavior times, and the fixed interval is kept the same
for all individuals. However, this one-size-fits-all approach performs poorly
for individuals with irregular routines, often scheduling decision points after
the target behavior has already occurred, rendering interventions ineffective.
In this paper, we propose SigmaScheduling, a method to dynamically schedule
decision points based on uncertainty in predicted behavior times. When behavior
timing is more predictable, SigmaScheduling schedules decision points closer to
the predicted behavior time; when timing is less certain, SigmaScheduling
schedules decision points earlier, increasing the likelihood of timely
intervention. We evaluated SigmaScheduling using real-world data from 68
participants in a 10-week trial of Oralytics, a JITAI designed to improve daily
toothbrushing. SigmaScheduling increased the likelihood that decision points
preceded brushing events in at least 70% of cases, preserving opportunities to
intervene and impact behavior. Our results indicate that SigmaScheduling can
advance precision mHealth, particularly for JITAIs targeting time-sensitive,
habitual behaviors such as oral hygiene or dietary habits.

</details>


### [85] [Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case](https://arxiv.org/abs/2507.10803)
*JaMor Hairston,Ritvik Ranjan,Sahithi Lakamana,Anthony Spadaro,Selen Bozkurt,Jeanmarie Perrone,Abeed Sarker*

Main category: cs.AI

TL;DR: 研究表明，少量提示的LLM（如GPT-4o）可以高效复现专家驱动的主题分析，为定性研究提供可扩展的补充。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在需要深度解释和领域专业知识的归纳主题分析任务中的可行性。

Method: 使用Reddit数据集，通过零、单和少量提示策略，将任务建模为一系列二元分类，评估LLM性能。

Result: GPT-4o在少量提示下表现最佳（准确率90.9%，F1分数0.71），高流行主题的分布与专家分类接近。

Conclusion: 少量提示的LLM方法可以自动化主题分析，为定性研究提供可扩展的解决方案。

Abstract: Background Large language models (LLMs) face challenges in inductive thematic
analysis, a task requiring deep interpretive and domain-specific expertise. We
evaluated the feasibility of using LLMs to replicate expert-driven thematic
analysis of social media data. Methods Using two temporally non-intersecting
Reddit datasets on xylazine (n=286 and n=686, for model optimization and
validation, respectively) with twelve expert-derived themes, we evaluated five
LLMs against expert coding. We modeled the task as a series of binary
classifications, rather than a single, multi-label classification, employing
zero-, single-, and few-shot prompting strategies and measuring performance via
accuracy, precision, recall, and F1-score. Results On the validation set,
GPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score:
0.71). For high-prevalence themes, model-derived thematic distributions closely
mirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use:
16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based
approaches can automate thematic analyses, offering a scalable supplement for
qualitative research. Keywords: thematic analysis, large language models,
natural language processing, qualitative analysis, social media, prompt
engineering, public health

</details>


### [86] [AF-XRAY: Visual Explanation and Resolution of Ambiguity in Legal Argumentation Frameworks](https://arxiv.org/abs/2507.10831)
*Yilin Xia,Heng Zheng,Shawn Bowers,Bertram Ludäscher*

Main category: cs.AI

TL;DR: AF-XRAY是一个开源工具包，用于探索和分析法律推理中的抽象论证框架，通过可视化、分类和关键攻击集生成帮助解决模糊性问题。


<details>
  <summary>Details</summary>
Motivation: 法律推理中的论证框架存在模糊性和解释困难，非专家难以理解。AF-XRAY旨在提供工具帮助用户分析和解决这些问题。

Method: AF-XRAY提供分层可视化、攻击边分类、覆盖可视化及关键攻击集生成，将模糊场景转化为明确解决方案。

Result: 工具通过实际法律案例验证，支持目的论法律推理，展示不同假设如何导致不同结论。

Conclusion: AF-XRAY能有效识别模糊性根源，帮助用户探索替代解决方案，提升法律推理的透明度和可理解性。

Abstract: Argumentation frameworks (AFs) provide formal approaches for legal reasoning,
but identifying sources of ambiguity and explaining argument acceptance remains
challenging for non-experts. We present AF-XRAY, an open-source toolkit for
exploring, analyzing, and visualizing abstract AFs in legal reasoning. AF-XRAY
introduces: (i) layered visualizations based on game-theoretic argument length
revealing well-founded derivation structures; (ii) classification of attack
edges by semantic roles (primary, secondary, blunders); (iii) overlay
visualizations of alternative 2-valued solutions on ambiguous 3-valued grounded
semantics; and (iv) identification of critical attack sets whose suspension
resolves undecided arguments. Through systematic generation of critical attack
sets, AF-XRAY transforms ambiguous scenarios into grounded solutions, enabling
users to pinpoint specific causes of ambiguity and explore alternative
resolutions. We use real-world legal cases (e.g., Wild Animals as modeled by
Bench-Capon) to show that our tool supports teleological legal reasoning by
revealing how different assumptions lead to different justified conclusions.

</details>


### [87] [NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization](https://arxiv.org/abs/2507.10894)
*Zongtao He,Liuyi Wang,Lu Chen,Chengju Liu,Qijun Chen*

Main category: cs.AI

TL;DR: NavComposer是一个自动生成高质量导航指令的框架，通过分解和重组语义实体（如动作、场景和对象）来生成自然语言指令。NavInstrCritic是一个无需标注的评估系统，用于评估指令质量。


<details>
  <summary>Details</summary>
Motivation: 解决专家提供的导航指令数量有限，合成指令质量不足的问题，以支持大规模研究。

Method: NavComposer分解语义实体并重组为指令，NavInstrCritic评估指令质量。

Result: 实验证明方法有效，支持大规模和通用性研究。

Conclusion: NavComposer和NavInstrCritic为语言导航研究提供了可扩展和通用的解决方案。

Abstract: Language-guided navigation is a cornerstone of embodied AI, enabling agents
to interpret language instructions and navigate complex environments. However,
expert-provided instructions are limited in quantity, while synthesized
annotations often lack quality, making them insufficient for large-scale
research. To address this, we propose NavComposer, a novel framework for
automatically generating high-quality navigation instructions. NavComposer
explicitly decomposes semantic entities such as actions, scenes, and objects,
and recomposes them into natural language instructions. Its modular
architecture allows flexible integration of state-of-the-art techniques, while
the explicit use of semantic entities enhances both the richness and accuracy
of instructions. Moreover, it operates in a data-agnostic manner, supporting
adaptation to diverse navigation trajectories without domain-specific training.
Complementing NavComposer, we introduce NavInstrCritic, a comprehensive
annotation-free evaluation system that assesses navigation instructions on
three dimensions: contrastive matching, semantic consistency, and linguistic
diversity. NavInstrCritic provides a holistic evaluation of instruction
quality, addressing limitations of traditional metrics that rely heavily on
expert annotations. By decoupling instruction generation and evaluation from
specific navigation agents, our method enables more scalable and generalizable
research. Extensive experiments provide direct and practical evidence for the
effectiveness of our method.

</details>


### [88] [Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation](https://arxiv.org/abs/2507.10911)
*Yicong Wu,Ting Chen,Irit Hochberg,Zhoujian Sun,Ruth Edry,Zhengxing Huang,Mor Peleg*

Main category: cs.AI

TL;DR: 研究探讨了使用基于大型语言模型（LLM）的多代理系统（MAS）为多病症患者提供更安全的治疗建议的可行性，发现单代理系统表现与多学科团队（MDT）相当，但建议仍存在不完整和不必要的药物问题。


<details>
  <summary>Details</summary>
Motivation: 多病症患者的治疗建议因治疗冲突风险而复杂，现有决策支持系统可扩展性不足，研究受全科医生（GP）和MDT协作启发，探索LLM-MAS的潜力。

Method: 设计了模拟MDT决策的单代理和MAS框架，通过LLM代理间的讨论解决医学冲突，并在多病症患者治疗任务上评估性能。

Result: 当前LLM下单代理GP表现与MDT相当，最佳模型能提供满足临床目标的正确建议，但建议不完整且存在不必要的药物冲突。

Conclusion: LLM-MAS在多病症治疗建议中可行，但需改进建议完整性和减少不必要的药物冲突。

Abstract: Therapy recommendation for chronic patients with multimorbidity is
challenging due to risks of treatment conflicts. Existing decision support
systems face scalability limitations. Inspired by the way in which general
practitioners (GP) manage multimorbidity patients, occasionally convening
multidisciplinary team (MDT) collaboration, this study investigated the
feasibility and value of using a Large Language Model (LLM)-based multi-agent
system (MAS) for safer therapy recommendations. We designed a single agent and
a MAS framework simulating MDT decision-making by enabling discussion among LLM
agents to resolve medical conflicts. The systems were evaluated on therapy
planning tasks for multimorbidity patients using benchmark cases. We compared
MAS performance with single-agent approaches and real-world benchmarks. An
important contribution of our study is the definition of evaluation metrics
that go beyond the technical precision and recall and allow the inspection of
clinical goals met and medication burden of the proposed advices to a gold
standard benchmark. Our results show that with current LLMs, a single agent GP
performs as well as MDTs. The best-scoring models provide correct
recommendations that address all clinical goals, yet the advices are
incomplete. Some models also present unnecessary medications, resulting in
unnecessary conflicts between medication and conditions or drug-drug
interactions.

</details>


### [89] [Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization](https://arxiv.org/abs/2507.10923)
*Yuhao Wang,Keyan Ding,Kehua Feng,Zeyuan Wang,Ming Qin,Xiaotong Li,Qiang Zhang,Huajun Chen*

Main category: cs.AI

TL;DR: 提出了一种知识引导的偏好优化（KPO）框架，通过蛋白质安全知识图谱整合先验知识，以减少生成有害蛋白质序列的风险。


<details>
  <summary>Details</summary>
Motivation: 蛋白质语言模型在功能优化和设计方面具有优势，但可能生成有害序列，带来生物安全和伦理挑战。

Method: 结合蛋白质安全知识图谱，采用图剪枝策略和强化学习，优化序列生成。

Result: KPO有效降低有害序列生成概率，同时保持高功能性。

Conclusion: KPO为生物技术中的生成模型提供了安全保证框架。

Abstract: Protein language models have emerged as powerful tools for sequence
generation, offering substantial advantages in functional optimization and
denovo design. However, these models also present significant risks of
generating harmful protein sequences, such as those that enhance viral
transmissibility or evade immune responses. These concerns underscore critical
biosafety and ethical challenges. To address these issues, we propose a
Knowledge-guided Preference Optimization (KPO) framework that integrates prior
knowledge via a Protein Safety Knowledge Graph. This framework utilizes an
efficient graph pruning strategy to identify preferred sequences and employs
reinforcement learning to minimize the risk of generating harmful proteins.
Experimental results demonstrate that KPO effectively reduces the likelihood of
producing hazardous sequences while maintaining high functionality, offering a
robust safety assurance framework for applying generative models in
biotechnology.

</details>


### [90] [Modeling Habitat Shifts: Integrating Convolutional Neural Networks and Tabular Data for Species Migration Prediction](https://arxiv.org/abs/2507.10993)
*Emir Durakovic,Min-Hong Shih*

Main category: cs.AI

TL;DR: 结合卷积神经网络和表格数据，准确预测鸟类在特定栖息地的存在，平均准确率达85%。


<details>
  <summary>Details</summary>
Motivation: 由于气候变化导致栖息地范围变化，需要一种可靠的方法来预测鸟类分布。

Method: 利用卫星图像和环境特征（如温度、降水、海拔），通过CNN捕捉空间特征，表格方法处理生态和地理数据。

Result: 模型预测鸟类分布的准确率为85%。

Conclusion: 该方法为理解鸟类迁徙提供了可扩展且可靠的解决方案。

Abstract: Due to climate-induced changes, many habitats are experiencing range shifts
away from their traditional geographic locations (Piguet, 2011). We propose a
solution to accurately model whether bird species are present in a specific
habitat through the combination of Convolutional Neural Networks (CNNs)
(O'Shea, 2015) and tabular data. Our approach makes use of satellite imagery
and environmental features (e.g., temperature, precipitation, elevation) to
predict bird presence across various climates. The CNN model captures spatial
characteristics of landscapes such as forestation, water bodies, and
urbanization, whereas the tabular method uses ecological and geographic data.
Both systems predict the distribution of birds with an average accuracy of 85%,
offering a scalable but reliable method to understand bird migration.

</details>


### [91] [Personalized Exercise Recommendation with Semantically-Grounded Knowledge Tracing](https://arxiv.org/abs/2507.11060)
*Yilmazcan Ozyurt,Tunaberk Almaci,Stefan Feuerriegel,Mrinmaya Sachan*

Main category: cs.AI

TL;DR: ExRec是一个基于语义知识追踪的个性化练习推荐框架，通过改进强化学习方法优化学生知识提升。


<details>
  <summary>Details</summary>
Motivation: 现有练习推荐方法忽视问题的语义内容和学生学习的结构化进展。

Method: 结合知识追踪模型和强化学习，采用模型化价值估计方法优化推荐。

Result: 在多个实际任务中验证有效性，并能泛化到新问题，生成可解释的学习轨迹。

Conclusion: 知识追踪引导的强化学习在教育个性化中具有潜力。

Abstract: We introduce ExRec, a general framework for personalized exercise
recommendation with semantically-grounded knowledge tracing. Our method builds
on the observation that existing exercise recommendation approaches simulate
student performance via knowledge tracing (KT) but they often overlook two key
aspects: (a) the semantic content of questions and (b) the sequential,
structured progression of student learning. To address this, our ExRec presents
an end-to-end pipeline, from annotating the KCs of questions and learning their
semantic representations to training KT models and optimizing several
reinforcement learning (RL) methods. Moreover, we improve standard
Q-learning-based continuous RL methods via a tailored model-based value
estimation (MVE) approach that directly leverages the components of KT model in
estimating cumulative knowledge improvement. We validate the effectiveness of
our ExRec using various RL methods across four real-world tasks with different
educational goals in online math learning. We further show that ExRec
generalizes robustly to new, unseen questions and that it produces
interpretable student learning trajectories. Together, our findings highlight
the promise of KT-guided RL for effective personalization in education.

</details>


### [92] [Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander](https://arxiv.org/abs/2507.11079)
*Li Wang,Qizhen Wu,Lei Chen*

Main category: cs.AI

TL;DR: 提出了一种基于视觉语言模型的指挥官系统，用于解决无人地面车辆对抗中的智能感知到决策推理问题，结合视觉语言模型和轻量级大语言模型，实现了高适应性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统手工规则方法在复杂战场环境中脆弱，而现有强化学习方法缺乏可解释性且主要关注动作而非战略决策。

Method: 整合视觉语言模型进行场景理解和轻量级大语言模型进行战略推理，在共享语义空间中实现统一感知与决策。

Result: 仿真和消融实验显示，该方法相比基线模型胜率超过80%。

Conclusion: 该方法通过模拟人类指挥官的认知过程，实现了全链条的感知到决策推理，具有高适应性和可解释性。

Abstract: In multiple unmanned ground vehicle confrontations, autonomously evolving
multi-agent tactical decisions from situational awareness remain a significant
challenge. Traditional handcraft rule-based methods become vulnerable in the
complicated and transient battlefield environment, and current reinforcement
learning methods mainly focus on action manipulation instead of strategic
decisions due to lack of interpretability. Here, we propose a vision-language
model-based commander to address the issue of intelligent
perception-to-decision reasoning in autonomous confrontations. Our method
integrates a vision language model for scene understanding and a lightweight
large language model for strategic reasoning, achieving unified perception and
decision within a shared semantic space, with strong adaptability and
interpretability. Unlike rule-based search and reinforcement learning methods,
the combination of the two modules establishes a full-chain process, reflecting
the cognitive process of human commanders. Simulation and ablation experiments
validate that the proposed approach achieves a win rate of over 80% compared
with baseline models.

</details>


### [93] [Function-to-Style Guidance of LLMs for Code Translation](https://arxiv.org/abs/2507.11083)
*Longhui Zhang,Bin Wang,Jiahao Wang,Xiaofeng Zhao,Min Zhang,Hao Yang,Meishan Zhang,Yu Li,Jing Li,Jun Yu,Min Zhang*

Main category: cs.AI

TL;DR: F2STrans提出了一种分阶段的代码翻译方法，通过功能学习和风格学习提升LLMs的翻译性能，并在新基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在代码翻译任务中取得进展，但确保翻译的正确性和可读性仍是挑战，限制了其在实际开发中的应用。

Method: F2STrans包含两个阶段：功能学习（优化翻译正确性）和风格学习（提升可读性），并引入新的代码翻译基准。

Result: 实验表明，F2STrans显著提升性能，使Qwen-1.5B在20种场景中平均表现优于Qwen-32B和GPT-4。

Conclusion: F2STrans通过分阶段学习有效解决了代码翻译的正确性和可读性问题，为实际应用提供了可行方案。

Abstract: Large language models (LLMs) have made significant strides in code
translation tasks. However, ensuring both the correctness and readability of
translated code remains a challenge, limiting their effective adoption in
real-world software development. In this work, we propose F2STrans, a
function-to-style guiding paradigm designed to progressively improve the
performance of LLMs in code translation. Our approach comprises two key stages:
(1) Functional learning, which optimizes translation correctness using
high-quality source-target code pairs mined from online programming platforms,
and (2) Style learning, which improves translation readability by incorporating
both positive and negative style examples. Additionally, we introduce a novel
code translation benchmark that includes up-to-date source code, extensive test
cases, and manually annotated ground-truth translations, enabling comprehensive
functional and stylistic evaluations. Experiments on both our new benchmark and
existing datasets demonstrate that our approach significantly improves code
translation performance. Notably, our approach enables Qwen-1.5B to outperform
prompt-enhanced Qwen-32B and GPT-4 on average across 20 diverse code
translation scenarios.

</details>


### [94] [AI Agent Architecture for Decentralized Trading of Alternative Assets](https://arxiv.org/abs/2507.11117)
*Ailiya Borjigin,Cong He,Charles CC Lee,Wei Zhou*

Main category: cs.AI

TL;DR: GoldMine OS是一个研究导向的架构，利用多个专用AI代理实现物理黄金与区块链稳定币（OZ）的自动化、安全代币化和交易，满足合规性、流动性和风险管理要求。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界替代资产（如黄金）在去中心化交易中如何将物理资产托管与区块链系统结合，并满足严格合规、流动性和风险管理需求的问题。

Method: 结合链上智能合约（关键风险控制）与链下AI代理（决策），设计四个协作代理（合规、代币发行、做市、风险控制）和一个协调核心。

Result: 原型实现按需代币发行（<1.2秒），做市代理保持高流动性（价差<0.5%），故障注入测试显示系统具备韧性（攻击检测与缓解时间<10秒）。

Conclusion: 基于AI代理的去中心化交易所可满足高性能与安全性需求，为传统非流动性资产提供民主化访问途径，并通过治理模型确保透明性与适应性。

Abstract: Decentralized trading of real-world alternative assets (e.g., gold) requires
bridging physical asset custody with blockchain systems while meeting strict
requirements for compliance, liquidity, and risk management. We present
GoldMine OS, a research oriented architecture that employs multiple specialized
AI agents to automate and secure the tokenization and exchange of physical gold
into a blockchain based stablecoin ("OZ"). Our approach combines on chain smart
contracts for critical risk controls with off chain AI agents for decision
making, blending the transparency and reliability of blockchains with the
flexibility of AI driven automation. We describe four cooperative agents
(Compliance, Token Issuance, Market Making, and Risk Control) and a
coordinating core, and evaluate the system through simulation and a controlled
pilot deployment. In experiments the prototype delivers on demand token
issuance in under 1.2 s, more than 100 times faster than manual workflows. The
Market Making agent maintains tight liquidity with spreads often below 0.5
percent even under volatile conditions. Fault injection tests show resilience:
an oracle price spoofing attack is detected and mitigated within 10 s, and a
simulated vault mis reporting halts issuance immediately with minimal user
impact. The architecture scales to 5000 transactions per second with 10000
concurrent users in benchmarks. These results indicate that an AI agent based
decentralized exchange for alternative assets can satisfy rigorous performance
and safety requirements. We discuss broader implications for democratizing
access to traditionally illiquid assets and explain how our governance model --
multi signature agent updates and on chain community voting on risk parameters
-- provides ongoing transparency, adaptability, and formal assurance of system
integrity.

</details>


### [95] [Defining neurosymbolic AI](https://arxiv.org/abs/2507.11127)
*Lennert De Smet,Luc De Raedt*

Main category: cs.AI

TL;DR: 本文提出了神经符号AI的正式定义，通过抽象其关键成分，将神经符号推理定义为逻辑函数和信念函数乘积的积分计算。


<details>
  <summary>Details</summary>
Motivation: 尽管神经符号AI领域已有多种系统，但缺乏普遍接受的正式定义，本文旨在填补这一空白。

Method: 引入一种形式化定义，抽象神经符号AI的关键成分，具体定义为逻辑函数和信念函数乘积的积分。

Result: 该定义能够抽象代表性神经符号AI系统的关键特征。

Conclusion: 提出的形式化定义为神经符号AI领域提供了统一的框架。

Abstract: Neurosymbolic AI focuses on integrating learning and reasoning, in
particular, on unifying logical and neural representations. Despite the
existence of an alphabet soup of neurosymbolic AI systems, the field is lacking
a generally accepted formal definition of what neurosymbolic models and
inference really are. We introduce a formal definition for neurosymbolic AI
that makes abstraction of its key ingredients. More specifically, we define
neurosymbolic inference as the computation of an integral over a product of a
logical and a belief function. We show that our neurosymbolic AI definition
makes abstraction of key representative neurosymbolic AI systems.

</details>


### [96] [Collaborative Trustworthiness for Good Decision Making in Autonomous Systems](https://arxiv.org/abs/2507.11135)
*Selma Saidi,Omar Laimona,Christoph Schmickler,Dirk Ziegenbein*

Main category: cs.AI

TL;DR: 提出了一种基于协作的自主系统可信决策方法，利用感知质量等属性确定可信系统，并采用BDD进行信念聚合与传播。


<details>
  <summary>Details</summary>
Motivation: 解决自主系统在动态复杂环境中安全可靠决策的挑战。

Method: 利用感知质量等属性筛选可信系统，结合社会认识论定义聚合与传播规则，使用BDD进行高效计算。

Result: 通过BDD模型实现高效协作自动推理，提升决策可信度。

Conclusion: 该方法为自主系统在复杂环境中的可信决策提供了新思路。

Abstract: Autonomous systems are becoming an integral part of many application domains,
like in the mobility sector. However, ensuring their safe and correct behaviour
in dynamic and complex environments remains a significant challenge, where
systems should autonomously make decisions e.g., about manoeuvring. We propose
in this paper a general collaborative approach for increasing the level of
trustworthiness in the environment of operation and improve reliability and
good decision making in autonomous system. In the presence of conflicting
information, aggregation becomes a major issue for trustworthy decision making
based on collaborative data sharing. Unlike classical approaches in the
literature that rely on consensus or majority as aggregation rule, we exploit
the fact that autonomous systems have different quality attributes like
perception quality. We use this criteria to determine which autonomous systems
are trustworthy and borrow concepts from social epistemology to define
aggregation and propagation rules, used for automated decision making. We use
Binary Decision Diagrams (BDDs) as formal models for beliefs aggregation and
propagation, and formulate reduction rules to reduce the size of the BDDs and
allow efficient computation structures for collaborative automated reasoning.

</details>


### [97] [Fine-grained Timing Analysis of Digital Integrated Circuits in Answer Set Programming](https://arxiv.org/abs/2507.11150)
*Alessandro Bertagnon,Marcello Dalpasso,Michele Favalli,Marco Gavanelli*

Main category: cs.AI

TL;DR: 论文提出了一种使用答案集编程（ASP）精确计算组合电路最大延迟的方法，以替代传统的静态时序分析，从而提高处理器性能。


<details>
  <summary>Details</summary>
Motivation: 传统静态时序分析只能提供最大延迟的上界，可能导致处理器性能未被充分利用。

Method: 将问题建模为答案集编程（ASP），并提出非平凡的编码方法。

Result: 实验证明ASP能有效解决硬件设计中的复杂问题。

Conclusion: ASP是解决硬件设计中复杂问题的可行方案。

Abstract: In the design of integrated circuits, one critical metric is the maximum
delay introduced by combinational modules within the circuit. This delay is
crucial because it represents the time required to perform a computation: in an
Arithmetic-Logic Unit it represents the maximum time taken by the circuit to
perform an arithmetic operation. When such a circuit is part of a larger,
synchronous system, like a CPU, the maximum delay directly impacts the maximum
clock frequency of the entire system. Typically, hardware designers use Static
Timing Analysis to compute an upper bound of the maximum delay because it can
be determined in polynomial time. However, relying on this upper bound can lead
to suboptimal processor speeds, thereby missing performance opportunities. In
this work, we tackle the challenging task of computing the actual maximum
delay, rather than an approximate value. Since the problem is computationally
hard, we model it in Answer Set Programming (ASP), a logic language featuring
extremely efficient solvers. We propose non-trivial encodings of the problem
into ASP. Experimental results show that ASP is a viable solution to address
complex problems in hardware design.

</details>


### [98] [DuetGraph: Coarse-to-Fine Knowledge Graph Reasoning with Dual-Pathway Global-Local Fusion](https://arxiv.org/abs/2507.11229)
*Jin Li,Zezhong Ding,Xike Xie*

Main category: cs.AI

TL;DR: DuetGraph提出了一种双路径全局-局部融合的粗到细知识图谱推理机制，通过分离全局和局部信息处理路径解决分数过平滑问题，显著提升推理质量和训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱推理方法因全局和局部信息堆叠处理导致分数过平滑，模糊正确与错误答案的区分，影响推理效果。

Method: DuetGraph采用双路径机制分离全局（注意力）和局部（消息传递）信息处理，并引入粗到细优化策略，将实体分为高低分集合以缩小候选空间。

Result: 实验表明，DuetGraph在推理质量上提升8.7%，训练效率加速1.8倍，达到SOTA性能。

Conclusion: DuetGraph通过双路径融合和粗到细优化有效解决过平滑问题，显著提升知识图谱推理效果。

Abstract: Knowledge graphs (KGs) are vital for enabling knowledge reasoning across
various domains. Recent KG reasoning methods that integrate both global and
local information have achieved promising results. However, existing methods
often suffer from score over-smoothing, which blurs the distinction between
correct and incorrect answers and hinders reasoning effectiveness. To address
this, we propose DuetGraph, a coarse-to-fine KG reasoning mechanism with
dual-pathway global-local fusion. DuetGraph tackles over-smoothing by
segregating -- rather than stacking -- the processing of local (via message
passing) and global (via attention) information into two distinct pathways,
preventing mutual interference and preserving representational discrimination.
In addition, DuetGraph introduces a coarse-to-fine optimization, which
partitions entities into high- and low-score subsets. This strategy narrows the
candidate space and sharpens the score gap between the two subsets, which
alleviates over-smoothing and enhances inference quality. Extensive experiments
on various datasets demonstrate that DuetGraph achieves state-of-the-art (SOTA)
performance, with up to an 8.7% improvement in reasoning quality and a
1.8$\times$ acceleration in training efficiency.

</details>


### [99] [Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems](https://arxiv.org/abs/2507.11277)
*Dany Moshkovich,Sergey Zeltyn*

Main category: cs.AI

TL;DR: AgentOps框架为基于LLM的智能代理系统提供了一套全面的运维解决方案，涵盖观察、分析、优化和自动化操作，以应对其独特的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着LLM驱动的智能代理系统在复杂任务中的应用增加，传统运维方法无法有效处理其不确定性，因此需要新的解决方案。

Method: 提出了AgentOps框架，包括行为观察、指标收集、问题检测、根因分析、优化建议和运行时自动化六个阶段的自动化流程。

Result: 该框架为开发者、测试者、SRE和业务用户提供了针对不同生命周期的需求支持，并通过自动化管理不确定性。

Conclusion: AgentOps通过自动化而非消除不确定性，实现了智能代理系统的安全、自适应和高效运行。

Abstract: Large Language Models (LLMs) are increasingly deployed within agentic
systems-collections of interacting, LLM-powered agents that execute complex,
adaptive workflows using memory, tools, and dynamic planning. While enabling
powerful new capabilities, these systems also introduce unique forms of
uncertainty stemming from probabilistic reasoning, evolving memory states, and
fluid execution paths. Traditional software observability and operations
practices fall short in addressing these challenges.
  This paper introduces AgentOps: a comprehensive framework for observing,
analyzing, optimizing, and automating operation of agentic AI systems. We
identify distinct needs across four key roles-developers, testers, site
reliability engineers (SREs), and business users-each of whom engages with the
system at different points in its lifecycle. We present the AgentOps Automation
Pipeline, a six-stage process encompassing behavior observation, metric
collection, issue detection, root cause analysis, optimized recommendations,
and runtime automation. Throughout, we emphasize the critical role of
automation in managing uncertainty and enabling self-improving AI systems-not
by eliminating uncertainty, but by taming it to ensure safe, adaptive, and
effective operation.

</details>


### [100] [Opus: A Prompt Intention Framework for Complex Workflow Generation](https://arxiv.org/abs/2507.11288)
*Théo Fagnoni,Mahsun Altin,Chia En Chung,Phillip Kingston,Alan Tuning,Dana O. Mohamed,Inès Adnani*

Main category: cs.AI

TL;DR: Opus Prompt Intention Framework通过引入中间层（Intention Capture）提升LLM在复杂工作流生成中的表现，显著改善语义相似性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM直接生成工作流时在复杂查询中的逻辑性和扩展性问题。

Method: 提出Opus框架，包括从用户查询中提取Workflow Signals、解析为结构化Workflow Intentions，并基于此生成工作流。

Result: 在1000对多意图查询-工作流对的基准测试中，语义相似性指标显著提升。

Conclusion: Opus框架通过意图捕获层有效提升工作流生成质量，尤其在混合意图场景中表现突出。

Abstract: This paper introduces the Opus Prompt Intention Framework, designed to
improve complex Workflow Generation with instruction-tuned Large Language
Models (LLMs). We propose an intermediate Intention Capture layer between user
queries and Workflow Generation, implementing the Opus Workflow Intention
Framework, which consists of extracting Workflow Signals from user queries,
interpreting them into structured Workflow Intention objects, and generating
Workflows based on these Intentions. Our results show that this layer enables
LLMs to produce logical and meaningful outputs that scale reliably as query
complexity increases. On a synthetic benchmark of 1,000 multi-intent
query-Workflow(s) pairs, applying the Opus Prompt Intention Framework to
Workflow Generation yields consistent improvements in semantic Workflow
similarity metrics. In this paper, we introduce the Opus Prompt Intention
Framework by applying the concepts of Workflow Signal and Workflow Intention to
LLM-driven Workflow Generation. We present a reproducible, customizable
LLM-based Intention Capture system to extract Workflow Signals and Workflow
Intentions from user queries. Finally, we provide empirical evidence that the
proposed system significantly improves Workflow Generation quality compared to
direct generation from user queries, particularly in cases of Mixed Intention
Elicitation.

</details>


### [101] [Contestability in Quantitative Argumentation](https://arxiv.org/abs/2507.11323)
*Xiang Yin,Nico Potyka,Antonio Rago,Timotheus Kampik,Francesca Toni*

Main category: cs.AI

TL;DR: 论文探讨了如何通过Edge-Weighted Quantitative Bipolar Argumentation Frameworks (EW-QBAFs)实现AI决策的可争议性，提出了一种梯度关系归因解释方法(G-RAEs)和迭代算法来调整权重以达到目标强度。


<details>
  <summary>Details</summary>
Motivation: 确保AI驱动的决策符合人类偏好，但目前EW-QBAFs在支持可争议性方面的研究较少。

Method: 提出G-RAEs方法量化主题论据强度对边权重的敏感性，并开发迭代算法调整权重。

Result: 实验表明，该方法在模拟推荐系统和多层感知器的合成EW-QBAFs上有效解决问题。

Conclusion: EW-QBAFs结合G-RAEs和迭代算法能有效实现AI决策的可争议性。

Abstract: Contestable AI requires that AI-driven decisions align with human
preferences. While various forms of argumentation have been shown to support
contestability, Edge-Weighted Quantitative Bipolar Argumentation Frameworks
(EW-QBAFs) have received little attention. In this work, we show how EW-QBAFs
can be deployed for this purpose. Specifically, we introduce the contestability
problem for EW-QBAFs, which asks how to modify edge weights (e.g., preferences)
to achieve a desired strength for a specific argument of interest (i.e., a
topic argument). To address this problem, we propose gradient-based relation
attribution explanations (G-RAEs), which quantify the sensitivity of the topic
argument's strength to changes in individual edge weights, thus providing
interpretable guidance for weight adjustments towards contestability. Building
on G-RAEs, we develop an iterative algorithm that progressively adjusts the
edge weights to attain the desired strength. We evaluate our approach
experimentally on synthetic EW-QBAFs that simulate the structural
characteristics of personalised recommender systems and multi-layer
perceptrons, and demonstrate that it can solve the problem effectively.

</details>


### [102] [CogDDN: A Cognitive Demand-Driven Navigation with Decision Optimization and Dual-Process Thinking](https://arxiv.org/abs/2507.11334)
*Yuehao Huang,Liang Liu,Shuangming Lei,Yukai Ma,Hao Su,Jianbiao Mei,Pengxiang Zhao,Yaqing Gu,Yong Liu,Jiajun Lv*

Main category: cs.AI

TL;DR: CogDDN是一种基于VLM的框架，通过模拟人类认知和学习机制，结合快速和慢速思维系统，提升机器人在未知环境中的导航和交互能力。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动的需求导航方法依赖预收集数据，泛化能力有限，无法适应未知场景。

Method: CogDDN结合快速启发式决策和慢速分析决策，通过语义对齐目标对象和指令，并利用知识库积累错误经验。

Result: 在AI2Thor模拟器上的实验显示，CogDDN比单视角相机方法性能提升15%。

Conclusion: CogDDN显著提高了导航准确性和适应性，适用于未知和非结构化环境。

Abstract: Mobile robots are increasingly required to navigate and interact within
unknown and unstructured environments to meet human demands. Demand-driven
navigation (DDN) enables robots to identify and locate objects based on
implicit human intent, even when object locations are unknown. However,
traditional data-driven DDN methods rely on pre-collected data for model
training and decision-making, limiting their generalization capability in
unseen scenarios. In this paper, we propose CogDDN, a VLM-based framework that
emulates the human cognitive and learning mechanisms by integrating fast and
slow thinking systems and selectively identifying key objects essential to
fulfilling user demands. CogDDN identifies appropriate target objects by
semantically aligning detected objects with the given instructions.
Furthermore, it incorporates a dual-process decision-making module, comprising
a Heuristic Process for rapid, efficient decisions and an Analytic Process that
analyzes past errors, accumulates them in a knowledge base, and continuously
improves performance. Chain of Thought (CoT) reasoning strengthens the
decision-making process. Extensive closed-loop evaluations on the AI2Thor
simulator with the ProcThor dataset show that CogDDN outperforms single-view
camera-only methods by 15%, demonstrating significant improvements in
navigation accuracy and adaptability. The project page is available at
https://yuehaohuang.github.io/CogDDN/.

</details>


### [103] [Foundation Models for Logistics: Toward Certifiable, Conversational Planning Interfaces](https://arxiv.org/abs/2507.11352)
*Yunhao Yang,Neel P. Bhatt,Christian Ellis,Alvaro Velasquez,Zhangyang Wang,Ufuk Topcu*

Main category: cs.AI

TL;DR: 提出了一种结合自然语言对话与可验证保证的神经符号框架，用于物流决策，提升实时性和安全性。


<details>
  <summary>Details</summary>
Motivation: 物流决策需要快速且持续的重新规划，现有方法（如整数规划）速度慢且忽略不确定性，而大语言模型（LLMs）易产生误解和幻觉。

Method: 引入神经符号框架，将用户请求转换为结构化规划规范，量化不确定性，并在置信度不足时触发交互式澄清循环。

Result: 轻量级模型在100个不确定性过滤示例上微调，超越GPT-4.1的零样本性能，推理延迟降低近50%。

Conclusion: 该框架为复杂物流提供了一条可验证、实时且用户对齐的决策路径。

Abstract: Logistics operators, from battlefield coordinators rerouting airlifts ahead
of a storm to warehouse managers juggling late trucks, often face life-critical
decisions that demand both domain expertise and rapid and continuous
replanning. While popular methods like integer programming yield logistics
plans that satisfy user-defined logical constraints, they are slow and assume
an idealized mathematical model of the environment that does not account for
uncertainty. On the other hand, large language models (LLMs) can handle
uncertainty and promise to accelerate replanning while lowering the barrier to
entry by translating free-form utterances into executable plans, yet they
remain prone to misinterpretations and hallucinations that jeopardize safety
and cost. We introduce a neurosymbolic framework that pairs the accessibility
of natural-language dialogue with verifiable guarantees on goal interpretation.
It converts user requests into structured planning specifications, quantifies
its own uncertainty at the field and token level, and invokes an interactive
clarification loop whenever confidence falls below an adaptive threshold. A
lightweight model, fine-tuned on just 100 uncertainty-filtered examples,
surpasses the zero-shot performance of GPT-4.1 while cutting inference latency
by nearly 50%. These preliminary results highlight a practical path toward
certifiable, real-time, and user-aligned decision-making for complex logistics.

</details>


### [104] [Modeling Code: Is Text All You Need?](https://arxiv.org/abs/2507.11467)
*Daniel Nichols,Konstantinos Parasyris,Harshitha Menon,Brian R. Bartoldson,Giorgis Georgakoudis,Tal Ben-Nun,Abhinav Bhatele*

Main category: cs.AI

TL;DR: 结合代码文本与结构化形式的新方法，弥补了现有LLMs在代码结构化分析上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有代码LLMs在结构化分析（如控制流和数据流）方面能力有限，而传统结构化方法缺乏生成能力和规模。

Method: 提出一种新方法，结合代码文本建模与结构化形式建模的优势。

Result: 未明确提及具体实验结果。

Conclusion: 新方法有望提升代码LLMs在结构化分析任务中的表现。

Abstract: Code LLMs have become extremely popular recently for modeling source code
across a variety of tasks, such as generation, translation, and summarization.
However, transformer-based models are limited in their capabilities to reason
through structured, analytical properties of code, such as control and data
flow. Previous work has explored the modeling of these properties with
structured data and graph neural networks. However, these approaches lack the
generative capabilities and scale of modern LLMs. In this work, we introduce a
novel approach to combine the strengths of modeling both code as text and more
structured forms.

</details>


### [105] [Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety](https://arxiv.org/abs/2507.11473)
*Tomek Korbak,Mikita Balesni,Elizabeth Barnes,Yoshua Bengio,Joe Benton,Joseph Bloom,Mark Chen,Alan Cooney,Allan Dafoe,Anca Dragan,Scott Emmons,Owain Evans,David Farhi,Ryan Greenblatt,Dan Hendrycks,Marius Hobbhahn,Evan Hubinger,Geoffrey Irving,Erik Jenner,Daniel Kokotajlo,Victoria Krakovna,Shane Legg,David Lindner,David Luan,Aleksander Mądry,Julian Michael,Neel Nanda,Dave Orr,Jakub Pachocki,Ethan Perez,Mary Phuong,Fabien Roger,Joshua Saxe,Buck Shlegeris,Martín Soto,Eric Steinberger,Jasmine Wang,Wojciech Zaremba,Bowen Baker,Rohin Shah,Vlad Mikulik*

Main category: cs.AI

TL;DR: AI系统通过人类语言“思考”为AI安全提供了独特机会，可通过监控思维链（CoT）检测不良意图。尽管不完美，但CoT监控有潜力，建议进一步研究和投资。


<details>
  <summary>Details</summary>
Motivation: 探索AI系统通过语言“思考”的特性，为AI安全提供新的监控方法。

Method: 提出监控思维链（CoT）的方法，以检测AI的不良意图。

Result: CoT监控虽不完美，但显示出潜力，建议进一步研究和投资。

Conclusion: 建议前沿模型开发者考虑开发决策对CoT可监控性的影响。

Abstract: AI systems that "think" in human language offer a unique opportunity for AI
safety: we can monitor their chains of thought (CoT) for the intent to
misbehave. Like all other known AI oversight methods, CoT monitoring is
imperfect and allows some misbehavior to go unnoticed. Nevertheless, it shows
promise and we recommend further research into CoT monitorability and
investment in CoT monitoring alongside existing safety methods. Because CoT
monitorability may be fragile, we recommend that frontier model developers
consider the impact of development decisions on CoT monitorability.

</details>


### [106] [Perspective-Aware AI in Extended Reality](https://arxiv.org/abs/2507.11479)
*Daniel Platnick,Matti Gruener,Marjan Alirezaie,Kent Larson,Dava J. Newman,Hossein Rahnama*

Main category: cs.AI

TL;DR: PAiR框架通过整合Perspective-Aware AI与XR，利用多模态数字足迹构建用户身份模型，实现自适应沉浸式体验。


<details>
  <summary>Details</summary>
Motivation: 当前XR系统因用户建模浅显和认知上下文有限，无法提供真正自适应的沉浸体验。

Method: 提出PAiR框架，基于Chronicles（多模态数字足迹构建的身份模型）和闭环系统，动态链接用户状态与沉浸环境。

Result: 通过Unity引擎实现的两个概念验证场景展示了PAiR的实用性。

Conclusion: PAiR为人类-AI交互开辟了新方向，将基于视角的身份模型嵌入沉浸式系统。

Abstract: AI-enhanced Extended Reality (XR) aims to deliver adaptive, immersive
experiences-yet current systems fall short due to shallow user modeling and
limited cognitive context. We introduce Perspective-Aware AI in Extended
Reality (PAiR), a foundational framework for integrating Perspective-Aware AI
(PAi) with XR to enable interpretable, context-aware experiences grounded in
user identity. PAi is built on Chronicles: reasoning-ready identity models
learned from multimodal digital footprints that capture users' cognitive and
experiential evolution. PAiR employs these models in a closed-loop system
linking dynamic user states with immersive environments. We present PAiR's
architecture, detailing its modules and system flow, and demonstrate its
utility through two proof-of-concept scenarios implemented in the Unity-based
OpenDome engine. PAiR opens a new direction for human-AI interaction by
embedding perspective-based identity models into immersive systems.

</details>


### [107] [Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light](https://arxiv.org/abs/2507.11482)
*Mani Hamidi,Terrence W. Deacon*

Main category: cs.AI

TL;DR: 论文提出一个受开放进化论启发的框架，重新审视强化学习的三个核心假设，并探讨其理论和应用意义。


<details>
  <summary>Details</summary>
Motivation: 针对强化学习中关于代理定义、学习目标和奖励假设的三个核心假设进行概念性修订，以推动理论和应用的发展。

Method: 结合开放进化论的视角，重新审视并讨论这三个假设，同时探讨进化动力学在个体生命周期内的作用。

Result: 通过进化论的类比，丰富了学习的目标和奖励假设的理解，但指出进化范式无法单独解决代理问题。

Conclusion: 建议整合生命起源理论中的热力学观点，为理解生物系统中的代理和资源受限强化学习提供基础。

Abstract: Three core tenets of reinforcement learning (RL)--concerning the definition
of agency, the objective of learning, and the scope of the reward
hypothesis--have been highlighted as key targets for conceptual revision, with
major implications for theory and application. We propose a framework, inspired
by open-ended evolutionary theory, to reconsider these three "dogmas." We
revisit each assumption and address related concerns raised alongside them. To
make our arguments relevant to RL as a model of biological learning, we first
establish that evolutionary dynamics can plausibly operate within living brains
over an individual's lifetime, and are not confined to cross-generational
processes. We begin by revisiting the second dogma, drawing on evolutionary
insights to enrich the "adaptation-rather-than-search" view of learning. We
then address the third dogma regarding the limits of the reward hypothesis,
using analogies from evolutionary fitness to illuminate the scalar reward vs.
multi-objective debate. After discussing practical implications for exploration
in RL, we turn to the first--and arguably most fundamental--issue: the absence
of a formal account of agency. We argue that unlike the other two problems, the
evolutionary paradigm alone cannot resolve the agency question, though it
gestures in a productive direction. We advocate integrating ideas from
origins-of-life theory, where the thermodynamics of sustenance and replication
offer promising foundations for understanding agency and resource-constrained
reinforcement learning in biological systems.

</details>


### [108] [DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering](https://arxiv.org/abs/2507.11527)
*Yinsheng Li,Zhen Dong,Yi Shao*

Main category: cs.AI

TL;DR: DrafterBench是一个用于评估LLM代理在土木工程图纸修订任务中的综合基准，包含12类任务、46个定制功能和1920个任务，旨在测试代理的多方面能力。


<details>
  <summary>Details</summary>
Motivation: 工业领域需要更多系统化的基准来评估自动化代理，尤其是在土木工程等具体领域。

Method: 提出DrafterBench，包含真实图纸文件总结的任务类型、定制功能和大量任务，测试代理的多项能力。

Result: DrafterBench能全面评估代理的结构化数据理解、功能执行、指令遵循和关键推理能力，并提供详细的任务准确性和错误统计。

Conclusion: DrafterBench为LLM在工程应用中的集成提供了深入见解和改进目标，是一个开源基准。

Abstract: Large Language Model (LLM) agents have shown great potential for solving
real-world problems and promise to be a solution for tasks automation in
industry. However, more benchmarks are needed to systematically evaluate
automation agents from an industrial perspective, for example, in Civil
Engineering. Therefore, we propose DrafterBench for the comprehensive
evaluation of LLM agents in the context of technical drawing revision, a
representation task in civil engineering. DrafterBench contains twelve types of
tasks summarized from real-world drawing files, with 46 customized
functions/tools and 1920 tasks in total. DrafterBench is an open-source
benchmark to rigorously test AI agents' proficiency in interpreting intricate
and long-context instructions, leveraging prior knowledge, and adapting to
dynamic instruction quality via implicit policy awareness. The toolkit
comprehensively assesses distinct capabilities in structured data
comprehension, function execution, instruction following, and critical
reasoning. DrafterBench offers detailed analysis of task accuracy and error
statistics, aiming to provide deeper insight into agent capabilities and
identify improvement targets for integrating LLMs in engineering applications.
Our benchmark is available at https://github.com/Eason-Li-AIS/DrafterBench,
with the test set hosted at
https://huggingface.co/datasets/Eason666/DrafterBench.

</details>


### [109] [How Many Instructions Can LLMs Follow at Once?](https://arxiv.org/abs/2507.11538)
*Daniel Jaroslawicz,Brendan Whiting,Parth Shah,Karime Maamari*

Main category: cs.AI

TL;DR: IFScale是一个新基准，用于评估LLM在高密度指令下的性能，发现即使前沿模型在500条指令时准确率仅为68%。


<details>
  <summary>Details</summary>
Motivation: 现有基准仅评估少量指令任务，无法反映生产级LLM系统需同时处理大量指令的需求。

Method: 引入IFScale基准，包含500条关键词包含指令，评估20个前沿模型在高指令密度下的表现。

Result: 最佳模型在500条指令时准确率为68%，模型规模和推理能力与性能下降模式相关。

Conclusion: IFScale揭示了高密度指令下的性能瓶颈，为实际应用中的提示设计提供参考，并开源了基准和结果。

Abstract: Production-grade LLM systems require robust adherence to dozens or even
hundreds of instructions simultaneously. However, the instruction-following
capabilities of LLMs at high instruction densities have not yet been
characterized, as existing benchmarks only evaluate models on tasks with a
single or few instructions. We introduce IFScale, a simple benchmark of 500
keyword-inclusion instructions for a business report writing task to measure
how instruction-following performance degrades as instruction density
increases. We evaluate 20 state-of-the-art models across seven major providers
and find that even the best frontier models only achieve 68% accuracy at the
max density of 500 instructions. Our analysis reveals model size and reasoning
capability to correlate with 3 distinct performance degradation patterns, bias
towards earlier instructions, and distinct categories of instruction-following
errors. Our insights can help inform design of instruction-dense prompts in
real-world applications and highlight important performance-latency tradeoffs.
We open-source the benchmark and all results for further analysis at
https://distylai.github.io/IFScale.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [110] [Latent Space Consistency for Sparse-View CT Reconstruction](https://arxiv.org/abs/2507.11152)
*Duoyou Chen,Yunqing Chen,Can Zhang,Zhou Wang,Cheng Chen,Ruoxiu Xiao*

Main category: eess.IV

TL;DR: 提出了一种名为CLS-DM的模型，通过跨模态特征对比学习，解决2D X射线与3D CT图像在潜在空间对齐的问题，显著提升了稀疏视图CT重建的效果。


<details>
  <summary>Details</summary>
Motivation: 传统CT重建方法存在时间消耗大和辐射暴露高的问题，稀疏视图X射线图像重建方法成为研究热点，但2D与3D潜在空间对齐困难。

Method: 提出CLS-DM模型，结合跨模态特征对比学习，从2D X射线图像中提取3D潜在信息，实现模态间潜在空间对齐。

Result: 在LIDC-IDRI和CTSpine1K数据集上，CLS-DM在PSNR和SSIM指标上优于经典和先进生成模型。

Conclusion: CLS-DM不仅提升了稀疏X射线重建CT的效果和经济性，还可推广至其他跨模态转换任务，如文本到图像合成。

Abstract: Computed Tomography (CT) is a widely utilized imaging modality in clinical
settings. Using densely acquired rotational X-ray arrays, CT can capture 3D
spatial features. However, it is confronted with challenged such as significant
time consumption and high radiation exposure. CT reconstruction methods based
on sparse-view X-ray images have garnered substantial attention from
researchers as they present a means to mitigate costs and risks. In recent
years, diffusion models, particularly the Latent Diffusion Model (LDM), have
demonstrated promising potential in the domain of 3D CT reconstruction.
Nonetheless, due to the substantial differences between the 2D latent
representation of X-ray modalities and the 3D latent representation of CT
modalities, the vanilla LDM is incapable of achieving effective alignment
within the latent space. To address this issue, we propose the Consistent
Latent Space Diffusion Model (CLS-DM), which incorporates cross-modal feature
contrastive learning to efficiently extract latent 3D information from 2D X-ray
images and achieve latent space alignment between modalities. Experimental
results indicate that CLS-DM outperforms classical and state-of-the-art
generative models in terms of standard voxel-level metrics (PSNR, SSIM) on the
LIDC-IDRI and CTSpine1K datasets. This methodology not only aids in enhancing
the effectiveness and economic viability of sparse X-ray reconstructed CT but
can also be generalized to other cross-modal transformation tasks, such as
text-to-image synthesis. We have made our code publicly available at
https://anonymous.4open.science/r/CLS-DM-50D6/ to facilitate further research
and applications in other domains.

</details>


### [111] [3D Magnetic Inverse Routine for Single-Segment Magnetic Field Images](https://arxiv.org/abs/2507.11293)
*J. Senthilnath,Chen Hao,F. C. Wellstood*

Main category: eess.IV

TL;DR: 提出了一种名为3D MIR的新方法，结合深度学习和物理约束，用于半导体封装中的3D电流参数恢复。


<details>
  <summary>Details</summary>
Motivation: 在半导体封装中，准确恢复3D信息对非破坏性测试和电路缺陷定位至关重要。

Method: 方法分为三个阶段：1) CNN处理磁图像预测参数；2) 利用物理约束提供初始估计；3) 优化器调整参数以最小化误差。

Result: 3D MIR方法能够高精度恢复3D信息，为磁图像重建设定了新标准。

Conclusion: 该方法展示了深度学习和物理驱动优化在实际应用中的潜力。

Abstract: In semiconductor packaging, accurately recovering 3D information is crucial
for non-destructive testing (NDT) to localize circuit defects. This paper
presents a novel approach called the 3D Magnetic Inverse Routine (3D MIR),
which leverages Magnetic Field Images (MFI) to retrieve the parameters for the
3D current flow of a single-segment. The 3D MIR integrates a deep learning
(DL)-based Convolutional Neural Network (CNN), spatial-physics-based
constraints, and optimization techniques. The method operates in three stages:
i) The CNN model processes the MFI data to predict ($\ell/z_o$), where $\ell$
is the wire length and $z_o$ is the wire's vertical depth beneath the magnetic
sensors and classify segment type ($c$). ii) By leveraging
spatial-physics-based constraints, the routine provides initial estimates for
the position ($x_o$, $y_o$, $z_o$), length ($\ell$), current ($I$), and current
flow direction (positive or negative) of the current segment. iii) An optimizer
then adjusts these five parameters ($x_o$, $y_o$, $z_o$, $\ell$, $I$) to
minimize the difference between the reconstructed MFI and the actual MFI. The
results demonstrate that the 3D MIR method accurately recovers 3D information
with high precision, setting a new benchmark for magnetic image reconstruction
in semiconductor packaging. This method highlights the potential of combining
DL and physics-driven optimization in practical applications.

</details>


### [112] [HANS-Net: Hyperbolic Convolution and Adaptive Temporal Attention for Accurate and Generalizable Liver and Tumor Segmentation in CT Imaging](https://arxiv.org/abs/2507.11325)
*Arefin Ittesafun Abian,Ripon Kumar Debnath,Md. Abdur Rahman,Mohaimenul Azam Khan Raiaan,Md Rafiqul Islam,Asif Karim,Reem E. Mohamed,Sami Azam*

Main category: eess.IV

TL;DR: HANS-Net是一种新型肝脏和肿瘤分割框架，结合双曲卷积、小波分解、突触可塑性机制和隐式神经表示，显著提高了CT图像分割的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 由于复杂的解剖结构、肿瘤外观的多样性和标注数据有限，腹部CT图像上的肝脏和肿瘤分割仍具挑战性。

Method: HANS-Net结合双曲卷积、小波分解模块、突触可塑性机制和隐式神经表示，并引入不确定性感知蒙特卡洛dropout和轻量级时间注意力。

Result: 在LiTS数据集上，HANS-Net的Dice得分为93.26%，IoU为88.09%，ASSD为0.72 mm，VOE为11.91%；在3D-IRCADb-01数据集上表现同样优异。

Conclusion: HANS-Net在肝脏和肿瘤分割中表现出高效性、鲁棒性和跨数据集泛化能力。

Abstract: Accurate liver and tumor segmentation on abdominal CT images is critical for
reliable diagnosis and treatment planning, but remains challenging due to
complex anatomical structures, variability in tumor appearance, and limited
annotated data. To address these issues, we introduce Hyperbolic-convolutions
Adaptive-temporal-attention with Neural-representation and Synaptic-plasticity
Network (HANS-Net), a novel segmentation framework that synergistically
combines hyperbolic convolutions for hierarchical geometric representation, a
wavelet-inspired decomposition module for multi-scale texture learning, a
biologically motivated synaptic plasticity mechanism for adaptive feature
enhancement, and an implicit neural representation branch to model fine-grained
and continuous anatomical boundaries. Additionally, we incorporate
uncertainty-aware Monte Carlo dropout to quantify prediction confidence and
lightweight temporal attention to improve inter-slice consistency without
sacrificing efficiency. Extensive evaluations of the LiTS dataset demonstrate
that HANS-Net achieves a mean Dice score of 93.26%, an IoU of 88.09%, an
average symmetric surface distance (ASSD) of 0.72 mm, and a volume overlap
error (VOE) of 11.91%. Furthermore, cross-dataset validation on the
3D-IRCADb-01 dataset obtains an average Dice of 87.45%, IoU of 80.30%, ASSD of
1.525 mm, and VOE of 19.71%, indicating strong generalization across different
datasets. These results confirm the effectiveness and robustness of HANS-Net in
providing anatomically consistent, accurate, and confident liver and tumor
segmentation.

</details>
